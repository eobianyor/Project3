{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Collect_WaterWatch_Data_20210201_2308_Google_Colab.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUA0sJAqlsOd"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1y4VQxAlsOg"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN_ZuWB7lsOg"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4x6PbngW4CL",
        "outputId": "c8ec0ab1-7c98-4377-bcb8-dfb7627b6290"
      },
      "source": [
        "# =========================================================\n",
        "#          Python Library Installations for Colab\n",
        "# =========================================================\n",
        "! pip install splinter\n",
        "# ---------------------------------------------------------\n",
        "!pip install beautifulsoup4\n",
        "# ---------------------------------------------------------\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting splinter\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/94/836feeefcc8af55cba5ea9716b83c665fd85ae9e1d81e22ae73357bf61cf/splinter-0.14.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from splinter) (1.15.0)\n",
            "Collecting selenium>=3.141.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium>=3.141.0->splinter) (1.24.3)\n",
            "Installing collected packages: selenium, splinter\n",
            "Successfully installed selenium-3.141.0 splinter-0.14.0\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Ign:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [602 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,746 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,964 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,394 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,396 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [893 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,163 kB]\n",
            "Fetched 11.4 MB in 4s (2,977 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 83.2 MB of archives.\n",
            "After this operation, 282 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 89.0.4389.82-0ubuntu0.18.04.1 [1,127 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 89.0.4389.82-0ubuntu0.18.04.1 [73.6 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 89.0.4389.82-0ubuntu0.18.04.1 [3,800 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 89.0.4389.82-0ubuntu0.18.04.1 [4,697 kB]\n",
            "Fetched 83.2 MB in 5s (15.1 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160975 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_89.0.4389.82-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_89.0.4389.82-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (89.0.4389.82-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up5XBnmqWv_y"
      },
      "source": [
        "# =========================================================\n",
        "#               Python Libraries for Colab\n",
        "# =========================================================\n",
        "import sys\n",
        "# ---------------------------------------------------------\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaiIS0QXYobU",
        "outputId": "9f39c130-2c59-45e5-c2a4-1280bb169c47"
      },
      "source": [
        "# =========================================================\n",
        "#               Mount Google Drive to Colab\n",
        "# =========================================================\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJPavFmElsOg"
      },
      "source": [
        "# =========================================================\n",
        "#               Import Python Libraries\n",
        "# =========================================================\n",
        "import os\n",
        "# ---------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# ---------------------------------------------------------\n",
        "from splinter import Browser\n",
        "# ---------------------------------------------------------\n",
        "from bs4 import BeautifulSoup as BS\n",
        "# ---------------------------------------------------------\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver import ActionChains\n",
        "from selenium.webdriver.support.ui import Select\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.common.exceptions import NoSuchElementException \n",
        "# ---------------------------------------------------------\n",
        "import urllib.request, urllib.error, urllib.parse\n",
        "# ---------------------------------------------------------\n",
        "from itertools import dropwhile\n",
        "# ---------------------------------------------------------\n",
        "import time\n",
        "import datetime\n",
        "from datetime import timedelta, date\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import warnings\n",
        "# import pymongo\n",
        "# import requests\n",
        "# import datefinder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A6FqKQ1lsOh"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fLYE2RllsOh"
      },
      "source": [
        "# URLs for the Websites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kmQ7VfRlsOh"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzT0h0Q2lsOh"
      },
      "source": [
        "# USGS_WaterWatch_url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_-WPwCdlsOi"
      },
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO3-rGxwlsOi"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpizr-1DlsOi"
      },
      "source": [
        "# Step 00 - Scrape the Tables from USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Using Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PrzcUI6lsOi"
      },
      "source": [
        "This did not work b/c the table is created with JavaScript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOU_PRcMlsOj"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_0NTk_blsOj"
      },
      "source": [
        "# # Importing the USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Websites\n",
        "# River_Stream_7Day_Flow_Conditions_Tables = pd.read_html(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjgD-12RlsOj"
      },
      "source": [
        "# len(River_Stream_7Day_Flow_Conditions_Tables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rRZcdtYMlsOj"
      },
      "source": [
        "# River_Stream_7Day_Flow_Conditions_Tables[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IEdTRx2lsOk"
      },
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBkfuy0blsOk"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T_vgEiYlsOk"
      },
      "source": [
        "# Step 2 - Scraping the Website with BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGaqfeZGlsOk"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed_l27MelsOl"
      },
      "source": [
        "## Scrape a webpage and create a BeautifulSoup object from the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVW9aBJAlsOl"
      },
      "source": [
        "## 2.1 USGS' WaterWatch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBSNqcXllsOl"
      },
      "source": [
        "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3k-6PCAlsOl"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mjgiZomlsOl"
      },
      "source": [
        "# Step 1 - Scrape a Table of All the Streamflow Stations In Idaho by County, Save a CSV File with Daily Streamflow Data for Each Station, and Scrape a Table with Extended Streamflow Statistics for Each Streamflow Station"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lzs7zBMlsOl"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvMlUjD4lsOm"
      },
      "source": [
        "## Scrape a webpage and create a BeautifulSoup object from the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeEsT_5DlsOm"
      },
      "source": [
        "## 1.1 Create the Driver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3efy0VllsOm"
      },
      "source": [
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAU9-IASlsOm"
      },
      "source": [
        "# from selenium import webdriver\n",
        "# from selenium.webdriver.support.ui import Select\n",
        "\n",
        "USGS_WaterWatch_url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
        "\n",
        "# driver = webdriver.Chrome()\n",
        "# driver.get(USGS_WaterWatch_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt7jdRit3ifp"
      },
      "source": [
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"-headless\")\n",
        "options.add_argument(\"-no-sandbox\")\n",
        "options.add_argument(\"-disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(\"chromedriver\",options=options)\n",
        "driver.get(USGS_WaterWatch_url)\n",
        "# print(driver.page_source) # results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaYG_ez3lsOm"
      },
      "source": [
        "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
        "# https://selenium-python.readthedocs.io/locating-elements.html\n",
        "\n",
        "driver.find_element_by_xpath(\"//*[contains(text(), 'Current Streamflow')]\").click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S3Afnm4lsOn"
      },
      "source": [
        "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
        "\n",
        "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi_GEYWDlsOn"
      },
      "source": [
        "# Press/Click a Button Without an ID\n",
        "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
        "\n",
        "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
        "\n",
        "button = driver.find_element_by_xpath(lst_all_statns)\n",
        "button.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYOXllKZlsOn"
      },
      "source": [
        "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "\n",
        "select = Select(driver.find_element_by_id('select_display'))\n",
        "\n",
        "# Select by visible text\n",
        "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
        "\n",
        "# Select by value text\n",
        "select.select_by_value('dailystagedischarge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er7O2xGYlsOn"
      },
      "source": [
        "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "\n",
        "select = Select(driver.find_element_by_id('group_table_by'))\n",
        "\n",
        "# Select by visible text\n",
        "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
        "\n",
        "# Select by value text\n",
        "select.select_by_value('county_cd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGDiqyxplsOo"
      },
      "source": [
        "# Press/Click a Button Without an ID\n",
        "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
        "\n",
        "sbmt_bttn = '//input[@type=\"submit\" and @value=\"go\"]'\n",
        "\n",
        "button = driver.find_element_by_xpath(sbmt_bttn)\n",
        "button.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jV9meL7ElsOo"
      },
      "source": [
        "# Find All the Station Numbers Scrap the table with all the stations and use that table to loop \n",
        "# through and click each station's link."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7RnNKF1lsOo"
      },
      "source": [
        "crrnt_url = driver.current_url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "OA4WXr_rlsOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "953f5686-18ed-42b3-8985-6f9bf045f8b1"
      },
      "source": [
        "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
        "\n",
        "statn_table = pd.read_html(crrnt_url)\n",
        "print(f\"Number of Tables on the current page: {len(statn_table)}\")\n",
        "statn_table[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Tables on the current page: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StationNumber</th>\n",
              "      <th>Station name</th>\n",
              "      <th>Dailymeangage height(ft)3/12</th>\n",
              "      <th>Dailymeanstream- flow (ft3/s)3/12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada County</td>\n",
              "      <td>Ada County</td>\n",
              "      <td>Ada County</td>\n",
              "      <td>Ada County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13206000</td>\n",
              "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13206305</td>\n",
              "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13206400</td>\n",
              "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bannock County</td>\n",
              "      <td>Bannock County</td>\n",
              "      <td>Bannock County</td>\n",
              "      <td>Bannock County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>13011500</td>\n",
              "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>13011900</td>\n",
              "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>--</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>13013650</td>\n",
              "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>13015000</td>\n",
              "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>--</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>13018750</td>\n",
              "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1370</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      StationNumber  ... Dailymeanstream- flow (ft3/s)3/12\n",
              "0        Ada County  ...                        Ada County\n",
              "1          13206000  ...                               271\n",
              "2          13206305  ...                               243\n",
              "3          13206400  ...                              6.35\n",
              "4    Bannock County  ...                    Bannock County\n",
              "..              ...  ...                               ...\n",
              "271        13011500  ...                               Ice\n",
              "272        13011900  ...                                --\n",
              "273        13013650  ...                               924\n",
              "274        13015000  ...                                --\n",
              "275        13018750  ...                              1370\n",
              "\n",
              "[276 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L9uQnVmXlsOp"
      },
      "source": [
        "# print(statn_table[1].dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l138G_3IlsOp"
      },
      "source": [
        "statn_table_df = statn_table[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "givhSHbAlsOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0cbaff8a-965d-4c13-f0d5-8071a18adece"
      },
      "source": [
        "# Seperate the text from the digits in the \"StationNumber\" column.\n",
        "# https://stackoverflow.com/questions/56851679/how-to-separate-pandas-column-that-contains-values-stored-as-text-and-numbers-in\n",
        "\n",
        "statn_table_df_splt_StatnNmbr = statn_table_df.join(statn_table_df.pop('StationNumber').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n",
        "statn_table_df_splt_StatnNmbr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Station name</th>\n",
              "      <th>Dailymeangage height(ft)3/12</th>\n",
              "      <th>Dailymeanstream- flow (ft3/s)3/12</th>\n",
              "      <th>numbers</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada County</td>\n",
              "      <td>Ada County</td>\n",
              "      <td>Ada County</td>\n",
              "      <td></td>\n",
              "      <td>Ada County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>271</td>\n",
              "      <td>13206000</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>243</td>\n",
              "      <td>13206305</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.35</td>\n",
              "      <td>13206400</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bannock County</td>\n",
              "      <td>Bannock County</td>\n",
              "      <td>Bannock County</td>\n",
              "      <td></td>\n",
              "      <td>Bannock County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ice</td>\n",
              "      <td>13011500</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>--</td>\n",
              "      <td>13011900</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>924</td>\n",
              "      <td>13013650</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>--</td>\n",
              "      <td>13015000</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1370</td>\n",
              "      <td>13018750</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Station name  ...            text\n",
              "0                                        Ada County  ...      Ada County\n",
              "1        BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID  ...                \n",
              "2             BOISE RIVER SOUTH CHANNEL AT EAGLE ID  ...                \n",
              "3                          EAGLE DRAIN AT EAGLE, ID  ...                \n",
              "4                                    Bannock County  ...  Bannock County\n",
              "..                                              ...  ...             ...\n",
              "271                      PACIFIC CREEK AT MORAN, WY  ...                \n",
              "272          BUFFALO FORK AB LAVA CREEK NR MORAN WY  ...                \n",
              "273                        SNAKE RIVER AT MOOSE, WY  ...                \n",
              "274                 GROS VENTRE RIVER AT ZENITH, WY  ...                \n",
              "275  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY  ...                \n",
              "\n",
              "[276 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa09iRdnlsOp"
      },
      "source": [
        "# Reference:\n",
        "#     - How to: Select a range of rows of a DataFrame by index\n",
        "#         - https://www.kite.com/python/examples/2805/pandas-select-a-range-of-rows-of-a-%60dataframe%60-by-index\n",
        "\n",
        "statn_table_df_splt_StatnNmbr[213:221]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH0s6dCWlsOp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "1dabd9ac-e607-41b3-c7f7-a3aab8fb0f6b"
      },
      "source": [
        "# This is to Drop the Row with an Index Number of 215 Because it's an Empty Row, See Above.\n",
        "statn_table_df_splt_StatnNmbr = statn_table_df_splt_StatnNmbr.drop(215)\n",
        "statn_table_df_splt_StatnNmbr = statn_table_df_splt_StatnNmbr.reset_index(drop = True)\n",
        "statn_table_df_splt_StatnNmbr[213:221]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Station name</th>\n",
              "      <th>Dailymeangage height(ft)3/12</th>\n",
              "      <th>Dailymeanstream- flow (ft3/s)3/12</th>\n",
              "      <th>numbers</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>Twin Falls County</td>\n",
              "      <td>Twin Falls County</td>\n",
              "      <td>Twin Falls County</td>\n",
              "      <td></td>\n",
              "      <td>Twin Falls County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>LOWER MILNER POWER PLANT AT MILNER ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13087505</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>SNAKE RIVER GAGING STATION AT MILNER ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13087995</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>SNAKE RIVER NR TWIN FALLS ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>371</td>\n",
              "      <td>13090500</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>ROCK CREEK AB HWY 30/93 XING AT TWIN FALLS ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>39.9</td>\n",
              "      <td>13092747</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>SNAKE RIVER NR BUHL ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1390</td>\n",
              "      <td>13094000</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>SALMON FALLS CREEK NR HAGERMAN ID</td>\n",
              "      <td>NaN</td>\n",
              "      <td>110</td>\n",
              "      <td>13108150</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Valley County</td>\n",
              "      <td>Valley County</td>\n",
              "      <td>Valley County</td>\n",
              "      <td></td>\n",
              "      <td>Valley County</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      Station name  ...               text\n",
              "213                              Twin Falls County  ...  Twin Falls County\n",
              "214          LOWER MILNER POWER PLANT AT MILNER ID  ...                   \n",
              "215        SNAKE RIVER GAGING STATION AT MILNER ID  ...                   \n",
              "216                   SNAKE RIVER NR TWIN FALLS ID  ...                   \n",
              "217  ROCK CREEK AB HWY 30/93 XING AT TWIN FALLS ID  ...                   \n",
              "218                         SNAKE RIVER NR BUHL ID  ...                   \n",
              "219              SALMON FALLS CREEK NR HAGERMAN ID  ...                   \n",
              "220                                  Valley County  ...      Valley County\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDlIZUzUlsOq"
      },
      "source": [
        "# # NEW CELL\n",
        "\n",
        "# if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
        "#     print(\"No County\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVEE7myglsOq"
      },
      "source": [
        "# Create a dataframe with only the \"numbers\" column from the \"statn_table_df_splt\" Dataframe\n",
        "statn_table_df_splt_StatnNmbr_nmbrs_clmn = pd.DataFrame(statn_table_df_splt_StatnNmbr[\"numbers\"])\n",
        "\n",
        "# Replace the Empty Rows with \"NaN\"\n",
        "# https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
        "\n",
        "nan_value = float(\"NaN\")\n",
        "statn_table_df_splt_StatnNmbr_nmbrs_clmn.replace(\"\", nan_value, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxeZBOoBlsOq"
      },
      "source": [
        "# # Count the Number of Null Values in the Dataframe\n",
        "# # https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
        "\n",
        "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bMIS8QklsOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959ca1ae-f322-4fe3-e6a3-bea998a93fd5"
      },
      "source": [
        "# Remove the \"NaN\" Null Values\n",
        "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls = statn_table_df_splt_StatnNmbr_nmbrs_clmn.dropna()\n",
        "print(f\"Number of Null Values: {statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.isna().sum()}\")\n",
        "print(\"*********************************************************************************************************\")\n",
        "print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Null Values: numbers    0\n",
            "dtype: int64\n",
            "*********************************************************************************************************\n",
            "numbers    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zUDcPDaClsOr"
      },
      "source": [
        "# # Convert the \"numbers\" column to an Interger Data Type\n",
        "\n",
        "# statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"] = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"].astype(int)\n",
        "\n",
        "# print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GTiZf0alsOr"
      },
      "source": [
        "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72wJRDN8lsOr"
      },
      "source": [
        "bgn_date = \"1992-01-01\"\n",
        "end_date = \"2015-12-31\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiosixI4lsOr"
      },
      "source": [
        "# Reference:\n",
        "#     - Checking if an Element Exist on a Webpage with Python Selenium\n",
        "#         - https://stackoverflow.com/questions/9567069/checking-if-element-exists-with-python-selenium\n",
        "\n",
        "def check_exists_by_xpath(xpath):\n",
        "    try:\n",
        "        select = Select(driver.find_element_by_id(\"select_data_1\"))\n",
        "        select.select_by_visible_text(\"Time-series:   Current/Historical Observations\")\n",
        "    except NoSuchElementException:\n",
        "        return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc_vN8jzlsOs"
      },
      "source": [
        "check_exists_by_xpath(\"https://waterdata.usgs.gov/id/nwis/uv/?site_no=13296000&agency_cd=USGS\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYh-sghcL17"
      },
      "source": [
        "test = webContent.decode(\"utf-8\")\n",
        "type(test)\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FlOp5SZUlsOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5d908b-2626-4a30-a5bb-32aa9f3dd1d3"
      },
      "source": [
        "statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr\n",
        "\n",
        "for row in statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.index:\n",
        "    \n",
        "    # Find the Hyper Link for One Station\n",
        "    statn_nmbr = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"][row]\n",
        "\n",
        "\n",
        "    # https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\n",
        "    # driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\n",
        "    driver.find_element_by_xpath(\"//*[contains(text(),'\" +statn_nmbr+\"')]\").click()\n",
        "\n",
        "\n",
        "    # Under Output Format Select the \"Tab-separated\" Output format\n",
        "    lst_all_statns = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
        "\n",
        "    lst_all_statns_button = driver.find_element_by_xpath(lst_all_statns)\n",
        "    lst_all_statns_button.click()\n",
        "#     time.sleep(5)\n",
        "\n",
        "    # Enter Values for the Begin Date and End Date\n",
        "    # Fill in Input Fills\n",
        "    #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
        "    # Clear the Input Field\n",
        "    #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
        "\n",
        "    element = driver.find_element_by_name(\"begin_date\")\n",
        "    element.clear()\n",
        "    element.send_keys(bgn_date)\n",
        "\n",
        "    element = driver.find_element_by_name(\"end_date\")\n",
        "    element.clear()\n",
        "    element.send_keys(end_date)\n",
        "    \n",
        "\n",
        "    # Press/Click a Button Without an ID\n",
        "    #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
        "    #     - https://stackoverflow.com/questions/21322116/using-selenium-in-python-to-click-select-a-radio-button/21322160\n",
        "\n",
        "    sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
        "\n",
        "    sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
        "    sbmt_bttn_button.click()\n",
        "#     time.sleep(5)\n",
        "\n",
        "\n",
        "#     from selenium.webdriver import ActionChains\n",
        "\n",
        "    actionChains = ActionChains(driver)\n",
        "\n",
        "\n",
        "    # Save the data file to This Computer\n",
        "\n",
        "    # How to Open and Write to a File on This Computer\n",
        "    #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
        "    # How to Change the Location of the File\n",
        "    #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
        "\n",
        "#     import urllib.request, urllib.error, urllib.parse\n",
        "#     import os\n",
        "\n",
        "\n",
        "    response = urllib.request.urlopen(driver.current_url)\n",
        "    webContent_bytes = response.read()\n",
        "    webContent_str = webContent_bytes.decode(\"utf-8\")\n",
        "\n",
        "\n",
        "    fle_nm = \"/content/gdrive/My Drive/Colab_Notebooks/USGS_Idaho_Water_Watch_Data/\" + statn_nmbr + \".txt\"\n",
        "\n",
        "    f = open(fle_nm, 'w')\n",
        "    f.write(webContent_str)\n",
        "    f.close\n",
        "\n",
        "# Go back to the original URL for the station\n",
        "    driver.back()\n",
        "    time.sleep(2)\n",
        "# ================================================================================================   \n",
        "# This isn't Working Because Some of the Stations do not have a \"Time-series: Current/Historical \n",
        "# Observations\" In the \"Available Data for this Site\" Dropdown List Box\n",
        "# ------------------------------------------------------------------------------------------------\n",
        "# # Select the \"Time-series: Current/Historical Observations\" from the dropdown list, this will \n",
        "# # create page which includes a table with extended streamflow statistics.\n",
        "\n",
        "    crrnt_url = driver.current_url\n",
        "\n",
        "    if check_exists_by_xpath(crrnt_url):\n",
        "        crrnt_hstrcl_obsrvtns = '//input[@value=\"uv\"]'\n",
        "\n",
        "        select = Select(driver.find_element_by_id(\"select_data_1\"))\n",
        "        select.select_by_visible_text(\"Time-series:   Current/Historical Observations\")\n",
        "# ================================================================================================\n",
        "\n",
        "# ================================================================================================\n",
        "# Instead of Using the \"Time-series: Current/Historical Observations\", I decided to Use the \n",
        "# \"Time-series:   Daily data\" for the Extended Mean. I do not Need to Select anything in the\n",
        "# \"Available Data for this Site\" Dropdown List Box.\n",
        "# ------------------------------------------------------------------------------------------------\n",
        "# Under Output Format Select the \"Tab-separated\" Output format\n",
        "    else:\n",
        "        statn_grph_stats = '//input[@type=\"radio\" and @value=\"gif_stats\"]'\n",
        "\n",
        "        statn_grph_stats_button = driver.find_element_by_xpath(statn_grph_stats)\n",
        "        statn_grph_stats_button.click()\n",
        "\n",
        "        sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
        "\n",
        "        sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
        "        sbmt_bttn_button.click()\n",
        "\n",
        "# ================================================================================================    \n",
        "    \n",
        "# Get the extended year streamflow min, max, median, mean, 25th percentile, and 75th percentile\n",
        "    # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
        "    \n",
        "    crrnt_hstrcl_obsrvtns_url = driver.current_url\n",
        "    crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
        "    print(f'Station Number: {statn_nmbr}')\n",
        "    print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
        "#     print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
        "    \n",
        "    if len(crrnt_hstrcl_obsrvtns_html) == 2:\n",
        "        \n",
        "#         print(crrnt_hstrcl_obsrvtns_html[1])\n",
        "\n",
        "        extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
        "\n",
        "\n",
        "        # Reference: \n",
        "    #     - Find column whose name contains a specific string:\n",
        "    #         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
        "\n",
        "    # print(extndd_yrs_sttstcs.columns)\n",
        "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
        "        min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
        "#         print(f'Min Flow: {min_strmflw}')\n",
        "\n",
        "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
        "        max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
        "#         print(f'Max Flow: {max_strmflw}')\n",
        "\n",
        "#         extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
        "#         _25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
        "# #         print(f'25th_prcntle: {_25th_prcntle_strmflw}')\n",
        "\n",
        "#         extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
        "#         _75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
        "# #         print(f'75th_prcntle: {_75th_prcntle_strmflw}')\n",
        "\n",
        "\n",
        "\n",
        "            # References:\n",
        "        #     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
        "        #         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
        "        #     - Pandas update a cell:\n",
        "        #         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
        "\n",
        "\n",
        "        # Find the Index for the Station  \n",
        "        indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
        "        print(f'Index No: {indx_lbl[0]}')\n",
        "\n",
        "        # Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
        "        # Dataframe\n",
        "    # #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
        "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
        "\n",
        "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
        "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
        "\n",
        "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
        "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
        "\n",
        "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
        "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
        "\n",
        "#     #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
        "#         statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
        "\n",
        "#     #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
        "#         statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]\n",
        "    \n",
        "    elif len(crrnt_hstrcl_obsrvtns_html) < 2:\n",
        "        print(\"No Extened Water Statistics\")\n",
        "    \n",
        "    print(\"********************************************************************************\")\n",
        "    \n",
        "# Go back to the URL with the list of Stations and Counties\n",
        "    driver.back()\n",
        "    driver.back()\n",
        "    \n",
        "driver.close()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Station Number: 13206000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 1\n",
            "********************************************************************************\n",
            "Station Number: 13206305\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 2\n",
            "********************************************************************************\n",
            "Station Number: 13206400\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 3\n",
            "********************************************************************************\n",
            "Station Number: 13073000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 5\n",
            "********************************************************************************\n",
            "Station Number: 13075000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 6\n",
            "********************************************************************************\n",
            "Station Number: 13075500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 7\n",
            "********************************************************************************\n",
            "Station Number: 13075910\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 8\n",
            "********************************************************************************\n",
            "Station Number: 10039500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 10\n",
            "********************************************************************************\n",
            "Station Number: 10068500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 11\n",
            "********************************************************************************\n",
            "Station Number: 12414900\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 13\n",
            "********************************************************************************\n",
            "Station Number: 12415070\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 12415135\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 15\n",
            "********************************************************************************\n",
            "Station Number: 13060000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 17\n",
            "********************************************************************************\n",
            "Station Number: 13062500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 18\n",
            "********************************************************************************\n",
            "Station Number: 13065500\n",
            "Number of Tables on the current page: 5\n",
            "********************************************************************************\n",
            "Station Number: 13066000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 20\n",
            "********************************************************************************\n",
            "Station Number: 13068300\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 21\n",
            "********************************************************************************\n",
            "Station Number: 13068495\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 22\n",
            "********************************************************************************\n",
            "Station Number: 13068500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 23\n",
            "********************************************************************************\n",
            "Station Number: 13069500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 24\n",
            "********************************************************************************\n",
            "Station Number: 13075983\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 25\n",
            "********************************************************************************\n",
            "Station Number: 13135500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 27\n",
            "********************************************************************************\n",
            "Station Number: 13135520\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 28\n",
            "********************************************************************************\n",
            "Station Number: 13136550\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 29\n",
            "********************************************************************************\n",
            "Station Number: 13137000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 30\n",
            "********************************************************************************\n",
            "Station Number: 13137500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 31\n",
            "********************************************************************************\n",
            "Station Number: 13138000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 32\n",
            "********************************************************************************\n",
            "Station Number: 13139510\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 33\n",
            "********************************************************************************\n",
            "Station Number: 13140335\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 34\n",
            "********************************************************************************\n",
            "Station Number: 13140800\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 35\n",
            "********************************************************************************\n",
            "Station Number: 13142500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 36\n",
            "********************************************************************************\n",
            "Station Number: 13147900\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 37\n",
            "********************************************************************************\n",
            "Station Number: 13148500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 38\n",
            "********************************************************************************\n",
            "Station Number: 13150430\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 39\n",
            "********************************************************************************\n",
            "Station Number: 13185000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 41\n",
            "********************************************************************************\n",
            "Station Number: 13200000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 42\n",
            "********************************************************************************\n",
            "Station Number: 13235000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 43\n",
            "********************************************************************************\n",
            "Station Number: 13237920\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 44\n",
            "********************************************************************************\n",
            "Station Number: 13246000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 45\n",
            "********************************************************************************\n",
            "Station Number: 13247500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 46\n",
            "********************************************************************************\n",
            "Station Number: 12391950\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 48\n",
            "********************************************************************************\n",
            "Station Number: 12392155\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 49\n",
            "********************************************************************************\n",
            "Station Number: 12392300\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 50\n",
            "********************************************************************************\n",
            "Station Number: 12393501\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 51\n",
            "********************************************************************************\n",
            "Station Number: 12395000\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13032500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 54\n",
            "********************************************************************************\n",
            "Station Number: 13037500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 55\n",
            "********************************************************************************\n",
            "Station Number: 13057132\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13057155\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 57\n",
            "********************************************************************************\n",
            "Station Number: 13057500\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13057940\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 59\n",
            "********************************************************************************\n",
            "Station Number: 13058000\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13058510\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13058520\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13058529\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13058530\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 12306500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 66\n",
            "********************************************************************************\n",
            "Station Number: 12308000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 67\n",
            "********************************************************************************\n",
            "Station Number: 12308500\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 12309500\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 12310100\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 70\n",
            "********************************************************************************\n",
            "Station Number: 12318500\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 12321500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 72\n",
            "********************************************************************************\n",
            "Station Number: 12322000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 73\n",
            "********************************************************************************\n",
            "Station Number: 12322001\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 74\n",
            "********************************************************************************\n",
            "Station Number: 13118700\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 76\n",
            "********************************************************************************\n",
            "Station Number: 13118975\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 77\n",
            "********************************************************************************\n",
            "Station Number: 13119000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 78\n",
            "********************************************************************************\n",
            "Station Number: 13132100\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 79\n",
            "********************************************************************************\n",
            "Station Number: 13132373\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13132500\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13132513\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 82\n",
            "********************************************************************************\n",
            "Station Number: 13132520\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 83\n",
            "********************************************************************************\n",
            "Station Number: 13132535\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 84\n",
            "********************************************************************************\n",
            "Station Number: 13132565\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 85\n",
            "********************************************************************************\n",
            "Station Number: 13141500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 87\n",
            "********************************************************************************\n",
            "Station Number: 13210810\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 89\n",
            "********************************************************************************\n",
            "Station Number: 13210824\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 90\n",
            "********************************************************************************\n",
            "Station Number: 13210831\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 91\n",
            "********************************************************************************\n",
            "Station Number: 13210980\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 92\n",
            "********************************************************************************\n",
            "Station Number: 13210986\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 93\n",
            "********************************************************************************\n",
            "Station Number: 132109867\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 94\n",
            "********************************************************************************\n",
            "Station Number: 13211205\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 95\n",
            "********************************************************************************\n",
            "Station Number: 13212549\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 96\n",
            "********************************************************************************\n",
            "Station Number: 13213000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 97\n",
            "********************************************************************************\n",
            "Station Number: 13213100\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 98\n",
            "********************************************************************************\n",
            "Station Number: 13057300\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 100\n",
            "********************************************************************************\n",
            "Station Number: 13063000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 101\n",
            "********************************************************************************\n",
            "Station Number: 13078000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 103\n",
            "********************************************************************************\n",
            "Station Number: 13079300\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13082500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 105\n",
            "********************************************************************************\n",
            "Station Number: 13083000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 106\n",
            "********************************************************************************\n",
            "Station Number: 13116500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 108\n",
            "********************************************************************************\n",
            "Station Number: 13340000\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13340600\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13120000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 113\n",
            "********************************************************************************\n",
            "Station Number: 13120500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 114\n",
            "********************************************************************************\n",
            "Station Number: 13122000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 115\n",
            "********************************************************************************\n",
            "Station Number: 13124265\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 116\n",
            "********************************************************************************\n",
            "Station Number: 13127000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 117\n",
            "********************************************************************************\n",
            "Station Number: 13128900\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 118\n",
            "********************************************************************************\n",
            "Station Number: 13295000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 119\n",
            "********************************************************************************\n",
            "Station Number: 13296000\n",
            "Number of Tables on the current page: 3\n",
            "********************************************************************************\n",
            "Station Number: 13296500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 121\n",
            "********************************************************************************\n",
            "Station Number: 13297330\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 122\n",
            "********************************************************************************\n",
            "Station Number: 13297355\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 123\n",
            "********************************************************************************\n",
            "Station Number: 13154500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 125\n",
            "********************************************************************************\n",
            "Station Number: 13159800\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 126\n",
            "********************************************************************************\n",
            "Station Number: 13186000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 127\n",
            "********************************************************************************\n",
            "Station Number: 13190500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 128\n",
            "********************************************************************************\n",
            "Station Number: 10092700\n",
            "Number of Tables on the current page: 6\n",
            "********************************************************************************\n",
            "Station Number: 13039500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 132\n",
            "********************************************************************************\n",
            "Station Number: 13042500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 133\n",
            "********************************************************************************\n",
            "Station Number: 13046000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 134\n",
            "********************************************************************************\n",
            "Station Number: 13046995\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 135\n",
            "********************************************************************************\n",
            "Station Number: 13047500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 136\n",
            "********************************************************************************\n",
            "Station Number: 13047600\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 137\n",
            "********************************************************************************\n",
            "Station Number: 13049500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 138\n",
            "********************************************************************************\n",
            "Station Number: 13050500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 139\n",
            "********************************************************************************\n",
            "Station Number: 13055000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 140\n",
            "********************************************************************************\n",
            "Station Number: 13249500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 142\n",
            "********************************************************************************\n",
            "Station Number: 13250000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 143\n",
            "********************************************************************************\n",
            "Station Number: 13095175\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 145\n",
            "********************************************************************************\n",
            "Station Number: 13095500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 146\n",
            "********************************************************************************\n",
            "Station Number: 13152500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 147\n",
            "********************************************************************************\n",
            "Station Number: 13316500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 149\n",
            "********************************************************************************\n",
            "Station Number: 13317000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 150\n",
            "********************************************************************************\n",
            "Station Number: 13336500\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13337000\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13337500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 153\n",
            "********************************************************************************\n",
            "Station Number: 13338500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 154\n",
            "********************************************************************************\n",
            "Station Number: 13038000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 156\n",
            "********************************************************************************\n",
            "Station Number: 13038500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 157\n",
            "********************************************************************************\n",
            "Station Number: 13112000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 158\n",
            "********************************************************************************\n",
            "Station Number: 13089500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 160\n",
            "********************************************************************************\n",
            "Station Number: 12413500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 162\n",
            "********************************************************************************\n",
            "Station Number: 12413860\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 163\n",
            "********************************************************************************\n",
            "Station Number: 12417650\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 164\n",
            "********************************************************************************\n",
            "Station Number: 12419000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 165\n",
            "********************************************************************************\n",
            "Station Number: 13345000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 167\n",
            "********************************************************************************\n",
            "Station Number: 13346800\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 168\n",
            "********************************************************************************\n",
            "Station Number: 13302005\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 170\n",
            "********************************************************************************\n",
            "Station Number: 13302500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 171\n",
            "********************************************************************************\n",
            "Station Number: 13305000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 172\n",
            "********************************************************************************\n",
            "Station Number: 13305310\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 173\n",
            "********************************************************************************\n",
            "Station Number: 13306370\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 174\n",
            "********************************************************************************\n",
            "Station Number: 13306385\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 175\n",
            "********************************************************************************\n",
            "Station Number: 13307000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 176\n",
            "********************************************************************************\n",
            "Station Number: 13310199\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 177\n",
            "********************************************************************************\n",
            "Station Number: 13338950\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 179\n",
            "********************************************************************************\n",
            "Station Number: 13055250\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 181\n",
            "********************************************************************************\n",
            "Station Number: 13055340\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 182\n",
            "********************************************************************************\n",
            "Station Number: 13056500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 183\n",
            "********************************************************************************\n",
            "Station Number: 13057000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 184\n",
            "********************************************************************************\n",
            "Station Number: 13081500\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13317660\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 188\n",
            "********************************************************************************\n",
            "Station Number: 13341050\n",
            "Number of Tables on the current page: 3\n",
            "********************************************************************************\n",
            "Station Number: 13341140\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 190\n",
            "********************************************************************************\n",
            "Station Number: 13341570\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 191\n",
            "********************************************************************************\n",
            "Station Number: 13342450\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 192\n",
            "********************************************************************************\n",
            "Station Number: 13342500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 193\n",
            "********************************************************************************\n",
            "Station Number: 13168500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 195\n",
            "********************************************************************************\n",
            "Station Number: 13176400\n",
            "Number of Tables on the current page: 3\n",
            "********************************************************************************\n",
            "Station Number: 13251000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 198\n",
            "********************************************************************************\n",
            "Station Number: 13077000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 200\n",
            "********************************************************************************\n",
            "Station Number: 12411000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 202\n",
            "********************************************************************************\n",
            "Station Number: 12413000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 203\n",
            "********************************************************************************\n",
            "Station Number: 12413125\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 204\n",
            "********************************************************************************\n",
            "Station Number: 12413130\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 205\n",
            "********************************************************************************\n",
            "Station Number: 12413131\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 206\n",
            "********************************************************************************\n",
            "Station Number: 12413210\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 207\n",
            "********************************************************************************\n",
            "Station Number: 12413355\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 208\n",
            "********************************************************************************\n",
            "Station Number: 12413875\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 209\n",
            "********************************************************************************\n",
            "Station Number: 12414500\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13052200\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 212\n",
            "********************************************************************************\n",
            "Station Number: 13087505\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13087995\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 215\n",
            "********************************************************************************\n",
            "Station Number: 13090500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 216\n",
            "********************************************************************************\n",
            "Station Number: 13092747\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 217\n",
            "********************************************************************************\n",
            "Station Number: 13094000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 218\n",
            "********************************************************************************\n",
            "Station Number: 13108150\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 219\n",
            "********************************************************************************\n",
            "Station Number: 13236500\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13239000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 222\n",
            "********************************************************************************\n",
            "Station Number: 13240000\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13309220\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 224\n",
            "********************************************************************************\n",
            "Station Number: 13310700\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 225\n",
            "********************************************************************************\n",
            "Station Number: 13310800\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13310850\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13311000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 228\n",
            "********************************************************************************\n",
            "Station Number: 13311250\n",
            "Number of Tables on the current page: 4\n",
            "********************************************************************************\n",
            "Station Number: 13311450\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 230\n",
            "********************************************************************************\n",
            "Station Number: 13313000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 231\n",
            "********************************************************************************\n",
            "Station Number: 13258500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 233\n",
            "********************************************************************************\n",
            "Station Number: 13265500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 234\n",
            "********************************************************************************\n",
            "Station Number: 13266000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 235\n",
            "********************************************************************************\n",
            "Station Number: 13269000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 236\n",
            "********************************************************************************\n",
            "Station Number: 12355347\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 12301250\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 240\n",
            "********************************************************************************\n",
            "Station Number: 12301933\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 241\n",
            "********************************************************************************\n",
            "Station Number: 12302055\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 242\n",
            "********************************************************************************\n",
            "Station Number: 12304500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 243\n",
            "********************************************************************************\n",
            "Station Number: 12305000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 244\n",
            "********************************************************************************\n",
            "Station Number: 480608115242901\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 12389500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 247\n",
            "********************************************************************************\n",
            "Station Number: 12390700\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 248\n",
            "********************************************************************************\n",
            "Station Number: 13105000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 250\n",
            "********************************************************************************\n",
            "Station Number: 13161500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 251\n",
            "********************************************************************************\n",
            "Station Number: 13162225\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 252\n",
            "********************************************************************************\n",
            "Station Number: 10396000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 254\n",
            "********************************************************************************\n",
            "Station Number: 13181000\n",
            "Number of Tables on the current page: 3\n",
            "********************************************************************************\n",
            "Station Number: 13183000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 257\n",
            "********************************************************************************\n",
            "Station Number: 13233300\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 258\n",
            "********************************************************************************\n",
            "Station Number: 13333000\n",
            "Number of Tables on the current page: 3\n",
            "********************************************************************************\n",
            "Station Number: 13334300\n",
            "Number of Tables on the current page: 6\n",
            "********************************************************************************\n",
            "Station Number: 13022500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 264\n",
            "********************************************************************************\n",
            "Station Number: 13023000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 265\n",
            "********************************************************************************\n",
            "Station Number: 13027500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 266\n",
            "********************************************************************************\n",
            "Station Number: 13010065\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 268\n",
            "********************************************************************************\n",
            "Station Number: 13011000\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 269\n",
            "********************************************************************************\n",
            "Station Number: 13011500\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 270\n",
            "********************************************************************************\n",
            "Station Number: 13011900\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13013650\n",
            "Number of Tables on the current page: 3\n",
            "********************************************************************************\n",
            "Station Number: 13015000\n",
            "Number of Tables on the current page: 1\n",
            "No Extened Water Statistics\n",
            "********************************************************************************\n",
            "Station Number: 13018750\n",
            "Number of Tables on the current page: 2\n",
            "Index No: 274\n",
            "********************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPfJwlbGlsOt"
      },
      "source": [
        "extndd_yrs_sttstcs_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mJ1fGmdVlsOt"
      },
      "source": [
        "statn_table_df_splt_StatnNmbr_test.head(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFrp8jilsOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91691b09-a64f-48d3-cca1-ace1fca4c2c5"
      },
      "source": [
        "# Create Dataframe for the county and each day\n",
        "\n",
        "# Reference:\n",
        "#     - How to Drop Empty Rows from a Dataframe\n",
        "#         - https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
        "\n",
        "cnty_date_df = statn_table_df_splt_StatnNmbr_test[[\"text\"]]\n",
        "print(type(cnty_date_df))\n",
        "cnty_date_df.replace(\"\", nan_value, inplace = True)\n",
        "cnty_date_df = cnty_date_df.dropna(how = \"any\")\n",
        "cnty_date_df = cnty_date_df.reset_index(drop = True)\n",
        "cnty_date_df = cnty_date_df.rename(columns = {\"text\": \"idaho_counties\"})\n",
        "cnty_date_df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4389: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idaho_counties</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ada County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bannock County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bear Lake County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Benewah County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bingham County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Blaine County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Boise County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bonner County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bonneville County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Boundary County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Butte County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Camas County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Canyon County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Caribou County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Cassia County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Clark County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Clearwater County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Custer County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Elmore County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Franklin County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Fremont County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Gem County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Gooding County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Idaho County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Jefferson County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Jerome County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Kootenai County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Latah County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Lemhi County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Lewis County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Madison County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Minidoka County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Nez Perce County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Owyhee County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Payette County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Power County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Shoshone County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Teton County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Twin Falls County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Valley County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Washington County</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Flathead County, Montana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Lincoln County, Montana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Sanders County, Montana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Elko County, Nevada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Harney County, Oregon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Malheur County, Oregon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Wallowa County, Oregon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Asotin County, Washington</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Lincoln County, Wyoming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Teton County, Wyoming</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               idaho_counties\n",
              "0                  Ada County\n",
              "1              Bannock County\n",
              "2            Bear Lake County\n",
              "3              Benewah County\n",
              "4              Bingham County\n",
              "5               Blaine County\n",
              "6                Boise County\n",
              "7               Bonner County\n",
              "8           Bonneville County\n",
              "9             Boundary County\n",
              "10               Butte County\n",
              "11               Camas County\n",
              "12              Canyon County\n",
              "13             Caribou County\n",
              "14              Cassia County\n",
              "15               Clark County\n",
              "16          Clearwater County\n",
              "17              Custer County\n",
              "18              Elmore County\n",
              "19            Franklin County\n",
              "20             Fremont County\n",
              "21                 Gem County\n",
              "22             Gooding County\n",
              "23               Idaho County\n",
              "24           Jefferson County\n",
              "25              Jerome County\n",
              "26            Kootenai County\n",
              "27               Latah County\n",
              "28               Lemhi County\n",
              "29               Lewis County\n",
              "30             Madison County\n",
              "31            Minidoka County\n",
              "32           Nez Perce County\n",
              "33              Owyhee County\n",
              "34             Payette County\n",
              "35               Power County\n",
              "36            Shoshone County\n",
              "37               Teton County\n",
              "38          Twin Falls County\n",
              "39              Valley County\n",
              "40          Washington County\n",
              "41   Flathead County, Montana\n",
              "42    Lincoln County, Montana\n",
              "43    Sanders County, Montana\n",
              "44        Elko County, Nevada\n",
              "45      Harney County, Oregon\n",
              "46     Malheur County, Oregon\n",
              "47     Wallowa County, Oregon\n",
              "48  Asotin County, Washington\n",
              "49    Lincoln County, Wyoming\n",
              "50      Teton County, Wyoming"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b37XFt_VlsOu"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COycxqGVlsOv"
      },
      "source": [
        "# Step 2 - Create a Dataframe for Each Station"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx6htmmMlsOv"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tO8AB75lsOv"
      },
      "source": [
        "## Scrape a webpage and create a BeautifulSoup object from the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6F56Gp0lsOv"
      },
      "source": [
        "## 2.1 USGS' Science for a Changing World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmwT_GaUlsOv"
      },
      "source": [
        "# The function to Skip All of the Commented Lines in the File\n",
        "#     https://cmdlinetips.com/2018/01/3-ways-to-read-a-file-and-skip-initial-comments-in-python/\n",
        "\n",
        "def is_comment(s):\n",
        "    \"\"\" function to check if a line\n",
        "         starts with some character.\n",
        "         Here # for comment\n",
        "    \"\"\"\n",
        "    # return true if a line starts with #\n",
        "    return s.startswith('#')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH3x0DF-lsOw"
      },
      "source": [
        "# Column Names for the Dataframe\n",
        "clmn_nms = [\"agency\", \n",
        "            \"site_nmbr\", \n",
        "            \"date\", \n",
        "            \"streamflow_rate\", \n",
        "            \"approved/pending\"]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBY1dDb5lsOw"
      },
      "source": [
        "# File Path for the Streamflow Data\n",
        "input_fle_path = os.path.join(\"Data\", \"Idaho_Streamflow_Data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBsEcI1hlsOw"
      },
      "source": [
        "# Dictionary of Data Types to Change in the Dataframe\n",
        "convert_dict = {\n",
        "                \"streamflow_rate\": float\n",
        "               } "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TSOazIdtlsOw"
      },
      "source": [
        "# List of Files in a Directory\n",
        "#     - https://careerkarma.com/blog/python-list-files-in-directory/\n",
        "\n",
        "input_fle_lst = os.listdir(input_fle_path)\n",
        "print(input_fle_lst)\n",
        "# input_fle_nm = input_fle_lst[0]\n",
        "# print(input_fle_nm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ddLgh8A8lsOx"
      },
      "source": [
        "# How to Ignore Hidden Files\n",
        "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
        "\n",
        "# Create a Dictionary of List from the Files in the Directory\n",
        "input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": []}\n",
        "\n",
        "for input_fle_nm in input_fle_lst:\n",
        "#     Skipping the Files that Start With \".\"\n",
        "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
        "\n",
        "# Append to the Station Numbers and File Names and create and append the Dataframe Name to the \n",
        "# Directory\n",
        "        input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
        "        input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
        "        input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
        "#         print(input_fle_nm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnqBlngClsOy"
      },
      "source": [
        "input_fle_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmHA8FjNlsOy"
      },
      "source": [
        "statn_table_df_splt_StatnNmbr.head()\n",
        "\n",
        "# The Last Index Value in the \"text\" Column\n",
        "lst_row_text_clmn = statn_table_df_splt_StatnNmbr[\"text\"].last_valid_index()\n",
        "lst_row_text_clmn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSX7WJgqlsOy"
      },
      "source": [
        "statn_table_df_splt_StatnNmbr[213:221]\n",
        "statn_table_df_splt_StatnNmbr.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "InrEmyiGlsOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8aaf653-3a45-445c-d344-5af855c4defe"
      },
      "source": [
        "# Create a List of the Counties\n",
        "cnty_lst = []\n",
        "\n",
        "count_1 = 0\n",
        "count_2 = 0\n",
        "count_3 = 0\n",
        "\n",
        "# Create a List of the Stations\n",
        "# statn_lst = []\n",
        "# cnty_lst = [[] * 154]\n",
        "new_dict = {}\n",
        "\n",
        "# The \"text\" Column is the County Name\n",
        "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
        "#     print(row)\n",
        " \n",
        "#     If this count is <= the Last Row in the \"text\" Column\n",
        "    if count_1 + 1 < 275:\n",
        "# *********************************************************************************************\n",
        "#                               Step 1: If the row is Not Empty\n",
        "# *********************************************************************************************\n",
        "        if row != \"\":\n",
        "            # Create a List of the Stations\n",
        "            statn_lst = []  # This will be a list of dictionaries\n",
        "            cnty_nm = row\n",
        "#         print(row)\n",
        "# #         count_1 = count_1\n",
        "#         cnty_lst[count_2].append(row)\n",
        "#         cnty_lst[count_2].append([])\n",
        "# *********************************************************************************************\n",
        "\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
        "# *********************************************************************************************\n",
        "\n",
        "        elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
        "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
        "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
        "        \n",
        "        \n",
        "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
        "# # #         count_3 = count_1\n",
        "# # #         print (count_3)\n",
        "# #         count_1 = 0\n",
        "\n",
        "\n",
        "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
        "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
        "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
        "                        \"Data\": \"\", \n",
        "                        \"Avg_Streamflow\": \"\",\n",
        "                        \"Prcnt_Below_Avg\": \"\"}\n",
        "    \n",
        "            statn_lst.append(dict(new_dict))\n",
        "# *********************************************************************************************\n",
        "\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
        "# *********************************************************************************************\n",
        "        elif row == \"\": #and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
        "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
        "        \n",
        "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
        "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
        "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
        "                        \"Data\": \"\", \n",
        "                        \"Avg_Streamflow\": \"\",\n",
        "                        \"Prcnt_Below_Avg\": \"\"}\n",
        "    \n",
        "            statn_lst.append(dict(new_dict))\n",
        "        \n",
        "#         count_2 = count_2 + 1\n",
        "        \n",
        "            cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
        "        \n",
        "# *********************************************************************************************\n",
        "\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
        "# *********************************************************************************************  \n",
        "    if count_1 + 1 > 274 and row == \"\":\n",
        "        print (count_1)\n",
        "\n",
        "\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
        "# *********************************************************************************************\n",
        "        \n",
        "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
        "                    \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
        "                    \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
        "                    \"Data\": \"\", \n",
        "                    \"Avg_Streamflow\": \"\",\n",
        "                    \"Prcnt_Below_Avg\": \"\"}\n",
        "\n",
        "        statn_lst.append(dict(new_dict))\n",
        "\n",
        "        cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
        "# *********************************************************************************************\n",
        "    \n",
        "    \n",
        "# *********************************************************************************************\n",
        "#                               Step 4: Add 1 to the Count\n",
        "# *********************************************************************************************    \n",
        "    count_1 = count_1 + 1\n",
        "# *********************************************************************************************\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmKdcNZllsOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0050738-423a-4be9-a522-6c2be235417d"
      },
      "source": [
        "import pprint\n",
        "pprint.pprint(cnty_lst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'Ada County': [{'Avg_Streamflow': '',\n",
            "                  'Data':      agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13206000 1992-01-01            141.0                A\n",
            "1      USGS  13206000 1992-01-02            139.0                A\n",
            "2      USGS  13206000 1992-01-03            139.0                A\n",
            "3      USGS  13206000 1992-01-04            140.0                A\n",
            "4      USGS  13206000 1992-01-05            141.0                A\n",
            "...     ...       ...        ...              ...              ...\n",
            "8761   USGS  13206000 2015-12-27            264.0                A\n",
            "8762   USGS  13206000 2015-12-28            268.0                A\n",
            "8763   USGS  13206000 2015-12-29            269.0                A\n",
            "8764   USGS  13206000 2015-12-30            269.0                A\n",
            "8765   USGS  13206000 2015-12-31            266.0                A\n",
            "\n",
            "[8766 rows x 5 columns],\n",
            "                  'File_Name': '13206000.txt',\n",
            "                  'Prcnt_Below_Avg': '',\n",
            "                  'Station_Nmbr': '13206000',\n",
            "                  'df_Name': '13206000_df'},\n",
            "                 {'Avg_Streamflow': '',\n",
            "                  'Data':      agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13206305 1999-11-01            150.0              A:e\n",
            "1      USGS  13206305 1999-11-02            140.0              A:e\n",
            "2      USGS  13206305 1999-11-03            140.0              A:e\n",
            "3      USGS  13206305 1999-11-04            150.0              A:e\n",
            "4      USGS  13206305 1999-11-05            150.0              A:e\n",
            "...     ...       ...        ...              ...              ...\n",
            "5900   USGS  13206305 2015-12-27            233.0                A\n",
            "5901   USGS  13206305 2015-12-28            238.0                A\n",
            "5902   USGS  13206305 2015-12-29            236.0                A\n",
            "5903   USGS  13206305 2015-12-30            234.0                A\n",
            "5904   USGS  13206305 2015-12-31            234.0                A\n",
            "\n",
            "[5905 rows x 5 columns],\n",
            "                  'File_Name': '13206305.txt',\n",
            "                  'Prcnt_Below_Avg': '',\n",
            "                  'Station_Nmbr': '13206305',\n",
            "                  'df_Name': '13206305_df'},\n",
            "                 {'Avg_Streamflow': '',\n",
            "                  'Data':     agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0     USGS  13206400 2010-07-09             38.0                A\n",
            "1     USGS  13206400 2010-07-10             38.4                A\n",
            "2     USGS  13206400 2010-07-11             37.9                A\n",
            "3     USGS  13206400 2010-07-12             37.3                A\n",
            "4     USGS  13206400 2010-07-13             37.5                A\n",
            "..     ...       ...        ...              ...              ...\n",
            "810   USGS  13206400 2012-09-26             38.9                A\n",
            "811   USGS  13206400 2012-09-27             40.0                A\n",
            "812   USGS  13206400 2012-09-28             40.0                A\n",
            "813   USGS  13206400 2012-09-29             40.7                A\n",
            "814   USGS  13206400 2012-09-30             39.3                A\n",
            "\n",
            "[815 rows x 5 columns],\n",
            "                  'File_Name': '13206400.txt',\n",
            "                  'Prcnt_Below_Avg': '',\n",
            "                  'Station_Nmbr': '13206400',\n",
            "                  'df_Name': '13206400_df'}]},\n",
            " {'Bannock County': [{'Avg_Streamflow': '',\n",
            "                      'Data':      agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13073000 1992-01-01            120.0                A\n",
            "1      USGS  13073000 1992-01-02            119.0                A\n",
            "2      USGS  13073000 1992-01-03            118.0                A\n",
            "3      USGS  13073000 1992-01-04            123.0                A\n",
            "4      USGS  13073000 1992-01-05            123.0                A\n",
            "...     ...       ...        ...              ...              ...\n",
            "8761   USGS  13073000 2015-12-27             92.5                A\n",
            "8762   USGS  13073000 2015-12-28             96.9                A\n",
            "8763   USGS  13073000 2015-12-29             98.7                A\n",
            "8764   USGS  13073000 2015-12-30             99.3                A\n",
            "8765   USGS  13073000 2015-12-31             84.8              A:e\n",
            "\n",
            "[8766 rows x 5 columns],\n",
            "                      'File_Name': '13073000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13073000',\n",
            "                      'df_Name': '13073000_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data':      agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13075000 1992-01-01             55.0                A\n",
            "1      USGS  13075000 1992-01-02             54.0                A\n",
            "2      USGS  13075000 1992-01-03             54.0                A\n",
            "3      USGS  13075000 1992-01-04             55.0                A\n",
            "4      USGS  13075000 1992-01-05             55.0                A\n",
            "...     ...       ...        ...              ...              ...\n",
            "8761   USGS  13075000 2015-12-27             38.9                A\n",
            "8762   USGS  13075000 2015-12-28             38.2                A\n",
            "8763   USGS  13075000 2015-12-29             37.4                A\n",
            "8764   USGS  13075000 2015-12-30             37.5                A\n",
            "8765   USGS  13075000 2015-12-31             33.1                A\n",
            "\n",
            "[8766 rows x 5 columns],\n",
            "                      'File_Name': '13075000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13075000',\n",
            "                      'df_Name': '13075000_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data':      agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13075500 1992-01-01            194.0              A:e\n",
            "1      USGS  13075500 1992-01-02            188.0              A:e\n",
            "2      USGS  13075500 1992-01-03            186.0              A:e\n",
            "3      USGS  13075500 1992-01-04            200.0              A:e\n",
            "4      USGS  13075500 1992-01-05            194.0              A:e\n",
            "...     ...       ...        ...              ...              ...\n",
            "8761   USGS  13075500 2015-12-27            115.0              A:e\n",
            "8762   USGS  13075500 2015-12-28            125.0              A:e\n",
            "8763   USGS  13075500 2015-12-29            143.0              A:e\n",
            "8764   USGS  13075500 2015-12-30            161.0              A:e\n",
            "8765   USGS  13075500 2015-12-31            132.0              A:e\n",
            "\n",
            "[8766 rows x 5 columns],\n",
            "                      'File_Name': '13075500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13075500',\n",
            "                      'df_Name': '13075500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13075910.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13075910',\n",
            "                      'df_Name': '13075910_df'}]},\n",
            " {'Bear Lake County': [{'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '10039500.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '10039500',\n",
            "                        'df_Name': '10039500_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '10068500.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '10068500',\n",
            "                        'df_Name': '10068500_df'}]},\n",
            " {'Benewah County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '12414900.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '12414900',\n",
            "                      'df_Name': '12414900_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '12415070.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '12415070',\n",
            "                      'df_Name': '12415070_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '12415135.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '12415135',\n",
            "                      'df_Name': '12415135_df'}]},\n",
            " {'Bingham County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13060000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13060000',\n",
            "                      'df_Name': '13060000_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13062500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13062500',\n",
            "                      'df_Name': '13062500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13065500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13065500',\n",
            "                      'df_Name': '13065500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13066000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13066000',\n",
            "                      'df_Name': '13066000_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13068300.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13068300',\n",
            "                      'df_Name': '13068300_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13068495.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13068495',\n",
            "                      'df_Name': '13068495_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13068500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13068500',\n",
            "                      'df_Name': '13068500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13069500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13069500',\n",
            "                      'df_Name': '13069500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13075983.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13075983',\n",
            "                      'df_Name': '13075983_df'}]},\n",
            " {'Blaine County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13135500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13135500',\n",
            "                     'df_Name': '13135500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13135520.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13135520',\n",
            "                     'df_Name': '13135520_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13136550.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13136550',\n",
            "                     'df_Name': '13136550_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13137000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13137000',\n",
            "                     'df_Name': '13137000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13137500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13137500',\n",
            "                     'df_Name': '13137500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13138000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13138000',\n",
            "                     'df_Name': '13138000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13139510.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13139510',\n",
            "                     'df_Name': '13139510_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13140335.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13140335',\n",
            "                     'df_Name': '13140335_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13140800.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13140800',\n",
            "                     'df_Name': '13140800_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13142500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13142500',\n",
            "                     'df_Name': '13142500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13147900.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13147900',\n",
            "                     'df_Name': '13147900_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13148500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13148500',\n",
            "                     'df_Name': '13148500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13150430.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13150430',\n",
            "                     'df_Name': '13150430_df'}]},\n",
            " {'Boise County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13185000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13185000',\n",
            "                    'df_Name': '13185000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13200000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13200000',\n",
            "                    'df_Name': '13200000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13235000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13235000',\n",
            "                    'df_Name': '13235000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13237920.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13237920',\n",
            "                    'df_Name': '13237920_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13246000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13246000',\n",
            "                    'df_Name': '13246000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13247500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13247500',\n",
            "                    'df_Name': '13247500_df'}]},\n",
            " {'Bonner County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '12391950.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '12391950',\n",
            "                     'df_Name': '12391950_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '12392155.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '12392155',\n",
            "                     'df_Name': '12392155_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '12392300.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '12392300',\n",
            "                     'df_Name': '12392300_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '12393501.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '12393501',\n",
            "                     'df_Name': '12393501_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '12395000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '12395000',\n",
            "                     'df_Name': '12395000_df'}]},\n",
            " {'Bonneville County': [{'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13032500.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13032500',\n",
            "                         'df_Name': '13032500_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13037500.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13037500',\n",
            "                         'df_Name': '13037500_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13057132.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13057132',\n",
            "                         'df_Name': '13057132_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13057155.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13057155',\n",
            "                         'df_Name': '13057155_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13057500.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13057500',\n",
            "                         'df_Name': '13057500_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13057940.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13057940',\n",
            "                         'df_Name': '13057940_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13058000.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13058000',\n",
            "                         'df_Name': '13058000_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13058510.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13058510',\n",
            "                         'df_Name': '13058510_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13058520.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13058520',\n",
            "                         'df_Name': '13058520_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13058529.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13058529',\n",
            "                         'df_Name': '13058529_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13058530.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13058530',\n",
            "                         'df_Name': '13058530_df'}]},\n",
            " {'Boundary County': [{'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12306500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12306500',\n",
            "                       'df_Name': '12306500_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12308000.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12308000',\n",
            "                       'df_Name': '12308000_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12308500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12308500',\n",
            "                       'df_Name': '12308500_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12309500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12309500',\n",
            "                       'df_Name': '12309500_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12310100.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12310100',\n",
            "                       'df_Name': '12310100_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12318500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12318500',\n",
            "                       'df_Name': '12318500_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12321500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12321500',\n",
            "                       'df_Name': '12321500_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12322000.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12322000',\n",
            "                       'df_Name': '12322000_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12322001.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12322001',\n",
            "                       'df_Name': '12322001_df'}]},\n",
            " {'Butte County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13118700.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13118700',\n",
            "                    'df_Name': '13118700_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13118975.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13118975',\n",
            "                    'df_Name': '13118975_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13119000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13119000',\n",
            "                    'df_Name': '13119000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132100.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132100',\n",
            "                    'df_Name': '13132100_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132373.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132373',\n",
            "                    'df_Name': '13132373_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132500',\n",
            "                    'df_Name': '13132500_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132513.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132513',\n",
            "                    'df_Name': '13132513_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132520.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132520',\n",
            "                    'df_Name': '13132520_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132535.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132535',\n",
            "                    'df_Name': '13132535_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13132565.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13132565',\n",
            "                    'df_Name': '13132565_df'}]},\n",
            " {'Camas County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13141500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13141500',\n",
            "                    'df_Name': '13141500_df'}]},\n",
            " {'Canyon County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13210810.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13210810',\n",
            "                     'df_Name': '13210810_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13210824.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13210824',\n",
            "                     'df_Name': '13210824_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13210831.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13210831',\n",
            "                     'df_Name': '13210831_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13210980.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13210980',\n",
            "                     'df_Name': '13210980_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13210986.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13210986',\n",
            "                     'df_Name': '13210986_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '132109867.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '132109867',\n",
            "                     'df_Name': '132109867_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13211205.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13211205',\n",
            "                     'df_Name': '13211205_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13212549.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13212549',\n",
            "                     'df_Name': '13212549_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13213000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13213000',\n",
            "                     'df_Name': '13213000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13213100.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13213100',\n",
            "                     'df_Name': '13213100_df'}]},\n",
            " {'Caribou County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13057300.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13057300',\n",
            "                      'df_Name': '13057300_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13063000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13063000',\n",
            "                      'df_Name': '13063000_df'}]},\n",
            " {'Cassia County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13078000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13078000',\n",
            "                     'df_Name': '13078000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13079300.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13079300',\n",
            "                     'df_Name': '13079300_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13082500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13082500',\n",
            "                     'df_Name': '13082500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13083000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13083000',\n",
            "                     'df_Name': '13083000_df'}]},\n",
            " {'Clark County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13116500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13116500',\n",
            "                    'df_Name': '13116500_df'}]},\n",
            " {'Clearwater County': [{'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13340000.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13340000',\n",
            "                         'df_Name': '13340000_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13340600.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13340600',\n",
            "                         'df_Name': '13340600_df'}]},\n",
            " {'Custer County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13120000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13120000',\n",
            "                     'df_Name': '13120000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13120500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13120500',\n",
            "                     'df_Name': '13120500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13122000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13122000',\n",
            "                     'df_Name': '13122000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13124265.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13124265',\n",
            "                     'df_Name': '13124265_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13127000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13127000',\n",
            "                     'df_Name': '13127000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13128900.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13128900',\n",
            "                     'df_Name': '13128900_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13295000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13295000',\n",
            "                     'df_Name': '13295000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13296000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13296000',\n",
            "                     'df_Name': '13296000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13296500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13296500',\n",
            "                     'df_Name': '13296500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13297330.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13297330',\n",
            "                     'df_Name': '13297330_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13297355.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13297355',\n",
            "                     'df_Name': '13297355_df'}]},\n",
            " {'Elmore County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13154500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13154500',\n",
            "                     'df_Name': '13154500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13159800.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13159800',\n",
            "                     'df_Name': '13159800_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13186000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13186000',\n",
            "                     'df_Name': '13186000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13190500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13190500',\n",
            "                     'df_Name': '13190500_df'}]},\n",
            " {'Franklin County': [{'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '10092700.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '10092700',\n",
            "                       'df_Name': '10092700_df'}]},\n",
            " {'Fremont County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13039500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13039500',\n",
            "                      'df_Name': '13039500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13042500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13042500',\n",
            "                      'df_Name': '13042500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13046000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13046000',\n",
            "                      'df_Name': '13046000_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13046995.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13046995',\n",
            "                      'df_Name': '13046995_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13047500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13047500',\n",
            "                      'df_Name': '13047500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13047600.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13047600',\n",
            "                      'df_Name': '13047600_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13049500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13049500',\n",
            "                      'df_Name': '13049500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13050500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13050500',\n",
            "                      'df_Name': '13050500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13055000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13055000',\n",
            "                      'df_Name': '13055000_df'}]},\n",
            " {'Gem County': [{'Avg_Streamflow': '',\n",
            "                  'Data': '',\n",
            "                  'File_Name': '13249500.txt',\n",
            "                  'Prcnt_Below_Avg': '',\n",
            "                  'Station_Nmbr': '13249500',\n",
            "                  'df_Name': '13249500_df'},\n",
            "                 {'Avg_Streamflow': '',\n",
            "                  'Data': '',\n",
            "                  'File_Name': '13250000.txt',\n",
            "                  'Prcnt_Below_Avg': '',\n",
            "                  'Station_Nmbr': '13250000',\n",
            "                  'df_Name': '13250000_df'}]},\n",
            " {'Gooding County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13095175.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13095175',\n",
            "                      'df_Name': '13095175_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13095500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13095500',\n",
            "                      'df_Name': '13095500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13152500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13152500',\n",
            "                      'df_Name': '13152500_df'}]},\n",
            " {'Idaho County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13316500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13316500',\n",
            "                    'df_Name': '13316500_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13317000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13317000',\n",
            "                    'df_Name': '13317000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13336500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13336500',\n",
            "                    'df_Name': '13336500_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13337000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13337000',\n",
            "                    'df_Name': '13337000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13337500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13337500',\n",
            "                    'df_Name': '13337500_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13338500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13338500',\n",
            "                    'df_Name': '13338500_df'}]},\n",
            " {'Jefferson County': [{'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13038000.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13038000',\n",
            "                        'df_Name': '13038000_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13038500.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13038500',\n",
            "                        'df_Name': '13038500_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13112000.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13112000',\n",
            "                        'df_Name': '13112000_df'}]},\n",
            " {'Jerome County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13089500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13089500',\n",
            "                     'df_Name': '13089500_df'}]},\n",
            " {'Kootenai County': [{'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413500',\n",
            "                       'df_Name': '12413500_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413860.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413860',\n",
            "                       'df_Name': '12413860_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12417650.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12417650',\n",
            "                       'df_Name': '12417650_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12419000.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12419000',\n",
            "                       'df_Name': '12419000_df'}]},\n",
            " {'Latah County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13345000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13345000',\n",
            "                    'df_Name': '13345000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13346800.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13346800',\n",
            "                    'df_Name': '13346800_df'}]},\n",
            " {'Lemhi County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13302005.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13302005',\n",
            "                    'df_Name': '13302005_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13302500.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13302500',\n",
            "                    'df_Name': '13302500_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13305000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13305000',\n",
            "                    'df_Name': '13305000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13305310.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13305310',\n",
            "                    'df_Name': '13305310_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13306370.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13306370',\n",
            "                    'df_Name': '13306370_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13306385.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13306385',\n",
            "                    'df_Name': '13306385_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13307000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13307000',\n",
            "                    'df_Name': '13307000_df'},\n",
            "                   {'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13310199.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13310199',\n",
            "                    'df_Name': '13310199_df'}]},\n",
            " {'Lewis County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13338950.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13338950',\n",
            "                    'df_Name': '13338950_df'}]},\n",
            " {'Madison County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13055250.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13055250',\n",
            "                      'df_Name': '13055250_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13055340.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13055340',\n",
            "                      'df_Name': '13055340_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13056500.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13056500',\n",
            "                      'df_Name': '13056500_df'},\n",
            "                     {'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13057000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13057000',\n",
            "                      'df_Name': '13057000_df'}]},\n",
            " {'Minidoka County': [{'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '13081500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '13081500',\n",
            "                       'df_Name': '13081500_df'}]},\n",
            " {'Nez Perce County': [{'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13317660.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13317660',\n",
            "                        'df_Name': '13317660_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13341050.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13341050',\n",
            "                        'df_Name': '13341050_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13341140.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13341140',\n",
            "                        'df_Name': '13341140_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13341570.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13341570',\n",
            "                        'df_Name': '13341570_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13342450.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13342450',\n",
            "                        'df_Name': '13342450_df'},\n",
            "                       {'Avg_Streamflow': '',\n",
            "                        'Data': '',\n",
            "                        'File_Name': '13342500.txt',\n",
            "                        'Prcnt_Below_Avg': '',\n",
            "                        'Station_Nmbr': '13342500',\n",
            "                        'df_Name': '13342500_df'}]},\n",
            " {'Owyhee County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13168500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13168500',\n",
            "                     'df_Name': '13168500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13176400.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13176400',\n",
            "                     'df_Name': '13176400_df'}]},\n",
            " {'Payette County': [{'Avg_Streamflow': '',\n",
            "                      'Data': '',\n",
            "                      'File_Name': '13251000.txt',\n",
            "                      'Prcnt_Below_Avg': '',\n",
            "                      'Station_Nmbr': '13251000',\n",
            "                      'df_Name': '13251000_df'}]},\n",
            " {'Power County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13077000.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13077000',\n",
            "                    'df_Name': '13077000_df'}]},\n",
            " {'Shoshone County': [{'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12411000.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12411000',\n",
            "                       'df_Name': '12411000_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413000.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413000',\n",
            "                       'df_Name': '12413000_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413125.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413125',\n",
            "                       'df_Name': '12413125_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413130.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413130',\n",
            "                       'df_Name': '12413130_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413131.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413131',\n",
            "                       'df_Name': '12413131_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413210.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413210',\n",
            "                       'df_Name': '12413210_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413355.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413355',\n",
            "                       'df_Name': '12413355_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12413875.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12413875',\n",
            "                       'df_Name': '12413875_df'},\n",
            "                      {'Avg_Streamflow': '',\n",
            "                       'Data': '',\n",
            "                       'File_Name': '12414500.txt',\n",
            "                       'Prcnt_Below_Avg': '',\n",
            "                       'Station_Nmbr': '12414500',\n",
            "                       'df_Name': '12414500_df'}]},\n",
            " {'Teton County': [{'Avg_Streamflow': '',\n",
            "                    'Data': '',\n",
            "                    'File_Name': '13052200.txt',\n",
            "                    'Prcnt_Below_Avg': '',\n",
            "                    'Station_Nmbr': '13052200',\n",
            "                    'df_Name': '13052200_df'}]},\n",
            " {'Twin Falls County': [{'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13087505.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13087505',\n",
            "                         'df_Name': '13087505_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13087995.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13087995',\n",
            "                         'df_Name': '13087995_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13090500.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13090500',\n",
            "                         'df_Name': '13090500_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13092747.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13092747',\n",
            "                         'df_Name': '13092747_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13094000.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13094000',\n",
            "                         'df_Name': '13094000_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13108150.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13108150',\n",
            "                         'df_Name': '13108150_df'}]},\n",
            " {'Valley County': [{'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13236500.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13236500',\n",
            "                     'df_Name': '13236500_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13239000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13239000',\n",
            "                     'df_Name': '13239000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13240000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13240000',\n",
            "                     'df_Name': '13240000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13309220.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13309220',\n",
            "                     'df_Name': '13309220_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13310700.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13310700',\n",
            "                     'df_Name': '13310700_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13310800.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13310800',\n",
            "                     'df_Name': '13310800_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13310850.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13310850',\n",
            "                     'df_Name': '13310850_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13311000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13311000',\n",
            "                     'df_Name': '13311000_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13311250.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13311250',\n",
            "                     'df_Name': '13311250_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13311450.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13311450',\n",
            "                     'df_Name': '13311450_df'},\n",
            "                    {'Avg_Streamflow': '',\n",
            "                     'Data': '',\n",
            "                     'File_Name': '13313000.txt',\n",
            "                     'Prcnt_Below_Avg': '',\n",
            "                     'Station_Nmbr': '13313000',\n",
            "                     'df_Name': '13313000_df'}]},\n",
            " {'Washington County': [{'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13258500.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13258500',\n",
            "                         'df_Name': '13258500_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13265500.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13265500',\n",
            "                         'df_Name': '13265500_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13266000.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13266000',\n",
            "                         'df_Name': '13266000_df'},\n",
            "                        {'Avg_Streamflow': '',\n",
            "                         'Data': '',\n",
            "                         'File_Name': '13269000.txt',\n",
            "                         'Prcnt_Below_Avg': '',\n",
            "                         'Station_Nmbr': '13269000',\n",
            "                         'df_Name': '13269000_df'}]},\n",
            " {'Flathead County, Montana': [{'Avg_Streamflow': '',\n",
            "                                'Data': '',\n",
            "                                'File_Name': '12355347.txt',\n",
            "                                'Prcnt_Below_Avg': '',\n",
            "                                'Station_Nmbr': '12355347',\n",
            "                                'df_Name': '12355347_df'}]},\n",
            " {'Lincoln County, Montana': [{'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12301250.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12301250',\n",
            "                               'df_Name': '12301250_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12301933.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12301933',\n",
            "                               'df_Name': '12301933_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12302055.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12302055',\n",
            "                               'df_Name': '12302055_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12304500.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12304500',\n",
            "                               'df_Name': '12304500_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12305000.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12305000',\n",
            "                               'df_Name': '12305000_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '480608115242901.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '480608115242901',\n",
            "                               'df_Name': '480608115242901_df'}]},\n",
            " {'Sanders County, Montana': [{'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12389500.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12389500',\n",
            "                               'df_Name': '12389500_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '12390700.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '12390700',\n",
            "                               'df_Name': '12390700_df'}]},\n",
            " {'Elko County, Nevada': [{'Avg_Streamflow': '',\n",
            "                           'Data': '',\n",
            "                           'File_Name': '13105000.txt',\n",
            "                           'Prcnt_Below_Avg': '',\n",
            "                           'Station_Nmbr': '13105000',\n",
            "                           'df_Name': '13105000_df'},\n",
            "                          {'Avg_Streamflow': '',\n",
            "                           'Data': '',\n",
            "                           'File_Name': '13161500.txt',\n",
            "                           'Prcnt_Below_Avg': '',\n",
            "                           'Station_Nmbr': '13161500',\n",
            "                           'df_Name': '13161500_df'},\n",
            "                          {'Avg_Streamflow': '',\n",
            "                           'Data': '',\n",
            "                           'File_Name': '13162225.txt',\n",
            "                           'Prcnt_Below_Avg': '',\n",
            "                           'Station_Nmbr': '13162225',\n",
            "                           'df_Name': '13162225_df'}]},\n",
            " {'Harney County, Oregon': [{'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '10396000.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '10396000',\n",
            "                             'df_Name': '10396000_df'}]},\n",
            " {'Malheur County, Oregon': [{'Avg_Streamflow': '',\n",
            "                              'Data': '',\n",
            "                              'File_Name': '13181000.txt',\n",
            "                              'Prcnt_Below_Avg': '',\n",
            "                              'Station_Nmbr': '13181000',\n",
            "                              'df_Name': '13181000_df'},\n",
            "                             {'Avg_Streamflow': '',\n",
            "                              'Data': '',\n",
            "                              'File_Name': '13183000.txt',\n",
            "                              'Prcnt_Below_Avg': '',\n",
            "                              'Station_Nmbr': '13183000',\n",
            "                              'df_Name': '13183000_df'},\n",
            "                             {'Avg_Streamflow': '',\n",
            "                              'Data': '',\n",
            "                              'File_Name': '13233300.txt',\n",
            "                              'Prcnt_Below_Avg': '',\n",
            "                              'Station_Nmbr': '13233300',\n",
            "                              'df_Name': '13233300_df'}]},\n",
            " {'Wallowa County, Oregon': [{'Avg_Streamflow': '',\n",
            "                              'Data': '',\n",
            "                              'File_Name': '13333000.txt',\n",
            "                              'Prcnt_Below_Avg': '',\n",
            "                              'Station_Nmbr': '13333000',\n",
            "                              'df_Name': '13333000_df'}]},\n",
            " {'Asotin County, Washington': [{'Avg_Streamflow': '',\n",
            "                                 'Data': '',\n",
            "                                 'File_Name': '13334300.txt',\n",
            "                                 'Prcnt_Below_Avg': '',\n",
            "                                 'Station_Nmbr': '13334300',\n",
            "                                 'df_Name': '13334300_df'}]},\n",
            " {'Lincoln County, Wyoming': [{'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '13022500.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '13022500',\n",
            "                               'df_Name': '13022500_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '13023000.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '13023000',\n",
            "                               'df_Name': '13023000_df'},\n",
            "                              {'Avg_Streamflow': '',\n",
            "                               'Data': '',\n",
            "                               'File_Name': '13027500.txt',\n",
            "                               'Prcnt_Below_Avg': '',\n",
            "                               'Station_Nmbr': '13027500',\n",
            "                               'df_Name': '13027500_df'}]},\n",
            " {'Teton County, Wyoming': [{'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13010065.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13010065',\n",
            "                             'df_Name': '13010065_df'},\n",
            "                            {'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13011000.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13011000',\n",
            "                             'df_Name': '13011000_df'},\n",
            "                            {'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13011500.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13011500',\n",
            "                             'df_Name': '13011500_df'},\n",
            "                            {'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13011900.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13011900',\n",
            "                             'df_Name': '13011900_df'},\n",
            "                            {'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13013650.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13013650',\n",
            "                             'df_Name': '13013650_df'},\n",
            "                            {'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13015000.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13015000',\n",
            "                             'df_Name': '13015000_df'},\n",
            "                            {'Avg_Streamflow': '',\n",
            "                             'Data': '',\n",
            "                             'File_Name': '13018750.txt',\n",
            "                             'Prcnt_Below_Avg': '',\n",
            "                             'Station_Nmbr': '13018750',\n",
            "                             'df_Name': '13018750_df'}]}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SKPoXFD_lsOz"
      },
      "source": [
        "# statn_lst\n",
        "# cnty_lst = {cnty_nm: statn_lst}\n",
        "# cnty_lst[0][0].append(input_fle_dict)\n",
        "# cnty_lst[0][1].append(\"test\")\n",
        "# pprint.pprint(cnty_lst)\n",
        "# print(\"********************************************************************\")\n",
        "# print(new_dict)\n",
        "# print(statn_lst)\n",
        "pprint.pprint(cnty_lst[0])\n",
        "# pprint.pprint(cnty_lst[50])\n",
        "print(\"********************************************************************\")\n",
        "pprint.pprint(cnty_lst[0][\"Ada County\"])\n",
        "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"])\n",
        "print(\"********************************************************************\")\n",
        "pprint.pprint(cnty_lst[0][\"Ada County\"][0])\n",
        "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0])\n",
        "print(\"********************************************************************\")\n",
        "pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Station_Nmbr\"])\n",
        "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])\n",
        "print(\"********************************************************************\")\n",
        "pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Data\"][\"date\"])\n",
        "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyThqrXZlsOz"
      },
      "source": [
        "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
        "\n",
        "print(cnty_lst[0].keys())\n",
        "print(\"********************************************************************\")\n",
        "print(cnty_lst[0][\"Ada County\"][0].keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSJ4wVkZlsOz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b56bLM_plsOz"
      },
      "source": [
        "#### def find(name, path):\n",
        "for root, dirs, files in os.walk(input_fle_path):\n",
        "    if \"13073000.txt\" in files:\n",
        "        print (os.path.join(root, \"13073000.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnEsYqIhlsOz"
      },
      "source": [
        "def find_all(\"13073000.txt\", input_fle_path):\n",
        "    result = []\n",
        "    for root, dirs, files in os.walk(input_fle_path):\n",
        "        if name in files:\n",
        "            result.append(os.path.join(root, name))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6EQIpiLHlsO0"
      },
      "source": [
        "# How to Ignore Hidden Files\n",
        "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
        "\n",
        "# # *********************************************************************************************\n",
        "# # Create a List of the Files in the Directory\n",
        "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
        "# # *********************************************************************************************\n",
        "\n",
        "# Create a List to Store/Save the Streamflow Data, Data will be Saved as a List of Dictionaries\n",
        "statn_data_lst_of_dicts = []\n",
        "input_fle_dict = {}\n",
        "\n",
        "\n",
        "\n",
        "# # *********************************************************************************************\n",
        "# Put the Station in a list by County Name\n",
        "# First Find the station in the county  \n",
        "\n",
        "if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
        "    print(\"No County\")\n",
        "# # *********************************************************************************************\n",
        "\n",
        "\n",
        "\n",
        "for input_fle_nm in os.listdir(input_fle_path):\n",
        "# Skip the Hidden Files in the Directory\n",
        "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
        "# # *********************************************************************************************\n",
        "# #         Append to the File Names to the Directory\n",
        "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
        "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
        "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
        "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
        "# #         print(input_fle_nm)\n",
        "# # *********************************************************************************************\n",
        "\n",
        "\n",
        "        input_fle_dict = {\"Station_Nmbr\": input_fle_nm[:-4], \n",
        "                          \"File_Name\": input_fle_nm, \n",
        "                          \"df_Name\": \"_\" + input_fle_nm[:-4] + \"_df\", \n",
        "                          \"Data\": \"\", \n",
        "                          \"Avg_Streamflow\": \"\",\n",
        "                          \"Prcnt_Below_Avg\": \"\"}\n",
        "\n",
        "# Append to the File Names to the Directory\n",
        "    statn_data_lst_of_dicts.append(dict(input_fle_dict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "gXPtxKRQlsO0"
      },
      "source": [
        "# https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
        "\n",
        "statn_data_lst_of_dicts\n",
        "# del statn_data_lst_of_dicts[0]\n",
        "# statn_data_lst_of_dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ksr7wsmlsO0"
      },
      "source": [
        "statn_data_lst_of_dicts[1]['Station_Nmbr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtzio0IhlsO0"
      },
      "source": [
        "# for i, station in enumerate(dict_nm[key]):\n",
        "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
        "    print(statn_data_lst_of_dicts[i]['File_Name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QVDf1A4lsO0"
      },
      "source": [
        "county = list(a_dict.keys())\n",
        "type(county)\n",
        "county[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0fnwIjSlsO0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwId4st5lsO0"
      },
      "source": [
        "a_series = pd.Series(data = [0,1,2,3,4], index = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"])\n",
        "a_series\n",
        "statn_data_lst_of_dicts\n",
        "a_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfxshwmwlsO0"
      },
      "source": [
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r63lBCBflsO1"
      },
      "source": [
        "pprint.pprint(cnty_lst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KE-vg2VvlsO1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed083c24-5ea7-4118-897f-09264a601386"
      },
      "source": [
        "# References:\n",
        "#     - Break a Loop:\n",
        "#         - https://www.programiz.com/python-programming/break-continue\n",
        "\n",
        "# for i, station in enumerate(dict_nm[key]):\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                           Step 1 Loop Through Each County \n",
        "# *********************************************************************************************\n",
        "\n",
        "statns_wth_no_strmflw_data = []\n",
        "\n",
        "for i, county_dict in enumerate(cnty_lst):\n",
        "    print(f\"Index No: {i}\")\n",
        "# Get dictionary keys as a list\n",
        "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
        "    county_lst = list(county_dict.keys())\n",
        "    county = county_lst[0]\n",
        "    print(f\"County: {county}\")\n",
        "#     print(f\"Stations:\")\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                    Step 2 Loop Through Each Station Within a County\n",
        "# *********************************************************************************************\n",
        "# \n",
        "    for station_dict in county_dict[county]:\n",
        "        station_lst_keys = list(station_dict.keys())\n",
        "        station_lst_File_Name = station_lst_keys[1]\n",
        "        station_lst_data = station_lst_keys[3]\n",
        "#         print(station_lst_keys)\n",
        "#         print(station_lst_File_Name)\n",
        "#         print(station_lst)\n",
        "        print(f\"Stations:{station_dict[station_lst_File_Name]}\")\n",
        "#     pprint.pprint(a_dict[county])\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                   Step 3 - Create the File Path for the Stream Data\n",
        "# *********************************************************************************************\n",
        "\n",
        "# Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
        "        input_fle_path_fr_lp = \"/content/gdrive/My Drive/Colab_Notebooks/USGS_Idaho_Water_Watch_Data/\" + station_dict[station_lst_File_Name]\n",
        "        # print(f\"File Path: {input_fle_path_fr_lp}\")\n",
        "        # print(\"----------------------------------------------------\")\n",
        "        \n",
        "# Create the Dataframe to Store the Streamflow Data from the .txt File\n",
        "        df = pd.DataFrame(columns = clmn_nms)\n",
        "\n",
        "# *********************************************************************************************\n",
        "#             Step 4 - Loop Through the .txt File and Store the Data into a Dataframe\n",
        "# *********************************************************************************************\n",
        "\n",
        "# Loop Through the .txt File and Store the Data into a Dataframe\n",
        "        with open(input_fle_path_fr_lp,'r') as fh:\n",
        "            # print(fh)\n",
        "            # print(\"----------------------------------------------------\")\n",
        "            for curline in dropwhile(is_comment, fh):\n",
        "#                 print(f\"Curline:\")\n",
        "#                 print(type(curline))\n",
        "#                 print(\"----------------------------------------------------\")\n",
        "    #         print(f\"Index Number: {count} {curline}\")\n",
        "    #         count = count + 1\n",
        "\n",
        "    # Split a String\n",
        "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
        "    # Pandas Series\n",
        "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
        "                to_append = curline[:-1].split(\"\\t\")\n",
        "                # print(f\"To Append: {to_append}\")\n",
        "#                 print(to_append)\n",
        "# #                 print(to_append[4])\n",
        "#                 print(\"----------------------------------------------------\")\n",
        "                \n",
        "                if len(to_append) == 5:\n",
        "#                     print(\"True\")\n",
        "            \n",
        "                    a_series = pd.Series(data = to_append, index = clmn_nms)\n",
        "#                     print(clmn_nms)\n",
        "                    # print(f\"Series: {a_series}\")\n",
        "#                     print(a_series)\n",
        "                    # print(\"----------------------------------------------------\")\n",
        "                    \n",
        "                        #             Dataframe\n",
        "    #             Dataframe Name\n",
        "#                     statn_nm = input_fle_nm[:-4]\n",
        "\n",
        "    #             Append Data to the Dataframe\n",
        "                    df= df.append(a_series, ignore_index=True)\n",
        "\n",
        "                    \n",
        "            \n",
        "                elif len(to_append) < 5:\n",
        "                    statns_wth_no_strmflw_data.append(station_dict[station_lst_File_Name])\n",
        "                    break\n",
        "#                     print(f\"Station {station_dict[station_lst_File_Name]} Does not \")\n",
        "                    \n",
        "#     #             Dataframe\n",
        "#     #             Dataframe Name\n",
        "#                 statn_nm = input_fle_nm[:-4]\n",
        "            # print(df)\n",
        "        if len(df) != 0:\n",
        "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
        "            df = df.drop(index = [0, 1])\n",
        "# Reset the Index so that it Starts with 0\n",
        "            df = df.reset_index(drop = True)\n",
        "# Change the Data Types of Each Column\n",
        "            for row in df[\"streamflow_rate\"]:\n",
        "              if isfloat(row) == False:\n",
        "                print(row)\n",
        "#             # df = df.astype(convert_dict)\n",
        "# # Change the Date Column to a datetime Data Type\n",
        "#             df['date']= pd.to_datetime(df['date'])\n",
        "\n",
        "# # Calculate the Averge Streamflow Rate for the Station\n",
        "#             avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
        "# #     avg_strmflw = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_mean\"]\n",
        "#             # print(f\"Average Streamflow: {avg_strmflw}\")\n",
        "    \n",
        "# #     #             Append Data to the Dataframe           \n",
        "# #             print(df)\n",
        "#             station_dict[station_lst_data] = df\n",
        "#             # print(f\"Data:{station_dict[station_lst_data]}\")\n",
        "#             # print(\"----------------------------------------------------\")\n",
        "            \n",
        "    print(\"********************************************************************\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index No: 0\n",
            "County: Ada County\n",
            "Stations:13206000.txt\n",
            "Stations:13206305.txt\n",
            "Stations:13206400.txt\n",
            "********************************************************************\n",
            "Index No: 1\n",
            "County: Bannock County\n",
            "Stations:13073000.txt\n",
            "Stations:13075000.txt\n",
            "Stations:13075500.txt\n",
            "Stations:13075910.txt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "********************************************************************\n",
            "Index No: 2\n",
            "County: Bear Lake County\n",
            "Stations:10039500.txt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Stations:10068500.txt\n",
            "********************************************************************\n",
            "Index No: 3\n",
            "County: Benewah County\n",
            "Stations:12414900.txt\n",
            "Stations:12415070.txt\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Stations:12415135.txt\n",
            "********************************************************************\n",
            "Index No: 4\n",
            "County: Bingham County\n",
            "Stations:13060000.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-e2c44df04802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m#             Append Data to the Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7749\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7750\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7751\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7752\u001b[0m         )\n\u001b[1;32m   7753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5232\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5236\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5203\u001b[0m         \"\"\"\n\u001b[1;32m   5204\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5205\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5213\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5214\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         merged_blocks = _merge_blocks(\n\u001b[0;32m-> 1909\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m         )\n\u001b[1;32m   1911\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1934\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1935\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "qEwlikWZscZN",
        "outputId": "594c4978-9d34-4a6c-c18f-18ceff261ea2"
      },
      "source": [
        "# =============================================================================================================================\n",
        "                          # Trying to Fix The VALUE ERROR MESSAGE: Cannot Convert to String to Float\n",
        "# =============================================================================================================================\n",
        "\n",
        "\n",
        "# pprint.pprint(cnty_lst[1][\"Bannock County\"][3])\n",
        "# pprint.pprint(cnty_lst[1][\"Bannock County\"][3][\"File_Name\"])\n",
        "# print(\"---------------------------------------------------------------------------\")\n",
        "\n",
        "station_File_Name = \"13075910.txt\"\n",
        "\n",
        "input_fle_path_fr_lp = \"/content/gdrive/My Drive/Colab_Notebooks/USGS_Idaho_Water_Watch_Data/\" + station_File_Name\n",
        "# print(f\"File Path: {input_fle_path_fr_lp}\")\n",
        "\n",
        "with open(input_fle_path_fr_lp,'r') as fh:\n",
        "  # print(fh)\n",
        "  # print(\"----------------------------------------------------\")\n",
        "  for curline in dropwhile(is_comment, fh):\n",
        "    # print(f\"Curline: {curline}\")\n",
        "    # print(type(curline))\n",
        "    # print(\"----------------------------------------------------\")\n",
        "    # print(f\"Index Number: {count} {curline}\")\n",
        "\n",
        "    to_append = curline[:-1].split(\"\\t\")\n",
        "    # print(f\"To Append: {to_append}\")\n",
        "#                 print(to_append)\n",
        "# #                 print(to_append[4])\n",
        "    # print(\"----------------------------------------------------\")\n",
        "\n",
        "\n",
        "    if len(to_append) == 5:\n",
        "      # print(\"True\")\n",
        "      # print(\"----------------------------------------------------\")\n",
        "\n",
        "      a_series = pd.Series(data = to_append, index = clmn_nms)\n",
        "#                     print(clmn_nms)\n",
        "#                     print(\"Series:\")\n",
        "#                     print(a_series)\n",
        "#                     print(\"----------------------------------------------------\")\n",
        "    \n",
        "        #             Dataframe\n",
        "#             Dataframe Name\n",
        "#                     statn_nm = input_fle_nm[:-4]\n",
        "\n",
        "#             Append Data to the Dataframe\n",
        "      df = df.append(a_series, ignore_index=True)\n",
        "\n",
        "    \n",
        "\n",
        "    elif len(to_append) < 5:\n",
        "      print(\"FALSE\")\n",
        "      print(f\"To Append: {to_append}\")\n",
        "      print(\"----------------------------------------------------\")\n",
        "      statns_wth_no_strmflw_data.append(station_dict[station_lst_File_Name])\n",
        "      break\n",
        "#                     print(f\"Station {station_dict[station_lst_File_Name]} Does not \")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>agency</th>\n",
              "      <th>site_nmbr</th>\n",
              "      <th>date</th>\n",
              "      <th>streamflow_rate</th>\n",
              "      <th>approved/pending</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>1992-01-01</td>\n",
              "      <td>478</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>1992-01-02</td>\n",
              "      <td>474</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>1992-01-03</td>\n",
              "      <td>468</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>1992-01-04</td>\n",
              "      <td>468</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>1992-01-05</td>\n",
              "      <td>475</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26297</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>2015-12-27</td>\n",
              "      <td>298</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26298</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>2015-12-28</td>\n",
              "      <td>355</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26299</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>2015-12-29</td>\n",
              "      <td>376</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26300</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>2015-12-30</td>\n",
              "      <td>387</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26301</th>\n",
              "      <td>USGS</td>\n",
              "      <td>13075910</td>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>355</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26302 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      agency site_nmbr        date streamflow_rate approved/pending\n",
              "0       USGS  13075910  1992-01-01             478                A\n",
              "1       USGS  13075910  1992-01-02             474                A\n",
              "2       USGS  13075910  1992-01-03             468                A\n",
              "3       USGS  13075910  1992-01-04             468                A\n",
              "4       USGS  13075910  1992-01-05             475                A\n",
              "...      ...       ...         ...             ...              ...\n",
              "26297   USGS  13075910  2015-12-27             298                A\n",
              "26298   USGS  13075910  2015-12-28             355                A\n",
              "26299   USGS  13075910  2015-12-29             376                A\n",
              "26300   USGS  13075910  2015-12-30             387                A\n",
              "26301   USGS  13075910  2015-12-31             355                A\n",
              "\n",
              "[26302 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "nZNKwBQQFqHT",
        "outputId": "f2e6b02a-60e3-41f0-cd59-5fe7f62dfebd"
      },
      "source": [
        "print(df.dtypes)\n",
        "df = df.astype(convert_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "agency              object\n",
            "site_nmbr           object\n",
            "date                object\n",
            "streamflow_rate     object\n",
            "approved/pending    object\n",
            "dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-b98834d3345e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5531\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5532\u001b[0m                     results.append(\n\u001b[0;32m-> 5533\u001b[0;31m                         \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5534\u001b[0m                     )\n\u001b[1;32m   5535\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5549\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     ) -> \"BlockManager\":\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     def convert(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L71hGVr929iv",
        "outputId": "bad3cc6a-5e02-4ee8-a4c2-aa9f6ca79b18"
      },
      "source": [
        "# =============================================================================================================================\n",
        "                          # Trying to Fix The VALUE ERROR MESSAGE: Cannot Convert to String to Float\n",
        "# =============================================================================================================================\n",
        "\n",
        "# Reference:\n",
        "#   - Checking if a string can be converted to float in Python\n",
        "#     - https://stackoverflow.com/questions/736043/checking-if-a-string-can-be-converted-to-float-in-python\n",
        "\n",
        "\n",
        "\n",
        "# df.applymap(np.isreal)\n",
        "# print(df.dtypes)\n",
        "# # type(df)\n",
        "# df = df.astype(convert_dict)\n",
        "# print(df.dtypes)\n",
        "\n",
        "def isfloat(value):\n",
        "  try:\n",
        "    float(value)\n",
        "    return True\n",
        "  except ValueError:\n",
        "    return False\n",
        "\n",
        "# row = \"4\"\n",
        "\n",
        "# isfloat(row)\n",
        "\n",
        "for row in df[\"streamflow_rate\"]:\n",
        "  if isfloat(row) == False:\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lJUK-u-PlsO1"
      },
      "source": [
        "statns_wth_no_strmflw_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "6nsEbvJ0lsO2"
      },
      "source": [
        "type(cnty_lst[0][\"Ada County\"][1][\"Data\"])\n",
        "cnty_lst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSSBIw0ulsO2"
      },
      "source": [
        "def division_exception_handeling(divisor, dividend):\n",
        "    try:\n",
        "        return divisor/dividend\n",
        "    except ZeroDivisionError:\n",
        "        return 0\n",
        "\n",
        "\n",
        "# number1 = 0\n",
        "# number2 = 0\n",
        "division_exception_handeling(5, 10)\n",
        "# self.divided = self.number1/(self.number2 or not self.number2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Jqj2N5DxlsO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fad5f7cc-0d22-4951-b543-b6b70d4385c7"
      },
      "source": [
        "# Refernces:\n",
        "#     - Get a list of dates between two dates\n",
        "#         - https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-50.php\n",
        "#     - Check if a variable is string\n",
        "#         - https://www.geeksforgeeks.org/python-check-if-a-variable-is-string/\n",
        "\n",
        "# This is Converting the Date String into a Datetime Data Type\n",
        "bgn_date_datetime = datetime.datetime.strptime(bgn_date, '%Y-%m-%d')\n",
        "end_date_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
        "\n",
        "# Create Dataframe for the county and each day\n",
        "# cnty_date_df = pd.DataFrame()\n",
        "\n",
        "def daterange(date1, date2):\n",
        "    for n in range(int ((date2 - date1).days)+1):\n",
        "        yield date1 + timedelta(n)\n",
        "\n",
        "# print(type(end_dt_datetime ))\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                                 Step 1 Loop Through Each Date\n",
        "# *********************************************************************************************\n",
        "\n",
        "for dt in daterange(bgn_date_datetime, end_date_datetime):\n",
        "    srch_date = dt.strftime(\"%Y-%m-%d\")\n",
        "#     print(type(dt))\n",
        "# This is Converting the Datetime Data Type into a String Data Type\n",
        "    print(dt.strftime(\"%Y-%m-%d\")) # This is a String\n",
        "    dly_strmflw_ttl = 0\n",
        "\n",
        "# Create the Dataframe to Store the Streamflow Data from the .txt File\n",
        "    srch_day_df = pd.DataFrame()\n",
        "#     cnty_date_df[srch_date] = \"\"\n",
        "    cnty_date_df[srch_date + \"_ttl_strmflw\"] = \"\"\n",
        "    cnty_date_df[srch_date + \"_cnty_prcnt_blw_extndd_avg\"] = \"\"\n",
        "    cnty_date_df[srch_date + \"wghtd__prcnt_blw_extndd_avg\"] = \"\" \n",
        "#     date_cnty_df_clmn_headr_nms.append(srch_date)\n",
        "#     date_cnty_df_rows\n",
        "    \n",
        "    \n",
        "# *********************************************************************************************\n",
        "#                               Step 2 Loop Through Each County\n",
        "# *********************************************************************************************\n",
        "    for i, county_dict in enumerate(cnty_lst):\n",
        "        print(f\"County Index No: {i}\")\n",
        "    \n",
        "    # Get dictionary keys as a list\n",
        "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
        "        county_lst = list(county_dict.keys())\n",
        "        county = county_lst[0]\n",
        "        \n",
        "        print(f\"County List Keys: {county_lst}\")\n",
        "        print(f\"County: {county}\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "        print(\"----------------------------------------------------\")\n",
        "        cnty_dly_strmflw_ttl = 0\n",
        "        nmbr_strms_blw_extndd_yrs_median = 0\n",
        "        ttl_nmbr_statns = 0\n",
        "        cnty_strms_prcnt_blw_extndd_avg = 0\n",
        "        ttl_nmbr_statns_with_data = 0\n",
        "        \n",
        "\n",
        "\n",
        "    \n",
        "# *********************************************************************************************\n",
        "#                    Step 2 Loop Through Each Station Within a County\n",
        "# *********************************************************************************************\n",
        "\n",
        "        for x, station_dict in enumerate(county_dict[county]):\n",
        "            station_lst_keys = list(station_dict.keys())\n",
        "            station_lst_statn_Name = station_lst_keys[0]\n",
        "            station_lst_data = station_lst_keys[3]\n",
        "#             print(station_lst_keys)\n",
        "#       print(station_lst_File_Name)\n",
        "#             print(station_lst)\n",
        "            print(f\"Stations:{station_dict[station_lst_statn_Name]}\")\n",
        "            df = station_dict[station_lst_data]\n",
        "#             print(type(df))\n",
        "#             pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Data\"][\"date\"])\n",
        "            data_df = cnty_lst[i][county][x][\"Data\"]\n",
        "            print(f\"Data:{data_df}\")\n",
        "#             print(f\"Data:{df}\")\n",
        "\n",
        "            ttl_nmbr_statns = ttl_nmbr_statns + 1\n",
        "\n",
        "# If the DataFrame is a String Data Type, Which Means it's Empty\n",
        "            if isinstance(data_df, str): \n",
        "                print(f\"This Station has no Data!\")\n",
        "                continue\n",
        "\n",
        "            elif not isinstance(data_df, str):\n",
        "                ttl_nmbr_statns_with_data = ttl_nmbr_statns_with_data + 1\n",
        "# Find the Index for the Date \n",
        "                test_indx_lbl = data_df[data_df[\"date\"] == srch_date].index.tolist()\n",
        "                print(f\"Date Index: {test_indx_lbl}\")\n",
        "# Use the Index for????\n",
        "                found_date = data_df[\"date\"][test_indx_lbl]\n",
        "                print(f\"Found Date: {test_indx_lbl}\")\n",
        "# Collect the Daily Streamflow Average\n",
        "                daily_strmflw_avg = data_df[\"streamflow_rate\"].values[test_indx_lbl]\n",
        "# Create a List of the Current Days Streamflow\n",
        "                print(f\"First: {daily_strmflw_avg}\")\n",
        "# Convert the List of the Current Days Streamflow to an Integer\n",
        "                daily_strmflw_avg = daily_strmflw_avg[0]\n",
        "                print(f\"Second: {daily_strmflw_avg}\")\n",
        "        \n",
        "                print(f\"Index: {test_indx_lbl}\")\n",
        "            \n",
        "# Add this Station's Streamflow Data to the County's Total Streamflow Data for the Particular Date           \n",
        "                cnty_dly_strmflw_ttl = cnty_dly_strmflw_ttl + daily_strmflw_avg\n",
        "                \n",
        "                print(f\"Date: {found_date}\")\n",
        "                print(f\"Station's Daily Streamflow Average: {daily_strmflw_avg}\")\n",
        "                print(type(daily_strmflw_avg))\n",
        "                print(\"----------------------------------------------------\")\n",
        "\n",
        "# Find the Index Number for the Current Station in the \"statn_table_df_splt_StatnNmbr_test\" Dataframe\n",
        "                statn_indx_lbl = statn_table_df_splt_StatnNmbr_test[statn_table_df_splt_StatnNmbr_test[\"numbers\"] == station_dict[station_lst_statn_Name]].index.tolist()\n",
        "# Find the Extended Years Medain in the \"statn_table_df_splt_StatnNmbr_test\" Dataframe\n",
        "                extndd_yrs_median_array = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_median\"].values[statn_indx_lbl]\n",
        "# Convert the Series into an Integer\n",
        "                extndd_yrs_median = extndd_yrs_median_array[0]\n",
        "                print(type(statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_median\"][statn_indx_lbl]))\n",
        "                print(f\"Extended Years Median: {extndd_yrs_median}\")\n",
        "#                 print(type(extndd_yrs_median))\n",
        "                print(\"----------------------------------------------------\")\n",
        "            \n",
        "# Is the Stream's Daily Streamflow on the Particular Date Below that Stream's Extended Streamflow Average \n",
        "                if daily_strmflw_avg < extndd_yrs_median:\n",
        "                    print(f\"{daily_strmflw_avg} < {extndd_yrs_median}\")\n",
        "                    nmbr_strms_blw_extndd_yrs_median = nmbr_strms_blw_extndd_yrs_median + 1\n",
        "                    print(f\"Streams Below Extended Average: {nmbr_strms_blw_extndd_yrs_median}\")\n",
        "        \n",
        "        print(\"====================================================\")\n",
        "        print(f\"{county} Daily Streamflow Average: {cnty_dly_strmflw_ttl}\")\n",
        "        dly_strmflw_ttl = dly_strmflw_ttl + cnty_dly_strmflw_ttl\n",
        "        print(f\"Total Number of Stations With Data: {ttl_nmbr_statns_with_data}\")\n",
        "        print(f\"Total Number of Stations Below Extended Average: {nmbr_strms_blw_extndd_yrs_median}\")\n",
        "        print(\"====================================================\")\n",
        "        \n",
        "# Add the Total Number of Stations and Total Number of Stations Who's Daily Streamflow Average\n",
        "# was Below the Extended Streamflow Average. County Daily Streamflow Create a dataframe with the county and each day\n",
        "#         I need total Streamflow amount and percent of streams below extended average\n",
        "\n",
        "        # Find the Index for the Date \n",
        "        cnty_date_df_indx_lbl = cnty_date_df[cnty_date_df[\"idaho_counties\"] == county].index.tolist()\n",
        "        \n",
        "        cnty_date_df[srch_date + \"_ttl_strmflw\"][cnty_date_df_indx_lbl] = cnty_dly_strmflw_ttl\n",
        "#         cnty_strms_prcnt_blw_extndd_avg = nmbr_strms_blw_extndd_yrs_median / ttl_nmbr_statns\n",
        "        cnty_strms_prcnt_blw_extndd_avg = division_exception_handeling(nmbr_strms_blw_extndd_yrs_median, ttl_nmbr_statns_with_data) * 100\n",
        "\n",
        "        print(\"****************************************************\")\n",
        "        print(f\"Precent Below Extended Average: {cnty_strms_prcnt_blw_extndd_avg}\")\n",
        "        print(\"****************************************************\")\n",
        "        cnty_date_df[srch_date + \"_cnty_prcnt_blw_extndd_avg\"][cnty_date_df_indx_lbl] = cnty_strms_prcnt_blw_extndd_avg \n",
        "        \n",
        "        \n",
        "    print(\"====================================================\")\n",
        "    print(f\"{srch_date} Daily Streamflow Average: {dly_strmflw_ttl}\")\n",
        "    print(\"====================================================\")\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "# # Create a dataframe with the county, each day, weighted average,\n",
        "# # Weighted Average\n",
        "#     print(\"====================================================\")\n",
        "#     wghtd_avg = cnty_dly_strmflw_ttl / dly_strmflw_ttl\n",
        "#     print(f\"{srch_date} Daily Streamflow Average: {dly_strmflw_ttl}\")\n",
        "#     print(\"====================================================\")\n",
        "#     print(\"********************************************************************\")\n",
        "                \n",
        "# #     pprint.pprint(a_dict[county])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1992-01-01\n",
            "County Index No: 0\n",
            "County List Keys: ['Ada County']\n",
            "County: Ada County\n",
            "----------------------------------------------------\n",
            "----------------------------------------------------\n",
            "Stations:13206000\n",
            "Data:     agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13206000 1992-01-01            141.0                A\n",
            "1      USGS  13206000 1992-01-02            139.0                A\n",
            "2      USGS  13206000 1992-01-03            139.0                A\n",
            "3      USGS  13206000 1992-01-04            140.0                A\n",
            "4      USGS  13206000 1992-01-05            141.0                A\n",
            "...     ...       ...        ...              ...              ...\n",
            "8761   USGS  13206000 2015-12-27            264.0                A\n",
            "8762   USGS  13206000 2015-12-28            268.0                A\n",
            "8763   USGS  13206000 2015-12-29            269.0                A\n",
            "8764   USGS  13206000 2015-12-30            269.0                A\n",
            "8765   USGS  13206000 2015-12-31            266.0                A\n",
            "\n",
            "[8766 rows x 5 columns]\n",
            "Date Index: [0]\n",
            "Found Date: [0]\n",
            "First: [141.]\n",
            "Second: 141.0\n",
            "Index: [0]\n",
            "Date: 0   1992-01-01\n",
            "Name: date, dtype: datetime64[ns]\n",
            "Station's Daily Streamflow Average: 141.0\n",
            "<class 'numpy.float64'>\n",
            "----------------------------------------------------\n",
            "<class 'pandas.core.series.Series'>\n",
            "Extended Years Median: 279.0\n",
            "----------------------------------------------------\n",
            "141.0 < 279.0\n",
            "Streams Below Extended Average: 1\n",
            "Stations:13206305\n",
            "Data:     agency site_nmbr       date  streamflow_rate approved/pending\n",
            "0      USGS  13206305 1999-11-01            150.0              A:e\n",
            "1      USGS  13206305 1999-11-02            140.0              A:e\n",
            "2      USGS  13206305 1999-11-03            140.0              A:e\n",
            "3      USGS  13206305 1999-11-04            150.0              A:e\n",
            "4      USGS  13206305 1999-11-05            150.0              A:e\n",
            "...     ...       ...        ...              ...              ...\n",
            "5900   USGS  13206305 2015-12-27            233.0                A\n",
            "5901   USGS  13206305 2015-12-28            238.0                A\n",
            "5902   USGS  13206305 2015-12-29            236.0                A\n",
            "5903   USGS  13206305 2015-12-30            234.0                A\n",
            "5904   USGS  13206305 2015-12-31            234.0                A\n",
            "\n",
            "[5905 rows x 5 columns]\n",
            "Date Index: []\n",
            "Found Date: []\n",
            "First: []\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c27a5ce270ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"First: {daily_strmflw_avg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# Convert the List of the Current Days Streamflow to an Integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mdaily_strmflw_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdaily_strmflw_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Second: {daily_strmflw_avg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "A2OcHAaTlsO6"
      },
      "source": [
        "statn_table_df_splt_StatnNmbr_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Y2Di1xRmlsO7"
      },
      "source": [
        "cnty_date_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8bZnEl5lsO7"
      },
      "source": [
        "substr = \"strmflw\"\n",
        "\n",
        "def string_contains_substring(string, substring):\n",
        "    return substring in string\n",
        "\n",
        "# string_contains_substring(\"1990-01-01_ttl_strmflw\", substr)  # Testing the function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnDwpkBslsO7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "R6V4ypwAlsO7"
      },
      "source": [
        "cnty_date_df_keys = cnty_date_df.keys()\n",
        "wghtd_avg_string = \"wghtd__prcnt_blw_extndd_avg\"\n",
        "cnty_prcnt_blw_extndd_avg_str = \"_cnty_prcnt_blw_extndd_avg\"\n",
        "ID_wildfire_ML_data = pd.DataFrame(columns = [\"date\", \"strms_blw_extndd_avg\"])\n",
        "\n",
        "for key in cnty_date_df_keys:\n",
        "    \n",
        "    if string_contains_substring(key, substr):\n",
        "# Create Variables\n",
        "        dly_wghtd_avg = 0\n",
        "    \n",
        "        date_sum = cnty_date_df[key].sum()\n",
        "        print(key)\n",
        "        print(date_sum)\n",
        "#         for x, station_dict in enumerate(county_dict[county]):\n",
        "        for row in cnty_date_df.index:\n",
        "# Craeting Strings\n",
        "            date = key[0:10]\n",
        "            wghted_avg_clmn_nm = date + wghtd_avg_string\n",
        "            cnty_prcnt_blw_extndd_avg_clmn_nm = date + cnty_prcnt_blw_extndd_avg_str\n",
        "            \n",
        "# Gathering Data from a Dataframe\n",
        "            cnty_prcnt_blw_extndd_avg = cnty_date_df[cnty_prcnt_blw_extndd_avg_clmn_nm][row]\n",
        "    \n",
        "# Calculations\n",
        "            wghtd_fctr = cnty_date_df[key][row] / date_sum\n",
        "            dly_wghtd_avg = dly_wghtd_avg + (cnty_prcnt_blw_extndd_avg * wghtd_fctr)\n",
        "            \n",
        "            \n",
        "            cnty_date_df[wghted_avg_clmn_nm][row] = wghtd_fctr\n",
        "            \n",
        "            print(key[0:10] + wghtd_avg_string)\n",
        "            print(cnty_date_df[\"idaho_counties\"][row])\n",
        "            print(cnty_date_df[key][row])\n",
        "            print(wghtd_fctr)\n",
        "            print(cnty_prcnt_blw_extndd_avg)\n",
        "            print(cnty_prcnt_blw_extndd_avg * wghtd_fctr)\n",
        "        \n",
        "# Add the Average Streamflow Data to the Final Dataframe \n",
        "        ID_wildfire_ML_data = ID_wildfire_ML_data.append({\"date\": date, \"strms_blw_extndd_avg\": dly_wghtd_avg}, ignore_index = True)\n",
        "\n",
        "        \n",
        "        print(\"********************************************************************\")\n",
        "        print(f\"{date} percent below extended average: {dly_wghtd_avg}\")\n",
        "        print(\"********************************************************************\")\n",
        "#             print(index)\n",
        "# cnty_date_sum_Series = cnty_date_df[\"1990-01-01_ttl_strmflw\"].sum()    # This is a Series\n",
        "# count1 = 1\n",
        "# cnty_date_sum_Series\n",
        "\n",
        "# for test in cnty_date_sum_Series:\n",
        "#     print(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "vJzAwtmelsO-"
      },
      "source": [
        "cnty_date_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1uq2tqdlsO-"
      },
      "source": [
        "cnty_date_df.sum()\n",
        "cnty_date_df[\"1990-01-30wghtd__prcnt_blw_extndd_avg\"].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qdkAdxrlsO-"
      },
      "source": [
        "ID_wildfire_ML_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJZNc00klsO-"
      },
      "source": [
        "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEWvFRFTlsO_"
      },
      "source": [
        "statn_data_lst[\"Station_Nmbr\"][0]\n",
        "# input_fle_dict[\"File_Name\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0fS6G9MlsO_"
      },
      "source": [
        "# for station in input_fle_dict[\"df_Name\"]:\n",
        "#     print(station)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHv0l195lsO_"
      },
      "source": [
        "input_fle_nm = input_fle_lst[0]\n",
        "input_fle_nm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S10kT8kTlsO_"
      },
      "source": [
        "# https://stackoverflow.com/questions/40482738/how-to-name-dataframe-with-variables-in-pandas\n",
        "\n",
        "N = 10 # 5 in sample\n",
        "dfs = {'name' + str(i):df for i in range(1,N)}\n",
        "print (dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn_qqE4clsO_"
      },
      "source": [
        "dfs[\"name2\"].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQlAn_8-lsO_"
      },
      "source": [
        "N = 10 # 5 in sample\n",
        "# for input_fle_nm in input_fle_lst:\n",
        "input_fle_nm =\"\"\n",
        "dfs = {input_fle_nm:df for input_fle_nm in input_fle_dict[\"df_Name\"]}\n",
        "# print (input_fle_nm)\n",
        "print (dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z67Ei6D4lsPA"
      },
      "source": [
        "statn_data_lst_of_dicts[2]['File_Name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ES7pUUY-lsPA"
      },
      "source": [
        "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
        "# *********************************************************************************************\n",
        "#                                   Step 1 Create Variables\n",
        "# *********************************************************************************************\n",
        "\n",
        "#     Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
        "    input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']\n",
        "\n",
        "#     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
        "    df = pd.DataFrame(columns = clmn_nms)\n",
        "#     print(df)\n",
        "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
        "# *********************************************************************************************\n",
        "\n",
        "# *********************************************************************************************\n",
        "#                           Step 2 Create a Dataframe for the Streamflow\n",
        "# *********************************************************************************************\n",
        "# Loop Through the .txt File and Store the Data into a Dataframe\n",
        "    with open(input_fle_path_fr_lp,'r') as fh:\n",
        "        for curline in dropwhile(is_comment, fh):\n",
        "#             print(curline)\n",
        "    #         print(f\"Index Number: {count} {curline}\")\n",
        "    #         count = count + 1\n",
        "\n",
        "\n",
        "\n",
        "    # Split a String\n",
        "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
        "    # Pandas Series\n",
        "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
        "            to_append = curline[:-1].split(\"\\t\")\n",
        "            a_series = pd.Series(to_append, index = clmn_nms)\n",
        "            print(a_series)\n",
        "            print(\"********************************************************************\")\n",
        "    #             Dataframe\n",
        "    #             Dataframe Name\n",
        "            statn_nm = input_fle_nm[:-4]\n",
        "\n",
        "    #             Append Data to the Dataframe\n",
        "            df= df.append(a_series, ignore_index=True)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     print(input_fle_nm)\n",
        "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
        "    df = df.drop(index = [0, 1])\n",
        "# Reset the Index so that it Starts with 0\n",
        "    df = df.reset_index(drop = True)\n",
        "# Change the Data Types of Each Column\n",
        "    df = df.astype(convert_dict) \n",
        "# Change the Date Column to a datetime Data Type\n",
        "    df['date']= pd.to_datetime(df['date'])\n",
        "    \n",
        "    avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
        "#     avg_strmflw = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_mean\"]\n",
        "    print(f\"Average Streamflow: {avg_strmflw}\")\n",
        "#     print(df[\"streamflow_rate\"])\n",
        "#     print(\"********************************************************************\")\n",
        "    print (df)\n",
        "    \n",
        "    count = 0\n",
        "    print(len(df))\n",
        "    \n",
        "    for i_df in range(len(df)):\n",
        "#         print (df[\"streamflow_rate\"][2])\n",
        "        print (df[\"streamflow_rate\"][i_df])\n",
        "#         print (df_row)\n",
        "        if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
        "            count = count + 1\n",
        "            \n",
        "            print (\"True\")\n",
        "        elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
        "            print (\"False\")\n",
        "        print(\"********************************************************************\")\n",
        "        print(\"********************************************************************\")\n",
        "\n",
        "    pct_blw_avg = (count / len(df) * 100)\n",
        "    print (pct_blw_avg)\n",
        "# Add a value into an empty dictionay element\n",
        "#     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
        "    statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
        "    statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
        "    statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
        "#     input_fle_dict[\"Data\"].append(df)\n",
        "\n",
        "    # df_nm = df_nm.drop(index = [0, 1])\n",
        "    # \"_\" + statn_nm + \"_df\" = df\n",
        "    # df_nm\n",
        "    # df\n",
        "    # df.drop(index = [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4lDLH3lsPA"
      },
      "source": [
        "Next Step, take the total number of streams that are below its 38 year average and create a\n",
        "precent of that per day (calculate a percent by county then a total precent for the state (Use \n",
        "weighted averaging for the county and for the state, so that bigger streams have more weight in the\n",
        "precent)). This will tell us how many streams are below average per day and we can relate that to \n",
        "how many fires were reported that day and how many lightning strikes occured that day."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MwHQU9yKlsPA"
      },
      "source": [
        "statn_data_lst_of_dicts\n",
        "# statn_data_lst_of_dicts[0]\n",
        "# statn_data_lst_of_dicts[0][\"Data\"]\n",
        "\n",
        "# data_df = statn_data_lst_of_dicts[0][\"Data\"]\n",
        "# data_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "W52nAvQHlsPA"
      },
      "source": [
        "# Refernces:\n",
        "#     - Get a list of dates between two dates\n",
        "#         - https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-50.php\n",
        "\n",
        "\n",
        "bgn_date_datetime = datetime.datetime.strptime(bgn_date, '%Y-%m-%d')\n",
        "end_date_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
        "\n",
        "def daterange(date1, date2):\n",
        "    for n in range(int ((date2 - date1).days)+1):\n",
        "        yield date1 + timedelta(n)\n",
        "\n",
        "start_dt = date(2015, 12, 20)\n",
        "end_dt = date(2016, 1, 11)\n",
        "# print(type(end_dt_datetime ))\n",
        "\n",
        "for dt in daterange(bgn_date_datetime, end_date_datetime):\n",
        "    \n",
        "    print(dt.strftime(\"%Y-%m-%d\")) # This is a String\n",
        "#     print(type(dt.strftime(\"%Y-%m-%d\")))\n",
        "\n",
        "        # Find the Index for the Station  \n",
        "#     test_indx_lbl = data_df[data_df[\"date\"] == dt].index.tolist()\n",
        "\n",
        "#     print(f'Index No: {test_indx_lbl[0]}')\n",
        "#     print(f'Streamflow Rate: {data_df[\"streamflow_rate\"][test_indx_lbl[0]]}')\n",
        "#     print(\"********************************************************************\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4svhfpflsPA"
      },
      "source": [
        "# Find the Index for the Station  \n",
        "test_indx_lbl = data_df[data_df[\"date\"] == \"1990-01-05\"].index.tolist()\n",
        "\n",
        "print(f'Index No: {test_indx_lbl[0]}')\n",
        "print(f'Streamflow Rate: {data_df[\"streamflow_rate\"][test_indx_lbl[0]]}')\n",
        "\n",
        "\n",
        "\n",
        "# To Do:\n",
        "#     - Create a dataframe with the date, county name, total streamflow, average streamflow, weighted \n",
        "#         percent\n",
        "#     - Count how many Stations have a recorded streamflow for that day\n",
        "#         - Make and if statement: If the data exist then count_total else skip that station and go \n",
        "#             to the next station\n",
        "#         - If the data exist then sum the amount of water flowing in the streams for each county\n",
        "#             - Weighted precent for each stream per day\n",
        "#             - Use the count_county and weighted_average_percent to create a streamflow weighted \n",
        "#                 average per county (weighted average is how many county streams are below it's\n",
        "#                 extended average)\n",
        "#             - Add the streamflow rate to the state streamflow\n",
        "#             - Create streamflow weighted average for the state of Idaho using the county streamflow\n",
        "#                 (weighted average is how many county streams are below it's extended average)\n",
        "#             - Append the streamflow weighted average to the new dataframe\n",
        "#                  - The dataframe would include the date, streamflow weighted average, lightning\n",
        "#                      strikes, average prcp, average temp., average humdity, dew point, number of \n",
        "#                      camping permits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_ZxfuUVlsPB"
      },
      "source": [
        "# print(\"_\" + input_fle_nm + \"_df\")\n",
        "# test = \"_\" + input_fle_nm\n",
        "# test[:-4]\n",
        "# input_fle_dict[\"df_Name\"]\n",
        "# _13073000_df.head()\n",
        "# _13206000_df.drop(index = [0, 1])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LCxNp-V7lsPB"
      },
      "source": [
        "input_fle_dict[\"Data\"][0].append(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuIMO_wmlsPB"
      },
      "source": [
        "input_fle_dict[\"Data\"][0].dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0cEJ1jilsPB"
      },
      "source": [
        "index = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw4m71d6lsPB"
      },
      "source": [
        "input_fle_dict['Station_Nmbr'][index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVZ7M7ZplsPB"
      },
      "source": [
        "input_fle_dict[\"Data\"][index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNvOxkLslsPB"
      },
      "source": [
        "# @@@@@@@@@@@@@@@@@@@@@@@"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ULtD3g4AlsPB"
      },
      "source": [
        "from itertools import dropwhile\n",
        "\n",
        "input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
        "\n",
        "count = 0 \n",
        "\n",
        "with open(input_fle_path,'r') as fh:\n",
        "    for curline in dropwhile(is_comment, fh):\n",
        "        print(f\"Index Number: {count} {curline}\")\n",
        "        count = count + 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWci6zdlsPB"
      },
      "source": [
        "curline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUAEs-OHlsPC"
      },
      "source": [
        "# Create Dataframe for the Data\n",
        "\n",
        "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]\n",
        "\n",
        "_13206000_df = pd.DataFrame(columns = clmn_nms)\n",
        "\n",
        "_13206000_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBKrisW0lsPC"
      },
      "source": [
        "# Split a String\n",
        "#     - https://www.geeksforgeeks.org/python-string-split/\n",
        "# Pandas Series\n",
        "#     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
        "\n",
        "print(type(curline))\n",
        "print(curline)\n",
        "print((curline.split(\"\\t\")))\n",
        "print(type(curline.split(\"\\t\")))\n",
        "\n",
        "to_append = curline[:-1].split(\"\\t\")\n",
        "a_series = pd.Series(to_append, index = clmn_nms)\n",
        "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
        "_13206000_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gh_lQx8lsPC"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM5rz1fRlsPC"
      },
      "source": [
        "# Step 3 - Get the Lighting Data from the National Centers for Enviromental Information (NCEI) National Oceanic and Atmospheric Administration (NOAA) Severe Weather Data Inventory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqxKXDjolsPC"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PM1B3Y9lsPC"
      },
      "source": [
        "## Scrape a webpage and create a BeautifulSoup object from the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dw_2v3UlsPC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoxgehaolsPD"
      },
      "source": [
        "# 3.1 Create the Webdriver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BR3g8RblsPD"
      },
      "source": [
        "# from selenium import webdriver\n",
        "# from selenium.webdriver.support.ui import Select\n",
        "\n",
        "url = \"https://www.ncdc.noaa.gov/severe-weather/severe-weather-data-inventory\"\n",
        "\n",
        "driver = webdriver.Chrome()\n",
        "driver.get(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04ep_lUjlsPD"
      },
      "source": [
        "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
        "# https://selenium-python.readthedocs.io/locating-elements.html\n",
        "\n",
        "driver.find_element_by_xpath(\"//*[contains(text(), 'Map Search')]\").click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHcFeerolsPD"
      },
      "source": [
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "year = \"2001\"\n",
        "\n",
        "\n",
        "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//input[@class='esri-input esri-search__input'])[1]\"))).send_keys(\"Idaho, USA\")\n",
        "# time.sleep(5)\n",
        "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='esri-search__submit-button esri-widget--button'])[1]\"))).click()\n",
        "# time.sleep(10)\n",
        "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()\n",
        "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='custom-select swdi-select']/option[text()=\" + dataset + \"])\"))).click()\n",
        "\n",
        "# # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "# driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()=\" + year + \"]\").click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZaJzMFYlsPE"
      },
      "source": [
        "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nac8ShzMlsPF"
      },
      "source": [
        "# References:\n",
        "#     - Get All the Options in the Dropdown List:\n",
        "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
        "#     - Remove a List of Unwanted Characters from a String:\n",
        "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
        "\n",
        "\n",
        "yrs_lghtnng_strks = [\"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]\n",
        "dataset = \"Lightning Strikes\"\n",
        "\n",
        "lghtnng_strks_df = pd.DataFrame()\n",
        "bad_chars = ['(', 'events)']\n",
        "\n",
        "for yr in yrs_lghtnng_strks:\n",
        "    WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + yr + \"])\"))).click()\n",
        "    \n",
        "    time.sleep(5)\n",
        "    \n",
        "    select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
        "    select.select_by_visible_text(dataset)    \n",
        "    \n",
        "    time.sleep(15)\n",
        "    \n",
        "    lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
        "    options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
        "    \n",
        "    for element in options:\n",
        "#     print (element.get_attribute(\"text\"))\n",
        "        text = element.get_attribute(\"text\")\n",
        "\n",
        "        count = 1\n",
        "    \n",
        "        for i in bad_chars:\n",
        "            text = text.replace(i, \"\")\n",
        "            \n",
        "            if count == 2:\n",
        "                text = text.replace(i, \"\")\n",
        "#                 print (text.split())\n",
        "#                 print (text.split()[0])\n",
        "#                 print (text.split()[1])\n",
        "#                 print (\"**************************\")\n",
        "                count = 0\n",
        "\n",
        "                lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
        "                                                            \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
        "\n",
        "            count = 1 + count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcCeC6xilsPG"
      },
      "source": [
        "options"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7JbU91XlsPG"
      },
      "source": [
        "test_df = lghtnng_strks_df\n",
        "test_df.dtypes\n",
        "# test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Swyi-I15lsPH"
      },
      "source": [
        "# How many seconds of phone calls are recorded in total?\n",
        "# print(test_df['number_of_strikes'].sum())\n",
        "# test_df\n",
        "\n",
        "# test_df.groupby(['month']).groups.keys()\n",
        "\n",
        "# test_df.groupby([test_df[\"date\"].dt.month]).sum().reset_index()\n",
        "\n",
        "\n",
        "# Split the String into Just the Year-Month:\n",
        "#     - https://stackoverflow.com/questions/26646191/pandas-groupby-month-and-year\n",
        "\n",
        "def getYearMonth(s):\n",
        "  return s.split(\"-\")[0]+\"-\"+s.split(\"-\")[1]\n",
        "\n",
        "test_df['YearMonth']= test_df['date'].apply(lambda x: getYearMonth(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8ru_V4wlsPH"
      },
      "source": [
        "print(test_df.dtypes)\n",
        "\n",
        "# Change the Date Column to a datetime Data Type\n",
        "test_df['date']= pd.to_datetime(test_df['date'])\n",
        "# or\n",
        "# test_df.astype({'date': 'datetime64'})\n",
        "\n",
        "# Change the \"number_of_strikes\" Column to an Integer (\"int32\") Data Type\n",
        "test_df = test_df.astype({'number_of_strikes': 'int32'})\n",
        "print(\"*******************************************\")\n",
        "print(test_df.dtypes)\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EgidgPJKlsPH"
      },
      "source": [
        "test_YearMonth_df = test_df.groupby(\"YearMonth\")[\"number_of_strikes\"].sum()\n",
        "test_YearMonth_df = pd.DataFrame(test_YearMonth_df)\n",
        "test_YearMonth_df = test_YearMonth_df.reset_index()\n",
        "test_YearMonth_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZZAtfvllsPI"
      },
      "source": [
        "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect'])\"))).click()\n",
        "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect']/option[text()=\" + dataset + \"])\"))).click()\n",
        "# driver.find_element_by_xpath(\"//select[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
        "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
        "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']\").click()\n",
        "\n",
        "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
        "\n",
        "select.select_by_visible_text(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXmhHXAPlsPI"
      },
      "source": [
        "test_YearMonth_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBbTxyDblsPI"
      },
      "source": [
        "# References:\n",
        "#     Shading an area between two points in a matplotlib plot:\n",
        "#         - https://stackoverflow.com/questions/3681872/shading-an-area-between-two-points-in-a-matplotlib-plot\n",
        "\n",
        "\n",
        "x_axis = np.arange(len(test_YearMonth_df))\n",
        "\n",
        "plt.figure(figsize = (25,20))\n",
        "plt.bar(x_axis, test_YearMonth_df[\"number_of_strikes\"])\n",
        "plt.xticks(x_axis, test_YearMonth_df[\"YearMonth\"], rotation = \"vertical\")\n",
        "plt.hlines(10,0,92, alpha = 1, color = \"red\")\n",
        "plt.axvspan(0, 3, color='y', alpha=0.4, lw=0) # Highlighting the 1992 Lightning Strikes\n",
        "plt.axvspan(4, 8, color='g', alpha=0.4, lw=0) # Highlighting the 1993 Lightning Strikes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpNX32QolsPI"
      },
      "source": [
        "# # https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
        "\n",
        "# lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
        "\n",
        "# options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
        "\n",
        "# print(options)\n",
        "\n",
        "# for element in options:\n",
        "#     print (element.get_attribute(\"text\").split(\" \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlry6xeGlsPJ"
      },
      "source": [
        "# References:\n",
        "#     - Get All the Options in the Dropdown List:\n",
        "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
        "#     - Remove a List of Unwanted Characters from a String:\n",
        "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
        "\n",
        "lghtnng_strks_df = pd.DataFrame()\n",
        "\n",
        "lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
        "\n",
        "options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
        "\n",
        "bad_chars = ['(', 'events)']\n",
        "\n",
        "for element in options:\n",
        "#     print (element.get_attribute(\"text\"))\n",
        "    text = element.get_attribute(\"text\")\n",
        "    \n",
        "    count = 1\n",
        "    \n",
        "    for i in bad_chars:\n",
        "        text = text.replace(i, \"\")\n",
        "        \n",
        "        if count == 2:\n",
        "            text = text.replace(i, \"\")\n",
        "            print (text.split())\n",
        "            print (text.split()[0])\n",
        "            print (text.split()[1])\n",
        "            print (\"**************************\")\n",
        "            count = 0\n",
        "            \n",
        "            lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
        "                                                        \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
        "            \n",
        "        count = 1 + count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAuqHgIJlsPJ"
      },
      "source": [
        "lghtnng_strks_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5Fr7zEElsPJ"
      },
      "source": [
        "def select_dropdown_value(year):\n",
        "    # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "    driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()='2001']\").click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SAcU9MialsPJ"
      },
      "source": [
        "# https://pythonspot.com/selenium-textbox/\n",
        "\n",
        "text_area = driver.find_element_by_class_name('esri-input esri-search__input')\n",
        "text_area.send_keys(\"This text is send using Python code.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZefnLS7vlsPJ"
      },
      "source": [
        "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
        "\n",
        "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNg-cJ4ElsPJ"
      },
      "source": [
        "# Press/Click a Button Without an ID\n",
        "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
        "\n",
        "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
        "\n",
        "button = driver.find_element_by_xpath(lst_all_statns)\n",
        "button.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW_Xc95JlsPK"
      },
      "source": [
        "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "\n",
        "select = Select(driver.find_element_by_id('select_display'))\n",
        "\n",
        "# Select by visible text\n",
        "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
        "\n",
        "# Select by value text\n",
        "select.select_by_value('dailystagedischarge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQZXiyszlsPK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0eYvYqTlsPK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSISZG8ClsPK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7S6_VMxlsPK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTFGB8JZlsPK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sJDZVGIlsPK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25anZT6NlsPK"
      },
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atg3W8-zlsPK"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6it9KqYklsPK"
      },
      "source": [
        "# Step 3 - Get the Mean Streamflow Rate for Each Station"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px38LvyHlsPL"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "606LDWV_lsPL"
      },
      "source": [
        "## Scrape a webpage and create a BeautifulSoup object from the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-F2r8BplsPL"
      },
      "source": [
        "## 3.1 USGS' Science for a Changing World"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4lFFxcRlsPL"
      },
      "source": [
        "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
        "\n",
        "input_fle_dict[\"Data\"][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqsE4TOjlsPL"
      },
      "source": [
        "# input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)\n",
        "statn_data_lst_of_dicts[0][\"Data\"][\"streamflow_rate\"].mean(axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iLVP0kTlsPL"
      },
      "source": [
        "input_fle_dict[\"Station_Nmbr\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Up2FtslsPL"
      },
      "source": [
        "# Find the index of a dictionary within a list (I modified this codes since my dictionary isn't in a list)\n",
        "#     - https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value\n",
        "\n",
        "def find_avg (lst, key, value):\n",
        "    for i, a_dict_2 in enumerate(lst):\n",
        "        print(a_dict_2[key])\n",
        "    #         print(input_fle_dict[\"Station_Nmbr\"])\n",
        "    #         print(\"********************************************************************\")\n",
        "#         if a_dict_2[key] == value:    \n",
        "#         if station == value:\n",
        "#             print(i)\n",
        "    \n",
        "                \n",
        "    \n",
        "#             avg_strmflw_rte = dict_nm[\"Data\"][i][\"streamflow_rate\"].mean(axis = 0)\n",
        "#             dict_nm[\"Avg_Streamflow\"][i].append(avg_strmflw_rte )\n",
        "\n",
        "#             avg_strmflw = lst[i][\"Data\"][\"streamflow_rate\"].mean(axis = 0)\n",
        "#             lst[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
        "        \n",
        "#             return i # avg_strmflw_rte\n",
        "    #             print(\"********************************************************************\")\n",
        "        return -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWpd4tjKlsPL"
      },
      "source": [
        "input_fle_dict[\"Station_Nmbr\"][0].append(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-IntgIPylsPL"
      },
      "source": [
        "find_avg(statn_data_lst_of_dicts, \"Station_Nmbr\", \"13206000\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hoEsXk9HlsPL"
      },
      "source": [
        "lst = [{'id':'1234','name':'Jason'}, {'id':'2345','name':'Tom'}, {'id':'3456','name':'Art'}]\n",
        "\n",
        "tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None)\n",
        "tom_index\n",
        "\n",
        "# tom_index = next((index for (index, d) in enumerate(input_fle_dict) if d[\"Station_Nmbr\"] == 13075910), None)\n",
        "# print(tom_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE6oRnZAlsPL"
      },
      "source": [
        "types1 = [type(k) for k in input_fle_dict[\"Station_Nmbr\"]]\n",
        "types1\n",
        "# type(13075000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UugGmVIPlsPL"
      },
      "source": [
        "dicts = [{'id':'1234','name':'Jason'},\n",
        "         {'id':'2345','name':'Tom'},\n",
        "         {'id':'3456','name':'Art'}]\n",
        "\n",
        "def find_index(dicts, key, value):\n",
        "    class Null: pass\n",
        "    for i, d in enumerate(dicts):\n",
        "        if d.get(key, Null) == value:\n",
        "            return d\n",
        "    else:\n",
        "        raise ValueError('no dict with the key and value combination found')\n",
        "\n",
        "print (find_index(dicts, 'name', 'Tom'))\n",
        "# 1\n",
        "# find_index(dicts, 'name', 'Ensnare')\n",
        "# ValueError: no dict with the key and value combination found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4hzerOUlsPL"
      },
      "source": [
        "dicts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AePJAnBwlsPM"
      },
      "source": [
        "def find(lst, key, value):\n",
        "#     i = 0\n",
        "    for i, dic in enumerate(lst):\n",
        "        print(lst)\n",
        "        print(dic)\n",
        "        print(\"********************************************************************\")\n",
        "        if dic[key] == value:\n",
        "            return i\n",
        "            print(\"********************************************************************\")\n",
        "    return -1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUNnsQaDlsPM"
      },
      "source": [
        "find(lst, \"name\", \"Tom\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tqebTWIlsPM"
      },
      "source": [
        "# Using list comprehension + enumerate() \n",
        "# Key index in Dictionary \n",
        "search_key = \"13075000\"\n",
        "\n",
        "temp = list(input_fle_dict.items())  Station_Nmbr\n",
        "res = list(input_fle_dict.keys()).index(search_key) \n",
        "res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnJ9HwpalsPM"
      },
      "source": [
        "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
        "    \n",
        "# Using list comprehension + enumerate() \n",
        "# Key index in Dictionary \n",
        "    temp = list(test_dict.items())  \n",
        "    res = [idx for idx, key in enumerate(temp) if key[0] == search_key] \n",
        "    \n",
        "    \n",
        "    input_fle_dict[\"Data\"][0][\"streamflow_rate\"] = input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIT62y-ulsPM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52dMYRzXlsPM"
      },
      "source": [
        "# +++++++++++++++++++++++++++++++++++++++"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Kil2AjLxlsPM"
      },
      "source": [
        "file = open(\"Data/Idaho_Streamflow_Data/13206000.txt\", \"r\")\n",
        "lines = file.readlines()[26:]\n",
        "\n",
        "print(type(lines))\n",
        "print(lines)\n",
        "\n",
        "pd.DataFrame(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxLBt9lWlsPM"
      },
      "source": [
        "# Delete a Row from the List\n",
        "#     - https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
        "\n",
        "del lines[0:1]\n",
        "lines\n",
        "# print((lines[1].split(\"\\t\")))\n",
        "test = lines[1][:-1].split(\"\\t\")\n",
        "test\n",
        "\n",
        "a_series = pd.Series(test, index = clmn_nms)\n",
        "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
        "_13206000_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKiCCA4hlsPN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VObfP7_lsPN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zWrzLFMSlsPN"
      },
      "source": [
        "# Read in the Text File and Convert to a Dataframe\n",
        "data = pd.read_csv('Data/Idaho_Streamflow_Data/13206000.txt')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cs5gkHdplsPN"
      },
      "source": [
        "# Drop the Empty Rows\n",
        "import numpy as np\n",
        "np.where(pd.isnull(statn_table_df_splt_StatnNmbr_nmbrs_clmn))\n",
        "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tkZbocslsPN"
      },
      "source": [
        "statn_table_df[\"StationNumber\"] = statn_table_df[\"StationNumber\"].astype(str)\n",
        "print(statn_table.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRg6LNAzlsPN"
      },
      "source": [
        "    if \"County\" in statn_table[\"StationNumber\"][0]:\n",
        "        print(\"true\")\n",
        "        statn_table_df_drp_cnty = statn_table_df.drop([0, 4], axis = 0)\n",
        "statn_table_df_drp_cnty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQrXQjjlsPN"
      },
      "source": [
        "# Delete the County Names from the Table\n",
        "# test = statn_table.drop([0, 4], axis = 0)\n",
        "# test.head()\n",
        "\n",
        "# Count the number of Rows in the Dataframe\n",
        "count = 0\n",
        "for statn_table_df_row in statn_table_df.index:\n",
        "\n",
        "    if \"County\" in statn_table_df[\"StationNumber\"][statn_table_df_row]:\n",
        "        statn_table_df_drp_cnty = statn_table_df.drop([statn_table_df_row], axis = 0)\n",
        "        count = count + 1\n",
        "\n",
        "print(count)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c3TJ5hUlsPN"
      },
      "source": [
        "statn_table_df_drp_cnty.head(15)\n",
        "# statn_table_df_drp_cnty.tail(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN54SOhFlsPN"
      },
      "source": [
        "print(statn_table_df_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt_6uqw_lsPN"
      },
      "source": [
        "statn_table_df[\"StationNumber\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Kq_SzMUZlsPO"
      },
      "source": [
        "# Grab All Page Source on the Page\n",
        "soup_lxml = BS(driver.page_source, \"lxml\")\n",
        "\n",
        "# Find All the Tables on the Page\n",
        "tables = soup_lxml.find_all(\"table\")\n",
        "tables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EASFUlWClsPO"
      },
      "source": [
        "# Read the Tables with Pandas\n",
        "dfs = pd.read_html(str(tables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9DcP4sHlsPO"
      },
      "source": [
        "# Access the Table\n",
        "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
        "print(\"*********************************************************************************************************\")\n",
        "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
        "print(\"*********************************************************************************************************\")\n",
        "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
        "dfs[11].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzF_oZyrlsPO"
      },
      "source": [
        "print(dfs[11][\"USGSstationnumber\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LFSAZZtlsPO"
      },
      "source": [
        "# Press/Click a Button Without an ID\n",
        "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
        "\n",
        "# Select(driver.find_element_by_id('rdb'))\n",
        "\n",
        "tab_sprtd_rado = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
        "\n",
        "button = driver.find_element_by_xpath(tab_sprtd_rado)\n",
        "button.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVQzui6GlsPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP-auiw1lsPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-XFPMMwlsPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pufNTZlrlsPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si__ZyVglsPO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy0YdqSSlsPP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWOkz4ZalsPP"
      },
      "source": [
        "# identify location of chromedriver and store it as a variable\n",
        "chromedriver = !which chromedriver\n",
        "print(type(chromedriver))\n",
        "chromedriver[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7cMn_salsPP"
      },
      "source": [
        "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvq581GclsPP"
      },
      "source": [
        "# Retrieve page with the requests module\n",
        "executable_path = {\"executable_path\": \"chromedriver\"}\n",
        "# OR\n",
        "# executable_path = {\"executable_path\": chromedriver[0]}\n",
        "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
        "# executable_path = {\"executable_path\": chromedriver}\n",
        "\n",
        "browser = Browser('chrome', **executable_path, headless = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C0J5pZQlsPP"
      },
      "source": [
        "# URL of page to be scraped\n",
        "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
        "# url = \"https://www.usgs.gov/\"\n",
        "browser.visit(url)\n",
        "window = browser.windows.current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySdh-gdVlsPP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D2sh4GhlsPP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYTteZz1lsPP"
      },
      "source": [
        "html = browser.html\n",
        "soup = BS(html, \"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHmxnaImlsPP"
      },
      "source": [
        "type(soup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCkabA9olsPP"
      },
      "source": [
        "# Print the html code of the NASA's Mars website\n",
        "print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uoJOK1hlsPQ"
      },
      "source": [
        "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
        "\n",
        "for option in soup.find_all('option'):\n",
        "    print(option)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q2aiUHwlsPQ"
      },
      "source": [
        "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
        "\n",
        "select = Select(driver.find_element_by_id('st'))\n",
        "\n",
        "# Select by visible text\n",
        "select.select_by_visible_text('Idaho')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkX1Xhf-lsPQ"
      },
      "source": [
        "# Fill in Input Fills\n",
        "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
        "# Clear the Input Field\n",
        "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
        "\n",
        "element = driver.find_element_by_name(\"bdt\")\n",
        "element.clear()\n",
        "element.send_keys(\"1990-01-01\")\n",
        "\n",
        "element = driver.find_element_by_name(\"edt\")\n",
        "element.clear()\n",
        "element.send_keys(\"1990-12-31\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCsgO9r7lsPQ"
      },
      "source": [
        "# Press/Click a Button Without an ID\n",
        "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
        "\n",
        "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
        "\n",
        "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
        "button.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGSXUZp6lsPQ"
      },
      "source": [
        "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
        "\n",
        "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
        "# test\n",
        "\n",
        "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
        "soup.findAll('table')[0].findAll('tr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OXe3yIeqlsPQ"
      },
      "source": [
        "# Grab All Page Source on the Page\n",
        "soup_lxml = BS(driver.page_source, \"lxml\")\n",
        "\n",
        "# Find All the Tables on the Page\n",
        "tables = soup_lxml.find_all(\"table\")\n",
        "tables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL1Ao3wZlsPR"
      },
      "source": [
        "# Read the Tables with Pandas\n",
        "dfs = pd.read_html(str(tables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IORWzfPTlsPR"
      },
      "source": [
        "# Access the Table\n",
        "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
        "print(\"*********************************************************************************************************\")\n",
        "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
        "print(\"*********************************************************************************************************\")\n",
        "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
        "dfs[11].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odUNPB5-lsPR"
      },
      "source": [
        "print(dfs[11][\"USGSstationnumber\"].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpB0xIsKlsPR"
      },
      "source": [
        "import requests, json\n",
        "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
        "data = json.loads(text)\n",
        "print(data['Scty'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zMdv8O4lsPR"
      },
      "source": [
        "for tr in soup.find_all('tr')[2:]:\n",
        "    tds = tr.find_all('td')\n",
        "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
        "#           (tds[0].text, tds[1].text, tds[2].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7-8-JxvlsPR"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhLyoSY4lsPR"
      },
      "source": [
        "# Step 1 - Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAspy4vGlsPR"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JcUVaftlsPS"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJRNmBSblsPS"
      },
      "source": [
        "# Step 1 - Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p60eOUxRlsPS"
      },
      "source": [
        "# ========================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPr4uXUJlsPS"
      },
      "source": [
        "### 1.1.2 Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeGGhQJDlsPS"
      },
      "source": [
        "#### 1.1.2.1 Collect the latest News Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOXL1xCplsPS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCwVTCu1wk3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEjrb_bB2xKF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}