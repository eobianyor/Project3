{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES\n",
    "# FOR DATA\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "# import time\n",
    "# import datetime\n",
    "# import requests\n",
    "# import datefinder\n",
    "\n",
    "# # FOR SQL LITE\n",
    "# from sqlalchemy import create_engine\n",
    "# from datetime import date\n",
    "\n",
    "# # FOR PLOTTING\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import style\n",
    "# style.use(\"fivethirtyeight\")\n",
    "# from matplotlib import rcParams\n",
    "# rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "# FOR MODELING\n",
    "from scipy.optimize import curve_fit\n",
    "# from splinter import Browser\n",
    "# from bs4 import BeautifulSoup as BS\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the CSV Files\n",
    "idahoFireWeather = os.path.join(\"..\", \"Data\", \"fires_Idaho_XY_TEST.csv\")\n",
    "\n",
    "# Open the CSV Files, Convert to a Dataframe, and Save as a Variable\n",
    "idaho_Fire_Weather_df = pd.read_csv(idahoFireWeather)\n",
    "# fires_Idaho_df = pd.read_csv(idahoFires, dtype={\"LOCAL_INCIDENT_ID\": 'string', \"FIRE_NAME\": 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>DISCOVERY_DATE_CONVERTED</th>\n",
       "      <th>CITY</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>rexburg</td>\n",
       "      <td>Fremont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2005-07-02</td>\n",
       "      <td>pocatello</td>\n",
       "      <td>Bannock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>pocatello</td>\n",
       "      <td>Bannock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>pocatello</td>\n",
       "      <td>Bannock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>2005-07-07</td>\n",
       "      <td>pocatello</td>\n",
       "      <td>Bannock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16522</td>\n",
       "      <td>B</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>hayden</td>\n",
       "      <td>Kootenai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16523</td>\n",
       "      <td>A</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>creston</td>\n",
       "      <td>Boundary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16524</td>\n",
       "      <td>A</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>sandpoint</td>\n",
       "      <td>Boundary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16525</td>\n",
       "      <td>A</td>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>emmett</td>\n",
       "      <td>Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16526</td>\n",
       "      <td>A</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>sandpoint</td>\n",
       "      <td>Boundary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16527 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIRE_SIZE_CLASS DISCOVERY_DATE_CONVERTED       CITY COUNTY_NAME\n",
       "0                   A               2005-07-16    rexburg     Fremont\n",
       "1                   A               2005-07-02  pocatello     Bannock\n",
       "2                   A               2005-07-04  pocatello     Bannock\n",
       "3                   A               2005-07-04  pocatello     Bannock\n",
       "4                   A               2005-07-07  pocatello     Bannock\n",
       "...               ...                      ...        ...         ...\n",
       "16522               B               2015-10-06     hayden    Kootenai\n",
       "16523               A               2015-10-11    creston    Boundary\n",
       "16524               A               2015-10-12  sandpoint    Boundary\n",
       "16525               A               2015-10-14     emmett      Valley\n",
       "16526               A               2015-10-17  sandpoint    Boundary\n",
       "\n",
       "[16527 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the Data in the Dataframe\n",
    "# print(fires_Idaho_df.keys())\n",
    "idaho_Fire_Weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIRE_YEAR                   0\n",
       "STAT_CAUSE_DESCR            0\n",
       "FIRE_SIZE                   0\n",
       "FIRE_SIZE_CLASS             0\n",
       "LATITUDE                    0\n",
       "LONGITUDE                   0\n",
       "DISCOVERY_DATE_CONVERTED    0\n",
       "CONT_DATE_CONVERTED         0\n",
       "FIRE_DAYS                   0\n",
       "COUNTY_NAME_Ada             0\n",
       "COUNTY_NAME_Adams           0\n",
       "COUNTY_NAME_Bannock         0\n",
       "COUNTY_NAME_Bear Lake       0\n",
       "COUNTY_NAME_Benewah         0\n",
       "COUNTY_NAME_Bingham         0\n",
       "COUNTY_NAME_Blaine          0\n",
       "COUNTY_NAME_Boise           0\n",
       "COUNTY_NAME_Bonner          0\n",
       "COUNTY_NAME_Bonneville      0\n",
       "COUNTY_NAME_Boundary        0\n",
       "COUNTY_NAME_Butte           0\n",
       "COUNTY_NAME_Camas           0\n",
       "COUNTY_NAME_Canyon          0\n",
       "COUNTY_NAME_Caribou         0\n",
       "COUNTY_NAME_Cassia          0\n",
       "COUNTY_NAME_Clark           0\n",
       "COUNTY_NAME_Clearwater      0\n",
       "COUNTY_NAME_Custer          0\n",
       "COUNTY_NAME_Elmore          0\n",
       "COUNTY_NAME_Franklin        0\n",
       "COUNTY_NAME_Fremont         0\n",
       "COUNTY_NAME_Gem             0\n",
       "COUNTY_NAME_Gooding         0\n",
       "COUNTY_NAME_Idaho           0\n",
       "COUNTY_NAME_Jefferson       0\n",
       "COUNTY_NAME_Jerome          0\n",
       "COUNTY_NAME_Kootenai        0\n",
       "COUNTY_NAME_Latah           0\n",
       "COUNTY_NAME_Lemhi           0\n",
       "COUNTY_NAME_Lewis           0\n",
       "COUNTY_NAME_Lincoln         0\n",
       "COUNTY_NAME_Madison         0\n",
       "COUNTY_NAME_Minidoka        0\n",
       "COUNTY_NAME_Nez Perce       0\n",
       "COUNTY_NAME_Oneida          0\n",
       "COUNTY_NAME_Owyhee          0\n",
       "COUNTY_NAME_Payette         0\n",
       "COUNTY_NAME_Power           0\n",
       "COUNTY_NAME_Shoshone        0\n",
       "COUNTY_NAME_Teton           0\n",
       "COUNTY_NAME_Twin Falls      0\n",
       "COUNTY_NAME_Valley          0\n",
       "COUNTY_NAME_Washington      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get dummy variables for nominal property column\n",
    "clean_fires_Idaho_2000_2015_df = pd.get_dummies(fires_Idaho_2000_2015_df, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "clean_fires_Idaho_2000_2015_df = pd.get_dummies(fires_Idaho_2000_2015_df, columns=[\"COUNTY_NAME\"])\n",
    "\n",
    "FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# replace values in each column according to the dictionaries above\n",
    "clean_fires_Idaho_2000_2015_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "clean_fires_Idaho_2000_2015_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and associate cities using the lat lng coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from citipy import citipy\n",
    "\n",
    "# # Pull lat lng columns from df\n",
    "# location_df = fires_Idaho_df[['LATITUDE', 'LONGITUDE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Generate a random cities from Lat Long table make sure we have up to 500. Delete any duplicates: \n",
    "# # Make lists needed\n",
    "# cityList = []\n",
    "# countryList = []\n",
    "\n",
    "# # Create a loop to find a city for each lat long pair\n",
    "# for index, row in location_df.iterrows():\n",
    "# #     print(f\"Searching for nearest city to lat long {row['Latitude'], row['Longitude']}...\")\n",
    "#     city = citipy.nearest_city(row[\"LATITUDE\"], row[\"LONGITUDE\"])\n",
    "#     cityName = city.city_name\n",
    "#     location_df.loc[index,\"CITY\"] = cityName\n",
    "#     cityList.append(cityName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_df['CITY'].value_counts()\n",
    "# # location_df['CITY'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT HISTORIC WEATHER DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING A NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>DISCOVERY_DATE_CONVERTED</th>\n",
       "      <th>CONT_DATE_CONVERTED</th>\n",
       "      <th>FIRE_DAYS</th>\n",
       "      <th>COUNTY_NAME_Ada</th>\n",
       "      <th>...</th>\n",
       "      <th>COUNTY_NAME_Nez Perce</th>\n",
       "      <th>COUNTY_NAME_Oneida</th>\n",
       "      <th>COUNTY_NAME_Owyhee</th>\n",
       "      <th>COUNTY_NAME_Payette</th>\n",
       "      <th>COUNTY_NAME_Power</th>\n",
       "      <th>COUNTY_NAME_Shoshone</th>\n",
       "      <th>COUNTY_NAME_Teton</th>\n",
       "      <th>COUNTY_NAME_Twin Falls</th>\n",
       "      <th>COUNTY_NAME_Valley</th>\n",
       "      <th>COUNTY_NAME_Washington</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>44.488611</td>\n",
       "      <td>-111.256111</td>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>2005-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>Campfire</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>42.736389</td>\n",
       "      <td>-112.384444</td>\n",
       "      <td>2005-07-02</td>\n",
       "      <td>2005-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>Campfire</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>42.839722</td>\n",
       "      <td>-112.176667</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>Campfire</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>42.691389</td>\n",
       "      <td>-112.368611</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "      <td>Campfire</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>42.736389</td>\n",
       "      <td>-112.072222</td>\n",
       "      <td>2005-07-07</td>\n",
       "      <td>2005-07-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17355</td>\n",
       "      <td>2015</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>47.833579</td>\n",
       "      <td>-116.788012</td>\n",
       "      <td>2015-10-06</td>\n",
       "      <td>2015-10-07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17356</td>\n",
       "      <td>2015</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>48.769787</td>\n",
       "      <td>-116.348913</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17357</td>\n",
       "      <td>2015</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>48.589271</td>\n",
       "      <td>-116.392942</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17358</td>\n",
       "      <td>2015</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>44.491862</td>\n",
       "      <td>-116.088832</td>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>2015-10-14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17359</td>\n",
       "      <td>2015</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>48.636208</td>\n",
       "      <td>-116.474317</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16527 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIRE_YEAR STAT_CAUSE_DESCR  FIRE_SIZE  FIRE_SIZE_CLASS   LATITUDE  \\\n",
       "0           2005    Miscellaneous       0.10                1  44.488611   \n",
       "1           2005         Campfire       0.10                1  42.736389   \n",
       "2           2005         Campfire       0.10                1  42.839722   \n",
       "3           2005         Campfire       0.10                1  42.691389   \n",
       "4           2005         Campfire       0.10                1  42.736389   \n",
       "...          ...              ...        ...              ...        ...   \n",
       "17355       2015    Miscellaneous       0.45                2  47.833579   \n",
       "17356       2015    Miscellaneous       0.10                1  48.769787   \n",
       "17357       2015    Miscellaneous       0.10                1  48.589271   \n",
       "17358       2015    Miscellaneous       0.10                1  44.491862   \n",
       "17359       2015    Miscellaneous       0.10                1  48.636208   \n",
       "\n",
       "        LONGITUDE DISCOVERY_DATE_CONVERTED CONT_DATE_CONVERTED  FIRE_DAYS  \\\n",
       "0     -111.256111               2005-07-16          2005-07-16          1   \n",
       "1     -112.384444               2005-07-02          2005-07-02          1   \n",
       "2     -112.176667               2005-07-04          2005-07-04          1   \n",
       "3     -112.368611               2005-07-04          2005-07-04          1   \n",
       "4     -112.072222               2005-07-07          2005-07-07          1   \n",
       "...           ...                      ...                 ...        ...   \n",
       "17355 -116.788012               2015-10-06          2015-10-07          2   \n",
       "17356 -116.348913               2015-10-11          2015-10-12          2   \n",
       "17357 -116.392942               2015-10-12          2015-10-12          1   \n",
       "17358 -116.088832               2015-10-14          2015-10-14          1   \n",
       "17359 -116.474317               2015-10-17          2015-10-18          2   \n",
       "\n",
       "       COUNTY_NAME_Ada  ...  COUNTY_NAME_Nez Perce  COUNTY_NAME_Oneida  \\\n",
       "0                    0  ...                      0                   0   \n",
       "1                    0  ...                      0                   0   \n",
       "2                    0  ...                      0                   0   \n",
       "3                    0  ...                      0                   0   \n",
       "4                    0  ...                      0                   0   \n",
       "...                ...  ...                    ...                 ...   \n",
       "17355                0  ...                      0                   0   \n",
       "17356                0  ...                      0                   0   \n",
       "17357                0  ...                      0                   0   \n",
       "17358                0  ...                      0                   0   \n",
       "17359                0  ...                      0                   0   \n",
       "\n",
       "       COUNTY_NAME_Owyhee  COUNTY_NAME_Payette  COUNTY_NAME_Power  \\\n",
       "0                       0                    0                  0   \n",
       "1                       0                    0                  0   \n",
       "2                       0                    0                  0   \n",
       "3                       0                    0                  0   \n",
       "4                       0                    0                  0   \n",
       "...                   ...                  ...                ...   \n",
       "17355                   0                    0                  0   \n",
       "17356                   0                    0                  0   \n",
       "17357                   0                    0                  0   \n",
       "17358                   0                    0                  0   \n",
       "17359                   0                    0                  0   \n",
       "\n",
       "       COUNTY_NAME_Shoshone  COUNTY_NAME_Teton  COUNTY_NAME_Twin Falls  \\\n",
       "0                         0                  0                       0   \n",
       "1                         0                  0                       0   \n",
       "2                         0                  0                       0   \n",
       "3                         0                  0                       0   \n",
       "4                         0                  0                       0   \n",
       "...                     ...                ...                     ...   \n",
       "17355                     0                  0                       0   \n",
       "17356                     0                  0                       0   \n",
       "17357                     0                  0                       0   \n",
       "17358                     0                  0                       0   \n",
       "17359                     0                  0                       0   \n",
       "\n",
       "       COUNTY_NAME_Valley  COUNTY_NAME_Washington  \n",
       "0                       0                       0  \n",
       "1                       0                       0  \n",
       "2                       0                       0  \n",
       "3                       0                       0  \n",
       "4                       0                       0  \n",
       "...                   ...                     ...  \n",
       "17355                   0                       0  \n",
       "17356                   0                       0  \n",
       "17357                   0                       0  \n",
       "17358                   1                       0  \n",
       "17359                   0                       0  \n",
       "\n",
       "[16527 rows x 53 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_fires_Idaho_2000_2015_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FIRE_YEAR', 'LATITUDE', 'LONGITUDE', 'FIRE_DAYS', 'COUNTY_NAME_Ada',\n",
      "       'COUNTY_NAME_Adams', 'COUNTY_NAME_Bannock', 'COUNTY_NAME_Bear Lake',\n",
      "       'COUNTY_NAME_Benewah', 'COUNTY_NAME_Bingham', 'COUNTY_NAME_Blaine',\n",
      "       'COUNTY_NAME_Boise', 'COUNTY_NAME_Bonner', 'COUNTY_NAME_Bonneville',\n",
      "       'COUNTY_NAME_Boundary', 'COUNTY_NAME_Butte', 'COUNTY_NAME_Camas',\n",
      "       'COUNTY_NAME_Canyon', 'COUNTY_NAME_Caribou', 'COUNTY_NAME_Cassia',\n",
      "       'COUNTY_NAME_Clark', 'COUNTY_NAME_Clearwater', 'COUNTY_NAME_Custer',\n",
      "       'COUNTY_NAME_Elmore', 'COUNTY_NAME_Franklin', 'COUNTY_NAME_Fremont',\n",
      "       'COUNTY_NAME_Gem', 'COUNTY_NAME_Gooding', 'COUNTY_NAME_Idaho',\n",
      "       'COUNTY_NAME_Jefferson', 'COUNTY_NAME_Jerome', 'COUNTY_NAME_Kootenai',\n",
      "       'COUNTY_NAME_Latah', 'COUNTY_NAME_Lemhi', 'COUNTY_NAME_Lewis',\n",
      "       'COUNTY_NAME_Lincoln', 'COUNTY_NAME_Madison', 'COUNTY_NAME_Minidoka',\n",
      "       'COUNTY_NAME_Nez Perce', 'COUNTY_NAME_Oneida', 'COUNTY_NAME_Owyhee',\n",
      "       'COUNTY_NAME_Payette', 'COUNTY_NAME_Power', 'COUNTY_NAME_Shoshone',\n",
      "       'COUNTY_NAME_Teton', 'COUNTY_NAME_Twin Falls', 'COUNTY_NAME_Valley',\n",
      "       'COUNTY_NAME_Washington'],\n",
      "      dtype='object')\n",
      "(16527, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.00500000e+03,  4.44886111e+01, -1.11256111e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.00500000e+03,  4.27363889e+01, -1.12384444e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.00500000e+03,  4.28397222e+01, -1.12176667e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 2.01500000e+03,  4.85892705e+01, -1.16392942e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.01500000e+03,  4.44918621e+01, -1.16088832e+02, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.01500000e+03,  4.86362077e+01, -1.16474317e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE X VALUES\n",
    "X = clean_fires_Idaho_2000_2015_df.drop(['STAT_CAUSE_DESCR', 'FIRE_SIZE', 'DISCOVERY_DATE_CONVERTED', 'CONT_DATE_CONVERTED', 'FIRE_SIZE_CLASS'], axis=1)\n",
    "print(X.keys())\n",
    "X = X.values.reshape(-1, 48)\n",
    "\n",
    "# X = X.to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "type(X)\n",
    "X\n",
    "\n",
    "# fires_Idaho_2000_2015_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16527, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE y VALUES\n",
    "y = clean_fires_Idaho_2000_2015_df[['FIRE_SIZE_CLASS']]\n",
    "\n",
    "y = y.values.reshape(-1, 1)\n",
    "\n",
    "print(y.shape)\n",
    "# type(y)\n",
    "y\n",
    "\n",
    "# # LABEL ENCODE Y\n",
    "# # Import required module\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# # Create an object of the label encoder class\n",
    "# labelencoder = LabelEncoder()\n",
    "\n",
    "# # apply \"le.fit_transform\"\n",
    "# old_y = Y[1].apply(le.fit_transform)\n",
    "# y = old_y\n",
    "\n",
    "# # # Change the shape of y v1\n",
    "# new_y = np.array(old_y)\n",
    "# y = new_y.reshape(-1, 1) \n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# Create variables to hold the scaled train & test data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# y_train_scaled = y_scaler.transform(y_train)\n",
    "# y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encode the categorical target variable to the necessary format for the model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 neural network with 1 hidden layer and 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12395, 48)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12395, 8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 77        \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Normal neural network with X inputs, 1 hidden layer, 10 nodes in hidden layer, and 7 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "fire_model_v1 = Sequential()\n",
    "fire_model_v1.add(Dense(units=10, activation='sigmoid', input_dim=2))\n",
    "fire_model_v1.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "# view the model's architecture\n",
    "fire_model_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:754 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-ed0f723f49ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 726\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:754 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Emeka\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 48)\n"
     ]
    }
   ],
   "source": [
    "## Compile and train the deep learning model\n",
    "fire_model_v1.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "fire_model_v1.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT MODEL ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,4))\n",
    "\n",
    "ax[0].plot(model_history.history['loss'])\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "\n",
    "ax[1].plot(model_history.history['accuracy'])\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep neural network with X inputs, 2 hidden layers, 10 nodes in each hidden layer, and 7 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "fire_model_v2 = Sequential()\n",
    "fire_model_v2.add(Dense(units=10, activation='sigmoid', input_dim=2))\n",
    "fire_model_v2.add(Dense(units=10, activation='sigmoid'))\n",
    "fire_model_v2.add(Dense(units=7, activation='softmax'))\n",
    "\n",
    "# view the model's architecture\n",
    "fire_model_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile and train the deep learning model\n",
    "fire_model_v2.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "fire_model_v2.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT MODEL ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,4))\n",
    "\n",
    "ax[0].plot(model_history.history['loss'])\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "\n",
    "ax[1].plot(model_history.history['accuracy'])\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_model_v1, fire_model_v1 = fire_model_v1.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "fire_model_v2, fire_model_v2 = fire_model_v2.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {deep_model_loss}, Accuracy: {deep_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
