{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES\n",
    "# FOR DATA\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "# import requests\n",
    "# import datefinder\n",
    "\n",
    "# # FOR SQL LITE\n",
    "# from sqlalchemy import create_engine\n",
    "# from datetime import date\n",
    "\n",
    "# # FOR PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "# FOR MODELING\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# FOR KNN AND OTHER MODELING\n",
    "# from scipy.optimize import curve_fit\n",
    "# # from splinter import Browser\n",
    "# # from bs4 import BeautifulSoup as BS\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# FOR TF MODELS\n",
    "import keras.models\n",
    "import keras.layers\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "idahoCounties = ['Ada', 'Adams', 'Bannock', 'Bear Lake', 'Benewah', 'Bingham', 'Blaine', 'Boise', 'Bonner', 'Bonneville', 'Boundary','Butte', \n",
    " 'Camas', 'Canyon', 'Caribou', 'Cassia', 'Clark', 'Clearwater', 'Custer', 'Elmore', 'Franklin', 'Fremont', 'Gem', 'Gooding', \n",
    " 'Idaho', 'Jefferson', 'Jerome' 'Kootenai', 'Latah', 'Lemhi', 'Lewis', 'Lincoln', 'Madison', 'Minidoka','Nez Perce', \n",
    " 'Oneida', 'Owyhee', 'Payette', 'Power', 'Shoshone', 'Teton', 'Twin Falls', 'Valley', 'Washington']\n",
    "        \n",
    "\n",
    "notIdahoCounties = ['Baker', 'Beaverhead', 'Box Elder', 'Elko', 'Gallatin', 'Malheur', 'Mineral', 'Missoula', 'Ravalli', 'Sanders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the CSV Files\n",
    "idahoFireWeatherDrought = os.path.join(\"..\", \"Data\", \"fires_Idaho_2000_2015_drought_weather.csv\")\n",
    "\n",
    "# Open the CSV Files, Convert to a Dataframe, and Save as a Variable\n",
    "idaho_Fire_Weather_Drought_df = pd.read_csv(idahoFireWeatherDrought)\n",
    "# fires_Idaho_df = pd.read_csv(idahoFires, dtype={\"LOCAL_INCIDENT_ID\": 'string', \"FIRE_NAME\": 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FPA_ID</th>\n",
       "      <th>SOURCE_SYSTEM_TYPE</th>\n",
       "      <th>SOURCE_SYSTEM</th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "      <th>FIRE_DAYS</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>DISCOVERY_MONTH_CONVERTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>155</td>\n",
       "      <td>FS-1419238</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.08</td>\n",
       "      <td>69.98</td>\n",
       "      <td>71.06</td>\n",
       "      <td>1</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>FS-1419278</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.04</td>\n",
       "      <td>62.06</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>FS-1419291</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>FS-1419292</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>FS-1419293</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64.94</td>\n",
       "      <td>68.00</td>\n",
       "      <td>71.96</td>\n",
       "      <td>71.96</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15481</td>\n",
       "      <td>15481</td>\n",
       "      <td>1847545</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847545</td>\n",
       "      <td>300274025</td>\n",
       "      <td>SFO-2015IDIDL6102015028</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.58</td>\n",
       "      <td>60.80</td>\n",
       "      <td>59.90</td>\n",
       "      <td>60.62</td>\n",
       "      <td>2</td>\n",
       "      <td>Boise</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15483</td>\n",
       "      <td>15483</td>\n",
       "      <td>1847684</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847684</td>\n",
       "      <td>300274204</td>\n",
       "      <td>SFO-2015IDIDL2102015023</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.28</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15484</td>\n",
       "      <td>15484</td>\n",
       "      <td>1847710</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847710</td>\n",
       "      <td>300274236</td>\n",
       "      <td>SFO-2015IDIDL2102015021</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15485</td>\n",
       "      <td>15485</td>\n",
       "      <td>1847762</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847762</td>\n",
       "      <td>300274306</td>\n",
       "      <td>SFO-2015IDIDL9802015030</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.28</td>\n",
       "      <td>58.46</td>\n",
       "      <td>61.52</td>\n",
       "      <td>63.68</td>\n",
       "      <td>1</td>\n",
       "      <td>Valley</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15486</td>\n",
       "      <td>15486</td>\n",
       "      <td>1848009</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1848009</td>\n",
       "      <td>300274600</td>\n",
       "      <td>SFO-2015IDIDL2102015024</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.18</td>\n",
       "      <td>51.80</td>\n",
       "      <td>53.06</td>\n",
       "      <td>55.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14902 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  OBJECTID  Shape  Join_Count  TARGET_FID     FOD_ID  \\\n",
       "0               0       152  Point           1         152        155   \n",
       "1               1       169  Point           1         169        172   \n",
       "2               2       173  Point           1         173        176   \n",
       "3               3       174  Point           1         174        177   \n",
       "4               4       175  Point           1         175        178   \n",
       "...           ...       ...    ...         ...         ...        ...   \n",
       "15481       15481   1847545  Point           1     1847545  300274025   \n",
       "15483       15483   1847684  Point           1     1847684  300274204   \n",
       "15484       15484   1847710  Point           1     1847710  300274236   \n",
       "15485       15485   1847762  Point           1     1847762  300274306   \n",
       "15486       15486   1848009  Point           1     1848009  300274600   \n",
       "\n",
       "                        FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
       "0                   FS-1419238                FED   FS-FIRESTAT   \n",
       "1                   FS-1419278                FED   FS-FIRESTAT   \n",
       "2                   FS-1419291                FED   FS-FIRESTAT   \n",
       "3                   FS-1419292                FED   FS-FIRESTAT   \n",
       "4                   FS-1419293                FED   FS-FIRESTAT   \n",
       "...                        ...                ...           ...   \n",
       "15481  SFO-2015IDIDL6102015028             NONFED       ST-NASF   \n",
       "15483  SFO-2015IDIDL2102015023             NONFED       ST-NASF   \n",
       "15484  SFO-2015IDIDL2102015021             NONFED       ST-NASF   \n",
       "15485  SFO-2015IDIDL9802015030             NONFED       ST-NASF   \n",
       "15486  SFO-2015IDIDL2102015024             NONFED       ST-NASF   \n",
       "\n",
       "      NWCG_REPORTING_AGENCY  ... DAY_PRCP_2 DAY_PRCP_3 DAY_PRCP_4  \\\n",
       "0                        FS  ...        0.0        0.0        0.0   \n",
       "1                        FS  ...        0.0        0.0        0.0   \n",
       "2                        FS  ...        0.0        0.0        0.0   \n",
       "3                        FS  ...        0.0        0.0        0.0   \n",
       "4                        FS  ...        0.0        0.0        0.8   \n",
       "...                     ...  ...        ...        ...        ...   \n",
       "15481                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15483                ST/C&L  ...        0.0        0.9        0.0   \n",
       "15484                ST/C&L  ...        0.9        0.0        0.0   \n",
       "15485                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15486                ST/C&L  ...        0.0        0.0        0.0   \n",
       "\n",
       "      DAY_AVG_TEMP_1  DAY_AVG_TEMP_2 DAY_AVG_TEMP_3 DAY_AVG_TEMP_4 FIRE_DAYS  \\\n",
       "0              77.00           69.08          69.98          71.06         1   \n",
       "1              64.04           62.06          69.08          66.92         1   \n",
       "2              69.08           66.92          64.04          64.94         1   \n",
       "3              69.08           66.92          64.04          64.94         1   \n",
       "4              64.94           68.00          71.96          71.96         1   \n",
       "...              ...             ...            ...            ...       ...   \n",
       "15481          64.58           60.80          59.90          60.62         2   \n",
       "15483          58.28           60.08          66.74          59.36         2   \n",
       "15484          60.08           66.74          59.36          50.00         1   \n",
       "15485          67.28           58.46          61.52          63.68         1   \n",
       "15486          50.18           51.80          53.06          55.40         2   \n",
       "\n",
       "      COUNTY_NAME DISCOVERY_MONTH_CONVERTED  \n",
       "0         Fremont                         7  \n",
       "1         Bannock                         7  \n",
       "2         Bannock                         7  \n",
       "3         Bannock                         7  \n",
       "4         Bannock                         7  \n",
       "...           ...                       ...  \n",
       "15481       Boise                        10  \n",
       "15483    Boundary                        10  \n",
       "15484    Boundary                        10  \n",
       "15485      Valley                        10  \n",
       "15486    Boundary                        10  \n",
       "\n",
       "[14902 rows x 119 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT DATE TO DATETIME FORMAT\n",
    "idaho_Fire_Weather_Drought_df['DISCOVERY_DATE_CONVERTED'] = pd.to_datetime(idaho_Fire_Weather_Drought_df['DISCOVERY_DATE_CONVERTED'])\n",
    "idaho_Fire_Weather_Drought_df['CONT_DATE_CONVERTED'] = pd.to_datetime(idaho_Fire_Weather_Drought_df['CONT_DATE_CONVERTED'])\n",
    "\n",
    "# CREATE COLUMNS WE NEED\n",
    "idaho_Fire_Weather_Drought_df['FIRE_DAYS'] = (((idaho_Fire_Weather_Drought_df['CONT_DOY']) + 1) - idaho_Fire_Weather_Drought_df['DISCOVERY_DOY'])\n",
    "idaho_Fire_Weather_Drought_df['COUNTY_NAME'] = (idaho_Fire_Weather_Drought_df['FIPS_NAME'])\n",
    "# Create month column\n",
    "idaho_Fire_Weather_Drought_df['DISCOVERY_MONTH_CONVERTED']=idaho_Fire_Weather_Drought_df['DISCOVERY_DATE_CONVERTED'].apply(lambda x: int(x.strftime('%m')))\n",
    "\n",
    "# FILTER ROWS FOR FIRES IN COUNTIES OUTSIDE IDAHO\n",
    "idaho_Fire_Weather_Drought_df = idaho_Fire_Weather_Drought_df[idaho_Fire_Weather_Drought_df['NAME'].isin(idahoCounties)]\n",
    "\n",
    "# View the Data in the Dataframe\n",
    "# print(idaho_Fire_Weather_df.keys())\n",
    "idaho_Fire_Weather_Drought_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OUTPUT THE AND UPDATED CSV FILE\n",
    "\n",
    "# output_path = os.path.join(\"..\", \"Data\", \"fires_Idaho_2000_2015_drought_weather_Plus.csv\")\n",
    "# with open(output_path, 'w') as csvfile:\n",
    "#         idaho_Fire_Weather_Drought_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEAN UP AND REMOVE UNWANTED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get dummy variables for nominal property column\n",
    "# # idaho_Fire_Weather_df = pd.get_dummies(idaho_Fire_Weather_df, columns=[\"FIRE_SIZE_CLASS\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"CITY\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"NAME\"])\n",
    "\n",
    "# # FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# # # replace values in each column according to the dictionaries above\n",
    "# # clean_fires_Idaho_2000_2015_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "# idaho_Fire_Weather_Drought_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables for nominal property column\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"NAME\"])\n",
    "\n",
    "# FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# # replace values in each column according to the dictionaries above\n",
    "# idaho_Fire_Weather_Drought_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "# idaho_Fire_Weather_Drought_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and associate cities using the lat lng coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FPA_ID</th>\n",
       "      <th>SOURCE_SYSTEM_TYPE</th>\n",
       "      <th>SOURCE_SYSTEM</th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "      <th>FIRE_DAYS</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>DISCOVERY_MONTH_CONVERTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>155</td>\n",
       "      <td>FS-1419238</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.08</td>\n",
       "      <td>69.98</td>\n",
       "      <td>71.06</td>\n",
       "      <td>1</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>FS-1419278</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.04</td>\n",
       "      <td>62.06</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>FS-1419291</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>FS-1419292</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>FS-1419293</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64.94</td>\n",
       "      <td>68.00</td>\n",
       "      <td>71.96</td>\n",
       "      <td>71.96</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15481</td>\n",
       "      <td>15481</td>\n",
       "      <td>1847545</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847545</td>\n",
       "      <td>300274025</td>\n",
       "      <td>SFO-2015IDIDL6102015028</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.58</td>\n",
       "      <td>60.80</td>\n",
       "      <td>59.90</td>\n",
       "      <td>60.62</td>\n",
       "      <td>2</td>\n",
       "      <td>Boise</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15483</td>\n",
       "      <td>15483</td>\n",
       "      <td>1847684</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847684</td>\n",
       "      <td>300274204</td>\n",
       "      <td>SFO-2015IDIDL2102015023</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.28</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15484</td>\n",
       "      <td>15484</td>\n",
       "      <td>1847710</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847710</td>\n",
       "      <td>300274236</td>\n",
       "      <td>SFO-2015IDIDL2102015021</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15485</td>\n",
       "      <td>15485</td>\n",
       "      <td>1847762</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847762</td>\n",
       "      <td>300274306</td>\n",
       "      <td>SFO-2015IDIDL9802015030</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.28</td>\n",
       "      <td>58.46</td>\n",
       "      <td>61.52</td>\n",
       "      <td>63.68</td>\n",
       "      <td>1</td>\n",
       "      <td>Valley</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15486</td>\n",
       "      <td>15486</td>\n",
       "      <td>1848009</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1848009</td>\n",
       "      <td>300274600</td>\n",
       "      <td>SFO-2015IDIDL2102015024</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.18</td>\n",
       "      <td>51.80</td>\n",
       "      <td>53.06</td>\n",
       "      <td>55.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14902 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  OBJECTID  Shape  Join_Count  TARGET_FID     FOD_ID  \\\n",
       "0               0       152  Point           1         152        155   \n",
       "1               1       169  Point           1         169        172   \n",
       "2               2       173  Point           1         173        176   \n",
       "3               3       174  Point           1         174        177   \n",
       "4               4       175  Point           1         175        178   \n",
       "...           ...       ...    ...         ...         ...        ...   \n",
       "15481       15481   1847545  Point           1     1847545  300274025   \n",
       "15483       15483   1847684  Point           1     1847684  300274204   \n",
       "15484       15484   1847710  Point           1     1847710  300274236   \n",
       "15485       15485   1847762  Point           1     1847762  300274306   \n",
       "15486       15486   1848009  Point           1     1848009  300274600   \n",
       "\n",
       "                        FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
       "0                   FS-1419238                FED   FS-FIRESTAT   \n",
       "1                   FS-1419278                FED   FS-FIRESTAT   \n",
       "2                   FS-1419291                FED   FS-FIRESTAT   \n",
       "3                   FS-1419292                FED   FS-FIRESTAT   \n",
       "4                   FS-1419293                FED   FS-FIRESTAT   \n",
       "...                        ...                ...           ...   \n",
       "15481  SFO-2015IDIDL6102015028             NONFED       ST-NASF   \n",
       "15483  SFO-2015IDIDL2102015023             NONFED       ST-NASF   \n",
       "15484  SFO-2015IDIDL2102015021             NONFED       ST-NASF   \n",
       "15485  SFO-2015IDIDL9802015030             NONFED       ST-NASF   \n",
       "15486  SFO-2015IDIDL2102015024             NONFED       ST-NASF   \n",
       "\n",
       "      NWCG_REPORTING_AGENCY  ... DAY_PRCP_2 DAY_PRCP_3 DAY_PRCP_4  \\\n",
       "0                        FS  ...        0.0        0.0        0.0   \n",
       "1                        FS  ...        0.0        0.0        0.0   \n",
       "2                        FS  ...        0.0        0.0        0.0   \n",
       "3                        FS  ...        0.0        0.0        0.0   \n",
       "4                        FS  ...        0.0        0.0        0.8   \n",
       "...                     ...  ...        ...        ...        ...   \n",
       "15481                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15483                ST/C&L  ...        0.0        0.9        0.0   \n",
       "15484                ST/C&L  ...        0.9        0.0        0.0   \n",
       "15485                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15486                ST/C&L  ...        0.0        0.0        0.0   \n",
       "\n",
       "      DAY_AVG_TEMP_1  DAY_AVG_TEMP_2 DAY_AVG_TEMP_3 DAY_AVG_TEMP_4 FIRE_DAYS  \\\n",
       "0              77.00           69.08          69.98          71.06         1   \n",
       "1              64.04           62.06          69.08          66.92         1   \n",
       "2              69.08           66.92          64.04          64.94         1   \n",
       "3              69.08           66.92          64.04          64.94         1   \n",
       "4              64.94           68.00          71.96          71.96         1   \n",
       "...              ...             ...            ...            ...       ...   \n",
       "15481          64.58           60.80          59.90          60.62         2   \n",
       "15483          58.28           60.08          66.74          59.36         2   \n",
       "15484          60.08           66.74          59.36          50.00         1   \n",
       "15485          67.28           58.46          61.52          63.68         1   \n",
       "15486          50.18           51.80          53.06          55.40         2   \n",
       "\n",
       "      COUNTY_NAME DISCOVERY_MONTH_CONVERTED  \n",
       "0         Fremont                         7  \n",
       "1         Bannock                         7  \n",
       "2         Bannock                         7  \n",
       "3         Bannock                         7  \n",
       "4         Bannock                         7  \n",
       "...           ...                       ...  \n",
       "15481       Boise                        10  \n",
       "15483    Boundary                        10  \n",
       "15484    Boundary                        10  \n",
       "15485      Valley                        10  \n",
       "15486    Boundary                        10  \n",
       "\n",
       "[14902 rows x 119 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idaho_Fire_Weather_Drought_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Avg for values\n",
    "Day1_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_1'].mean()\n",
    "Day2_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_2'].mean()\n",
    "Day3_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_3'].mean()\n",
    "Day4_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_4'].mean()\n",
    "Day1_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'].mean()\n",
    "Day2_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'].mean()\n",
    "Day3_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'].mean()\n",
    "Day4_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'].mean()\n",
    "\n",
    "# Use Avg values to fill any null values\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_1'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_1'].fillna(Day1_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_2'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_2'].fillna(Day2_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_3'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_3'].fillna(Day3_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_4'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_4'].fillna(Day4_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'].fillna(Day1_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'].fillna(Day2_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'].fillna(Day3_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'].fillna(Day4_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>DISCOVERY_MONTH_CONVERTED</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>AVE_SIZE12</th>\n",
       "      <th>CROP_ACR12</th>\n",
       "      <th>None</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>DAY_PRCP_1</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>FIRE_SIZE_CLASS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041246</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>0.163815</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>0.061832</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>-0.003069</td>\n",
       "      <td>-0.028075</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>-0.075665</td>\n",
       "      <td>-0.080226</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.043749</td>\n",
       "      <td>0.078619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DISCOVERY_MONTH_CONVERTED</td>\n",
       "      <td>-0.041246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052756</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.114252</td>\n",
       "      <td>0.114252</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>0.155414</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>-0.031009</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.038563</td>\n",
       "      <td>-0.065824</td>\n",
       "      <td>-0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FIRE_YEAR</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>-0.052756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139417</td>\n",
       "      <td>-0.188559</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>-0.123206</td>\n",
       "      <td>-0.167924</td>\n",
       "      <td>-0.211975</td>\n",
       "      <td>-0.179604</td>\n",
       "      <td>-0.116881</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.036142</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0.113086</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.109455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVE_SIZE12</td>\n",
       "      <td>0.163815</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>-0.139417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577044</td>\n",
       "      <td>-0.132600</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.098384</td>\n",
       "      <td>0.094162</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.019457</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.014886</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.046041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CROP_ACR12</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.188559</td>\n",
       "      <td>0.577044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131695</td>\n",
       "      <td>0.131695</td>\n",
       "      <td>0.139625</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>0.136077</td>\n",
       "      <td>0.102025</td>\n",
       "      <td>-0.003605</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>-0.052992</td>\n",
       "      <td>-0.059147</td>\n",
       "      <td>-0.046783</td>\n",
       "      <td>-0.023749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>None</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>-0.114252</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>-0.132600</td>\n",
       "      <td>-0.131695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.722797</td>\n",
       "      <td>-0.471042</td>\n",
       "      <td>-0.246894</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.036124</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>0.031823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D0</td>\n",
       "      <td>0.061832</td>\n",
       "      <td>0.114252</td>\n",
       "      <td>-0.123206</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.131695</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>0.471042</td>\n",
       "      <td>0.246894</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>-0.007870</td>\n",
       "      <td>-0.021974</td>\n",
       "      <td>-0.036124</td>\n",
       "      <td>-0.032575</td>\n",
       "      <td>-0.031823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D1</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>-0.167924</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.139625</td>\n",
       "      <td>-0.722797</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>0.371050</td>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>-0.032908</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>-0.030196</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D2</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>-0.211975</td>\n",
       "      <td>0.098384</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>-0.471042</td>\n",
       "      <td>0.471042</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585870</td>\n",
       "      <td>0.216305</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>-0.021172</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>-0.087505</td>\n",
       "      <td>-0.090341</td>\n",
       "      <td>-0.086722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D3</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.155414</td>\n",
       "      <td>-0.179604</td>\n",
       "      <td>0.094162</td>\n",
       "      <td>0.136077</td>\n",
       "      <td>-0.246894</td>\n",
       "      <td>0.246894</td>\n",
       "      <td>0.371050</td>\n",
       "      <td>0.585870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440823</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.012112</td>\n",
       "      <td>-0.020128</td>\n",
       "      <td>-0.016641</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.120978</td>\n",
       "      <td>-0.126993</td>\n",
       "      <td>-0.114686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D4</td>\n",
       "      <td>-0.003069</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>-0.116881</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>0.102025</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.216305</td>\n",
       "      <td>0.440823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.056946</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>-0.077982</td>\n",
       "      <td>-0.073660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_1</td>\n",
       "      <td>-0.028075</td>\n",
       "      <td>-0.031009</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.003605</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136445</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>-0.117898</td>\n",
       "      <td>-0.153304</td>\n",
       "      <td>-0.124828</td>\n",
       "      <td>-0.094944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_2</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>-0.019457</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>-0.012112</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.136445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127114</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>-0.022026</td>\n",
       "      <td>-0.098343</td>\n",
       "      <td>-0.132457</td>\n",
       "      <td>-0.104374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_3</td>\n",
       "      <td>-0.075665</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>-0.020128</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.127114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092419</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>-0.014444</td>\n",
       "      <td>-0.076734</td>\n",
       "      <td>-0.138960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_4</td>\n",
       "      <td>-0.080226</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.036142</td>\n",
       "      <td>-0.014886</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>-0.007870</td>\n",
       "      <td>-0.032908</td>\n",
       "      <td>-0.021172</td>\n",
       "      <td>-0.016641</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.092419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>-0.080317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_1</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>-0.052992</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>-0.021974</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.056946</td>\n",
       "      <td>-0.117898</td>\n",
       "      <td>-0.022026</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877481</td>\n",
       "      <td>0.769969</td>\n",
       "      <td>0.695622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_2</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>-0.038563</td>\n",
       "      <td>0.113086</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>-0.059147</td>\n",
       "      <td>0.036124</td>\n",
       "      <td>-0.036124</td>\n",
       "      <td>-0.030196</td>\n",
       "      <td>-0.087505</td>\n",
       "      <td>-0.120978</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>-0.153304</td>\n",
       "      <td>-0.098343</td>\n",
       "      <td>-0.014444</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.877481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869587</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_3</td>\n",
       "      <td>0.043749</td>\n",
       "      <td>-0.065824</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>-0.046783</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>-0.032575</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.090341</td>\n",
       "      <td>-0.126993</td>\n",
       "      <td>-0.077982</td>\n",
       "      <td>-0.124828</td>\n",
       "      <td>-0.132457</td>\n",
       "      <td>-0.076734</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.769969</td>\n",
       "      <td>0.869587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_4</td>\n",
       "      <td>0.078619</td>\n",
       "      <td>-0.117800</td>\n",
       "      <td>0.109455</td>\n",
       "      <td>0.046041</td>\n",
       "      <td>-0.023749</td>\n",
       "      <td>0.031823</td>\n",
       "      <td>-0.031823</td>\n",
       "      <td>-0.011003</td>\n",
       "      <td>-0.086722</td>\n",
       "      <td>-0.114686</td>\n",
       "      <td>-0.073660</td>\n",
       "      <td>-0.094944</td>\n",
       "      <td>-0.104374</td>\n",
       "      <td>-0.138960</td>\n",
       "      <td>-0.080317</td>\n",
       "      <td>0.695622</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.849300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FIRE_SIZE_CLASS  DISCOVERY_MONTH_CONVERTED  \\\n",
       "FIRE_SIZE_CLASS                   1.000000                  -0.041246   \n",
       "DISCOVERY_MONTH_CONVERTED        -0.041246                   1.000000   \n",
       "FIRE_YEAR                        -0.031566                  -0.052756   \n",
       "AVE_SIZE12                        0.163815                   0.029308   \n",
       "CROP_ACR12                        0.153558                   0.005049   \n",
       "None                             -0.061832                  -0.114252   \n",
       "D0                                0.061832                   0.114252   \n",
       "D1                                0.085644                   0.093930   \n",
       "D2                                0.033487                   0.139979   \n",
       "D3                                0.004514                   0.155414   \n",
       "D4                               -0.003069                   0.046775   \n",
       "DAY_PRCP_1                       -0.028075                  -0.031009   \n",
       "DAY_PRCP_2                       -0.055122                   0.010065   \n",
       "DAY_PRCP_3                       -0.075665                   0.027465   \n",
       "DAY_PRCP_4                       -0.080226                   0.009608   \n",
       "DAY_AVG_TEMP_1                    0.011915                  -0.014133   \n",
       "DAY_AVG_TEMP_2                    0.009872                  -0.038563   \n",
       "DAY_AVG_TEMP_3                    0.043749                  -0.065824   \n",
       "DAY_AVG_TEMP_4                    0.078619                  -0.117800   \n",
       "\n",
       "                           FIRE_YEAR  AVE_SIZE12  CROP_ACR12      None  \\\n",
       "FIRE_SIZE_CLASS            -0.031566    0.163815    0.153558 -0.061832   \n",
       "DISCOVERY_MONTH_CONVERTED  -0.052756    0.029308    0.005049 -0.114252   \n",
       "FIRE_YEAR                   1.000000   -0.139417   -0.188559  0.123206   \n",
       "AVE_SIZE12                 -0.139417    1.000000    0.577044 -0.132600   \n",
       "CROP_ACR12                 -0.188559    0.577044    1.000000 -0.131695   \n",
       "None                        0.123206   -0.132600   -0.131695  1.000000   \n",
       "D0                         -0.123206    0.132600    0.131695 -1.000000   \n",
       "D1                         -0.167924    0.141231    0.139625 -0.722797   \n",
       "D2                         -0.211975    0.098384    0.109089 -0.471042   \n",
       "D3                         -0.179604    0.094162    0.136077 -0.246894   \n",
       "D4                         -0.116881    0.044858    0.102025 -0.088997   \n",
       "DAY_PRCP_1                  0.034387   -0.005764   -0.003605  0.007993   \n",
       "DAY_PRCP_2                  0.048676   -0.019457   -0.024724 -0.011623   \n",
       "DAY_PRCP_3                  0.028215   -0.006819   -0.031351 -0.008244   \n",
       "DAY_PRCP_4                  0.036142   -0.014886   -0.012383  0.007870   \n",
       "DAY_AVG_TEMP_1              0.117933    0.021817   -0.052992  0.021974   \n",
       "DAY_AVG_TEMP_2              0.113086    0.030689   -0.059147  0.036124   \n",
       "DAY_AVG_TEMP_3              0.105979    0.047380   -0.046783  0.032575   \n",
       "DAY_AVG_TEMP_4              0.109455    0.046041   -0.023749  0.031823   \n",
       "\n",
       "                                 D0        D1        D2        D3        D4  \\\n",
       "FIRE_SIZE_CLASS            0.061832  0.085644  0.033487  0.004514 -0.003069   \n",
       "DISCOVERY_MONTH_CONVERTED  0.114252  0.093930  0.139979  0.155414  0.046775   \n",
       "FIRE_YEAR                 -0.123206 -0.167924 -0.211975 -0.179604 -0.116881   \n",
       "AVE_SIZE12                 0.132600  0.141231  0.098384  0.094162  0.044858   \n",
       "CROP_ACR12                 0.131695  0.139625  0.109089  0.136077  0.102025   \n",
       "None                      -1.000000 -0.722797 -0.471042 -0.246894 -0.088997   \n",
       "D0                         1.000000  0.722797  0.471042  0.246894  0.088997   \n",
       "D1                         0.722797  1.000000  0.704019  0.371050  0.134097   \n",
       "D2                         0.471042  0.704019  1.000000  0.585870  0.216305   \n",
       "D3                         0.246894  0.371050  0.585870  1.000000  0.440823   \n",
       "D4                         0.088997  0.134097  0.216305  0.440823  1.000000   \n",
       "DAY_PRCP_1                -0.007993  0.006476  0.024966 -0.002278  0.001515   \n",
       "DAY_PRCP_2                 0.011623  0.009556  0.013385 -0.012112  0.001186   \n",
       "DAY_PRCP_3                 0.008244 -0.006602  0.009985 -0.020128  0.001011   \n",
       "DAY_PRCP_4                -0.007870 -0.032908 -0.021172 -0.016641 -0.002063   \n",
       "DAY_AVG_TEMP_1            -0.021974 -0.017714 -0.074823 -0.115261 -0.056946   \n",
       "DAY_AVG_TEMP_2            -0.036124 -0.030196 -0.087505 -0.120978 -0.078471   \n",
       "DAY_AVG_TEMP_3            -0.032575 -0.023075 -0.090341 -0.126993 -0.077982   \n",
       "DAY_AVG_TEMP_4            -0.031823 -0.011003 -0.086722 -0.114686 -0.073660   \n",
       "\n",
       "                           DAY_PRCP_1  DAY_PRCP_2  DAY_PRCP_3  DAY_PRCP_4  \\\n",
       "FIRE_SIZE_CLASS             -0.028075   -0.055122   -0.075665   -0.080226   \n",
       "DISCOVERY_MONTH_CONVERTED   -0.031009    0.010065    0.027465    0.009608   \n",
       "FIRE_YEAR                    0.034387    0.048676    0.028215    0.036142   \n",
       "AVE_SIZE12                  -0.005764   -0.019457   -0.006819   -0.014886   \n",
       "CROP_ACR12                  -0.003605   -0.024724   -0.031351   -0.012383   \n",
       "None                         0.007993   -0.011623   -0.008244    0.007870   \n",
       "D0                          -0.007993    0.011623    0.008244   -0.007870   \n",
       "D1                           0.006476    0.009556   -0.006602   -0.032908   \n",
       "D2                           0.024966    0.013385    0.009985   -0.021172   \n",
       "D3                          -0.002278   -0.012112   -0.020128   -0.016641   \n",
       "D4                           0.001515    0.001186    0.001011   -0.002063   \n",
       "DAY_PRCP_1                   1.000000    0.136445    0.051241    0.008809   \n",
       "DAY_PRCP_2                   0.136445    1.000000    0.127114    0.020576   \n",
       "DAY_PRCP_3                   0.051241    0.127114    1.000000    0.092419   \n",
       "DAY_PRCP_4                   0.008809    0.020576    0.092419    1.000000   \n",
       "DAY_AVG_TEMP_1              -0.117898   -0.022026    0.005253    0.015917   \n",
       "DAY_AVG_TEMP_2              -0.153304   -0.098343   -0.014444    0.021574   \n",
       "DAY_AVG_TEMP_3              -0.124828   -0.132457   -0.076734   -0.003134   \n",
       "DAY_AVG_TEMP_4              -0.094944   -0.104374   -0.138960   -0.080317   \n",
       "\n",
       "                           DAY_AVG_TEMP_1  DAY_AVG_TEMP_2  DAY_AVG_TEMP_3  \\\n",
       "FIRE_SIZE_CLASS                  0.011915        0.009872        0.043749   \n",
       "DISCOVERY_MONTH_CONVERTED       -0.014133       -0.038563       -0.065824   \n",
       "FIRE_YEAR                        0.117933        0.113086        0.105979   \n",
       "AVE_SIZE12                       0.021817        0.030689        0.047380   \n",
       "CROP_ACR12                      -0.052992       -0.059147       -0.046783   \n",
       "None                             0.021974        0.036124        0.032575   \n",
       "D0                              -0.021974       -0.036124       -0.032575   \n",
       "D1                              -0.017714       -0.030196       -0.023075   \n",
       "D2                              -0.074823       -0.087505       -0.090341   \n",
       "D3                              -0.115261       -0.120978       -0.126993   \n",
       "D4                              -0.056946       -0.078471       -0.077982   \n",
       "DAY_PRCP_1                      -0.117898       -0.153304       -0.124828   \n",
       "DAY_PRCP_2                      -0.022026       -0.098343       -0.132457   \n",
       "DAY_PRCP_3                       0.005253       -0.014444       -0.076734   \n",
       "DAY_PRCP_4                       0.015917        0.021574       -0.003134   \n",
       "DAY_AVG_TEMP_1                   1.000000        0.877481        0.769969   \n",
       "DAY_AVG_TEMP_2                   0.877481        1.000000        0.869587   \n",
       "DAY_AVG_TEMP_3                   0.769969        0.869587        1.000000   \n",
       "DAY_AVG_TEMP_4                   0.695622        0.753000        0.849300   \n",
       "\n",
       "                           DAY_AVG_TEMP_4  \n",
       "FIRE_SIZE_CLASS                  0.078619  \n",
       "DISCOVERY_MONTH_CONVERTED       -0.117800  \n",
       "FIRE_YEAR                        0.109455  \n",
       "AVE_SIZE12                       0.046041  \n",
       "CROP_ACR12                      -0.023749  \n",
       "None                             0.031823  \n",
       "D0                              -0.031823  \n",
       "D1                              -0.011003  \n",
       "D2                              -0.086722  \n",
       "D3                              -0.114686  \n",
       "D4                              -0.073660  \n",
       "DAY_PRCP_1                      -0.094944  \n",
       "DAY_PRCP_2                      -0.104374  \n",
       "DAY_PRCP_3                      -0.138960  \n",
       "DAY_PRCP_4                      -0.080317  \n",
       "DAY_AVG_TEMP_1                   0.695622  \n",
       "DAY_AVG_TEMP_2                   0.753000  \n",
       "DAY_AVG_TEMP_3                   0.849300  \n",
       "DAY_AVG_TEMP_4                   1.000000  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_df = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'DISCOVERY_MONTH_CONVERTED', 'DISCOVERY_DATE_CONVERTED', 'FIRE_YEAR', 'STAT_CAUSE_DESCR', 'AVE_SIZE12', 'CROP_ACR12', 'NAME', \n",
    "                                         'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', \n",
    "                                         'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# Corr_df = idaho_Fire_Weather_Drought_df[['NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "#                                    'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "    \n",
    "Corr_df['FIRE_SIZE_CLASS']= Corr_df['FIRE_SIZE_CLASS'].astype('category').cat.codes\n",
    "\n",
    "Corr_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING A NEURAL NETWORK MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INVESTIGATING INPUTS\n",
    "# # Possible X columns\n",
    "# # [['DISCOVERY_MONTH_CONVERTED', 'FIRE_SIZE_CLASS', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', \n",
    "# #   'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# New_df = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_DATE_CONVERTED', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "#                                    'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "# New_df['FIRE_SIZE_CLASS']= New_df['FIRE_SIZE_CLASS'].astype('category').cat.codes\n",
    "# # New_df['AVE_FAM_SZ']= New_df['AVE_FAM_SZ'].apply(lambda x: x//1)\n",
    "\n",
    "# # Drop Y column\n",
    "# New_df = New_df.drop(['FIRE_SIZE_CLASS'], axis=1)\n",
    "# New_df = New_df.drop(['STAT_CAUSE_DESCR'], axis=1)\n",
    "\n",
    "# # Run PCA \n",
    "# from sklearn.decomposition import PCA\n",
    "# n_components=40\n",
    "# pca = PCA(n_components=n_components)\n",
    "\n",
    "# # Create multiple columns for County \"NAME\"\n",
    "# New_df = pd.get_dummies(New_df, columns=['NAME'])\n",
    "# # New_df = pd.get_dummies(New_df, columns=['STAT_CAUSE_DESCR'])\n",
    "\n",
    "# NoOfCols = n_components\n",
    "\n",
    "# X_Array = New_df.to_numpy()\n",
    "# pca.fit(X_Array)\n",
    "# # print(pca.singular_values_)\n",
    "# x = pca.transform(X_Array)\n",
    "# x\n",
    "# # print(x.shape)\n",
    "# # type(x)\n",
    "# # x\n",
    "\n",
    "# NoOfCols = n_components\n",
    "# NoOfRuns = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X Input is (14902, 48)\n",
      "Type of X input is <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.   , 60.   ,  0.125, ...,  0.   ,  0.   ,  0.   ],\n",
       "       [ 7.   , 40.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       [ 7.   , 40.   ,  0.   , ...,  0.   ,  0.   ,  0.   ],\n",
       "       ...,\n",
       "       [10.   , 80.   ,  0.225, ...,  0.   ,  0.   ,  0.   ],\n",
       "       [10.   , 60.35 ,  0.   , ...,  0.   ,  1.   ,  0.   ],\n",
       "       [10.   , 80.   ,  0.   , ...,  0.   ,  0.   ,  0.   ]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE X VALUES\n",
    "# X by Keep\n",
    "X = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_MONTH_CONVERTED', 'DISCOVERY_DATE_CONVERTED', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', \n",
    "                                   'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', \n",
    "                                   'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# GET AVERAGE VALUES FOR DROUGHT (D0-D4), PRECIPITATION AND TEMP\n",
    "X['AV_D'] = (X['D0'] + X['D1'] + X['D2'] + X['D3'] + X['D4'])  / 5\n",
    "X['AV_PRCP'] = (X['DAY_PRCP_1'] + X['DAY_PRCP_2'] + X['DAY_PRCP_3'] + X['DAY_PRCP_4'])  / 4\n",
    "X['AV_TEMP'] = (X['DAY_AVG_TEMP_1'] + X['DAY_AVG_TEMP_2'] + X['DAY_AVG_TEMP_3'] + X['DAY_AVG_TEMP_4'])  / 4\n",
    "\n",
    "# ADD COLUMNS FIRE_SIZE_FLAG COLUMN AND IDAHO COLUMNS THAT HAVE NO FIRE INFO (FOR COMPLETENESS)\n",
    "X['NAME_Jerome'] = 0\n",
    "X['NAME_Kootenai'] = 0\n",
    "\n",
    "# DROP UNWANTED COLUMNS\n",
    "X = X.drop(['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_DATE_CONVERTED', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', 'None',\n",
    "'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4'], axis=1)\n",
    "# X = pd.get_dummies(X, columns=['STAT_CAUSE_DESCR'])\n",
    "X = pd.get_dummies(X, columns=['NAME'])\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# # TO OUTPUT CSVs FILTERED BY FIRE SIZE\n",
    "# # Filter \n",
    "# class1_df = X.loc[(X['FIRE_SIZE_CLASS']== 'A')]\n",
    "# class1_df\n",
    "\n",
    "# # # OUTPUT THE AND UPDATED CSV FILE\n",
    "# Class1_firesOutput_path = os.path.join(\"..\", \"Data\", \"Class1_fires.csv\")\n",
    "# with open(Class1_firesOutput_path, 'w') as csvfile:\n",
    "#         class1_df.to_csv(Class1_firesOutput_path, index=False)\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "# # Interim views\n",
    "# print(X.dtypes)\n",
    "# print(len(X.columns))\n",
    "# print(X.columns)\n",
    "# # X\n",
    "\n",
    "# seed values for reshape and no of ML runs (epochs)\n",
    "NoOfCols = 48\n",
    "NoOfRuns = 1000\n",
    "\n",
    "# # Reshape X from df to array v1\n",
    "X = X.values.reshape(-1, NoOfCols)\n",
    "\n",
    "# # Reshape X from df to array v2\n",
    "# X = X.to_numpy()\n",
    "\n",
    "# # View output\n",
    "print(f\"Shape of X Input is {X.shape}\")\n",
    "print(f\"Type of X input is {type(X)}\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y is (14902, 1)\n",
      "Type of y is <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE y VALUES\n",
    "y = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS']]\n",
    "\n",
    "# ADD COLUMNS FIRE_SIZE_FLAG COLUMN\n",
    "y['FIRE_SIZE_FLAG'] = 0\n",
    "\n",
    "# CREATE A FIRE CLASS SIZE SIZE E, F, G = FLAG 1, SIZE A, B, C, D = FLAG 0\n",
    "# y.loc[(y['FIRE_SIZE_CLASS'] == 'E') | (y['FIRE_SIZE_CLASS'] == 'F') | (y['FIRE_SIZE_CLASS'] == 'G'), 'FIRE_SIZE_FLAG'] = 1\n",
    "y.loc[(y['FIRE_SIZE_CLASS'] == 'F') | (y['FIRE_SIZE_CLASS'] == 'G'), 'FIRE_SIZE_FLAG'] = 2\n",
    "y.loc[(y['FIRE_SIZE_CLASS'] == 'D') | (y['FIRE_SIZE_CLASS'] == 'D'), 'FIRE_SIZE_FLAG'] = 1\n",
    "\n",
    "# DROP FIRE_SIZE_CLASS COLUMNS\n",
    "y = y.drop(['FIRE_SIZE_CLASS'], axis=1)\n",
    "\n",
    "# y = idaho_Fire_Weather_Drought_df[['STAT_CAUSE_DESCR', 'FIRE_SIZE_CLASS']]\n",
    "# y = pd.get_dummies(y, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "\n",
    "# y = y.values.reshape(-1, 2)\n",
    "\n",
    "# print(y.shape)\n",
    "# # type(y)\n",
    "# y\n",
    "\n",
    "# LABEL ENCODE Y\n",
    "# Import required module\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create an object of the label encoder class\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# apply \"le.fit_transform\"\n",
    "old_y = y.apply(le.fit_transform)\n",
    "y = old_y\n",
    "\n",
    "# # Change the shape of y v1\n",
    "new_y = np.array(old_y)\n",
    "y = new_y.reshape(-1, 1) \n",
    "\n",
    "# View output\n",
    "print(f\"Shape of y is {y.shape}\")\n",
    "print(f\"Type of y is {type(y)}\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AND TRIAN SPLITS, SCALE X AND CATEGORIZE Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train: (11176, 1)\n",
      "X train: (11176, 48)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "print(f\"y train: {y_train.shape}\")\n",
    "print(f\"X train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11176, 48)\n"
     ]
    }
   ],
   "source": [
    "# # Scale your data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# # y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# # Create variables to hold the scaled train & test data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# # y_train_scaled = y_scaler.transform(y_train)\n",
    "# # y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y train data: [[0]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      " Categorical y training data: (11176, 3)\n",
      " Categorical y training data: [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "### Encode the categorical target variable to the necessary format for the model\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# preview data\n",
    "print(f\" y train data: {y_train}\")\n",
    "print(f\" Categorical y training data: {y_train_categorical.shape}\")\n",
    "print(f\" Categorical y training data: {y_train_categorical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11176, 48)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X Inputs\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11176, 48)\n",
      "(11176, 48)\n",
      "(11176, 3)\n"
     ]
    }
   ],
   "source": [
    "# X Inputs\n",
    "print(X_train.shape)\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "# Y Inputs\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 20)                980       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 53,591\n",
      "Trainable params: 53,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Normal neural network with X inputs, 1 hidden layer, 10 nodes in hidden layer, and 7 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "fire_model_v1 = Sequential()\n",
    "fire_model_v1.add(Dense(units=20, activation='sigmoid', input_dim=NoOfCols))\n",
    "fire_model_v1.add(Dense(128, activation='relu'))\n",
    "fire_model_v1.add(Dense(128, activation='sigmoid'))\n",
    "fire_model_v1.add(Dropout(.1))\n",
    "fire_model_v1.add(Dense(128, activation='relu'))\n",
    "fire_model_v1.add(Dense(128, activation='sigmoid'))\n",
    "fire_model_v1.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# view the model's architecture\n",
    "fire_model_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "350/350 - 1s - loss: 0.3504 - accuracy: 0.9137\n",
      "Epoch 2/1000\n",
      "350/350 - 0s - loss: 0.3294 - accuracy: 0.9162\n",
      "Epoch 3/1000\n",
      "350/350 - 0s - loss: 0.3267 - accuracy: 0.9162\n",
      "Epoch 4/1000\n",
      "350/350 - 0s - loss: 0.3259 - accuracy: 0.9162\n",
      "Epoch 5/1000\n",
      "350/350 - 0s - loss: 0.3262 - accuracy: 0.9162\n",
      "Epoch 6/1000\n",
      "350/350 - 0s - loss: 0.3248 - accuracy: 0.9162\n",
      "Epoch 7/1000\n",
      "350/350 - 0s - loss: 0.3249 - accuracy: 0.9162\n",
      "Epoch 8/1000\n",
      "350/350 - 0s - loss: 0.3244 - accuracy: 0.9162\n",
      "Epoch 9/1000\n",
      "350/350 - 0s - loss: 0.3235 - accuracy: 0.9162\n",
      "Epoch 10/1000\n",
      "350/350 - 0s - loss: 0.3244 - accuracy: 0.9162\n",
      "Epoch 11/1000\n",
      "350/350 - 0s - loss: 0.3235 - accuracy: 0.9162\n",
      "Epoch 12/1000\n",
      "350/350 - 0s - loss: 0.3234 - accuracy: 0.9162\n",
      "Epoch 13/1000\n",
      "350/350 - 0s - loss: 0.3229 - accuracy: 0.9162\n",
      "Epoch 14/1000\n",
      "350/350 - 0s - loss: 0.3225 - accuracy: 0.9162\n",
      "Epoch 15/1000\n",
      "350/350 - 0s - loss: 0.3223 - accuracy: 0.9162\n",
      "Epoch 16/1000\n",
      "350/350 - 0s - loss: 0.3221 - accuracy: 0.9162\n",
      "Epoch 17/1000\n",
      "350/350 - 0s - loss: 0.3217 - accuracy: 0.9162\n",
      "Epoch 18/1000\n",
      "350/350 - 0s - loss: 0.3197 - accuracy: 0.9162\n",
      "Epoch 19/1000\n",
      "350/350 - 0s - loss: 0.3197 - accuracy: 0.9162\n",
      "Epoch 20/1000\n",
      "350/350 - 0s - loss: 0.3182 - accuracy: 0.9162\n",
      "Epoch 21/1000\n",
      "350/350 - 0s - loss: 0.3178 - accuracy: 0.9162\n",
      "Epoch 22/1000\n",
      "350/350 - 0s - loss: 0.3172 - accuracy: 0.9162\n",
      "Epoch 23/1000\n",
      "350/350 - 0s - loss: 0.3175 - accuracy: 0.9162\n",
      "Epoch 24/1000\n",
      "350/350 - 0s - loss: 0.3160 - accuracy: 0.9162\n",
      "Epoch 25/1000\n",
      "350/350 - 0s - loss: 0.3153 - accuracy: 0.9162\n",
      "Epoch 26/1000\n",
      "350/350 - 0s - loss: 0.3162 - accuracy: 0.9162\n",
      "Epoch 27/1000\n",
      "350/350 - 0s - loss: 0.3146 - accuracy: 0.9162\n",
      "Epoch 28/1000\n",
      "350/350 - 0s - loss: 0.3130 - accuracy: 0.9162\n",
      "Epoch 29/1000\n",
      "350/350 - 0s - loss: 0.3130 - accuracy: 0.9162\n",
      "Epoch 30/1000\n",
      "350/350 - 0s - loss: 0.3121 - accuracy: 0.9162\n",
      "Epoch 31/1000\n",
      "350/350 - 0s - loss: 0.3121 - accuracy: 0.9162\n",
      "Epoch 32/1000\n",
      "350/350 - 0s - loss: 0.3122 - accuracy: 0.9162\n",
      "Epoch 33/1000\n",
      "350/350 - 0s - loss: 0.3124 - accuracy: 0.9162\n",
      "Epoch 34/1000\n",
      "350/350 - 0s - loss: 0.3109 - accuracy: 0.9162\n",
      "Epoch 35/1000\n",
      "350/350 - 0s - loss: 0.3113 - accuracy: 0.9162\n",
      "Epoch 36/1000\n",
      "350/350 - 0s - loss: 0.3095 - accuracy: 0.9162\n",
      "Epoch 37/1000\n",
      "350/350 - 0s - loss: 0.3109 - accuracy: 0.9162\n",
      "Epoch 38/1000\n",
      "350/350 - 0s - loss: 0.3092 - accuracy: 0.9162\n",
      "Epoch 39/1000\n",
      "350/350 - 0s - loss: 0.3086 - accuracy: 0.9162\n",
      "Epoch 40/1000\n",
      "350/350 - 0s - loss: 0.3079 - accuracy: 0.9162\n",
      "Epoch 41/1000\n",
      "350/350 - 0s - loss: 0.3078 - accuracy: 0.9162\n",
      "Epoch 42/1000\n",
      "350/350 - 0s - loss: 0.3072 - accuracy: 0.9162\n",
      "Epoch 43/1000\n",
      "350/350 - 0s - loss: 0.3064 - accuracy: 0.9162\n",
      "Epoch 44/1000\n",
      "350/350 - 0s - loss: 0.3057 - accuracy: 0.9162\n",
      "Epoch 45/1000\n",
      "350/350 - 0s - loss: 0.3052 - accuracy: 0.9162\n",
      "Epoch 46/1000\n",
      "350/350 - 0s - loss: 0.3046 - accuracy: 0.9162\n",
      "Epoch 47/1000\n",
      "350/350 - 0s - loss: 0.3042 - accuracy: 0.9162\n",
      "Epoch 48/1000\n",
      "350/350 - 0s - loss: 0.3026 - accuracy: 0.9162\n",
      "Epoch 49/1000\n",
      "350/350 - 0s - loss: 0.3039 - accuracy: 0.9162\n",
      "Epoch 50/1000\n",
      "350/350 - 0s - loss: 0.3029 - accuracy: 0.9162\n",
      "Epoch 51/1000\n",
      "350/350 - 0s - loss: 0.3020 - accuracy: 0.9162\n",
      "Epoch 52/1000\n",
      "350/350 - 0s - loss: 0.3016 - accuracy: 0.9162\n",
      "Epoch 53/1000\n",
      "350/350 - 0s - loss: 0.3021 - accuracy: 0.9162\n",
      "Epoch 54/1000\n",
      "350/350 - 0s - loss: 0.3000 - accuracy: 0.9162\n",
      "Epoch 55/1000\n",
      "350/350 - 0s - loss: 0.3004 - accuracy: 0.9162\n",
      "Epoch 56/1000\n",
      "350/350 - 0s - loss: 0.2988 - accuracy: 0.9162\n",
      "Epoch 57/1000\n",
      "350/350 - 0s - loss: 0.2995 - accuracy: 0.9162\n",
      "Epoch 58/1000\n",
      "350/350 - 0s - loss: 0.2992 - accuracy: 0.9162\n",
      "Epoch 59/1000\n",
      "350/350 - 0s - loss: 0.2980 - accuracy: 0.9162\n",
      "Epoch 60/1000\n",
      "350/350 - 0s - loss: 0.2969 - accuracy: 0.9162\n",
      "Epoch 61/1000\n",
      "350/350 - 1s - loss: 0.2976 - accuracy: 0.9162\n",
      "Epoch 62/1000\n",
      "350/350 - 1s - loss: 0.2965 - accuracy: 0.9162\n",
      "Epoch 63/1000\n",
      "350/350 - 0s - loss: 0.2949 - accuracy: 0.9164\n",
      "Epoch 64/1000\n",
      "350/350 - 1s - loss: 0.2959 - accuracy: 0.9167\n",
      "Epoch 65/1000\n",
      "350/350 - 1s - loss: 0.2953 - accuracy: 0.9164\n",
      "Epoch 66/1000\n",
      "350/350 - 1s - loss: 0.2955 - accuracy: 0.9161\n",
      "Epoch 67/1000\n",
      "350/350 - 0s - loss: 0.2938 - accuracy: 0.9162\n",
      "Epoch 68/1000\n",
      "350/350 - 1s - loss: 0.2931 - accuracy: 0.9162\n",
      "Epoch 69/1000\n",
      "350/350 - 1s - loss: 0.2925 - accuracy: 0.9163\n",
      "Epoch 70/1000\n",
      "350/350 - 0s - loss: 0.2916 - accuracy: 0.9162\n",
      "Epoch 71/1000\n",
      "350/350 - 1s - loss: 0.2916 - accuracy: 0.9163\n",
      "Epoch 72/1000\n",
      "350/350 - 1s - loss: 0.2909 - accuracy: 0.9160\n",
      "Epoch 73/1000\n",
      "350/350 - 1s - loss: 0.2913 - accuracy: 0.9161\n",
      "Epoch 74/1000\n",
      "350/350 - 0s - loss: 0.2897 - accuracy: 0.9163\n",
      "Epoch 75/1000\n",
      "350/350 - 1s - loss: 0.2898 - accuracy: 0.9168\n",
      "Epoch 76/1000\n",
      "350/350 - 0s - loss: 0.2897 - accuracy: 0.9162\n",
      "Epoch 77/1000\n",
      "350/350 - 1s - loss: 0.2876 - accuracy: 0.9169\n",
      "Epoch 78/1000\n",
      "350/350 - 0s - loss: 0.2887 - accuracy: 0.9163\n",
      "Epoch 79/1000\n",
      "350/350 - 1s - loss: 0.2868 - accuracy: 0.9168\n",
      "Epoch 80/1000\n",
      "350/350 - 1s - loss: 0.2865 - accuracy: 0.9171\n",
      "Epoch 81/1000\n",
      "350/350 - 1s - loss: 0.2852 - accuracy: 0.9167\n",
      "Epoch 82/1000\n",
      "350/350 - 1s - loss: 0.2859 - accuracy: 0.9164\n",
      "Epoch 83/1000\n",
      "350/350 - 1s - loss: 0.2847 - accuracy: 0.9171\n",
      "Epoch 84/1000\n",
      "350/350 - 1s - loss: 0.2841 - accuracy: 0.9174\n",
      "Epoch 85/1000\n",
      "350/350 - 1s - loss: 0.2839 - accuracy: 0.9170\n",
      "Epoch 86/1000\n",
      "350/350 - 1s - loss: 0.2829 - accuracy: 0.9173\n",
      "Epoch 87/1000\n",
      "350/350 - 1s - loss: 0.2829 - accuracy: 0.9172\n",
      "Epoch 88/1000\n",
      "350/350 - 1s - loss: 0.2820 - accuracy: 0.9175\n",
      "Epoch 89/1000\n",
      "350/350 - 1s - loss: 0.2801 - accuracy: 0.9174\n",
      "Epoch 90/1000\n",
      "350/350 - 1s - loss: 0.2804 - accuracy: 0.9178\n",
      "Epoch 91/1000\n",
      "350/350 - 1s - loss: 0.2806 - accuracy: 0.9177\n",
      "Epoch 92/1000\n",
      "350/350 - 1s - loss: 0.2796 - accuracy: 0.9179\n",
      "Epoch 93/1000\n",
      "350/350 - 0s - loss: 0.2797 - accuracy: 0.9180\n",
      "Epoch 94/1000\n",
      "350/350 - 1s - loss: 0.2794 - accuracy: 0.9181\n",
      "Epoch 95/1000\n",
      "350/350 - 1s - loss: 0.2777 - accuracy: 0.9177\n",
      "Epoch 96/1000\n",
      "350/350 - 1s - loss: 0.2772 - accuracy: 0.9178\n",
      "Epoch 97/1000\n",
      "350/350 - 1s - loss: 0.2769 - accuracy: 0.9184\n",
      "Epoch 98/1000\n",
      "350/350 - 1s - loss: 0.2760 - accuracy: 0.9185\n",
      "Epoch 99/1000\n",
      "350/350 - 1s - loss: 0.2755 - accuracy: 0.9179\n",
      "Epoch 100/1000\n",
      "350/350 - 1s - loss: 0.2751 - accuracy: 0.9188\n",
      "Epoch 101/1000\n",
      "350/350 - 1s - loss: 0.2737 - accuracy: 0.9179\n",
      "Epoch 102/1000\n",
      "350/350 - 1s - loss: 0.2735 - accuracy: 0.9181\n",
      "Epoch 103/1000\n",
      "350/350 - 1s - loss: 0.2740 - accuracy: 0.9192\n",
      "Epoch 104/1000\n",
      "350/350 - 1s - loss: 0.2729 - accuracy: 0.9187\n",
      "Epoch 105/1000\n",
      "350/350 - 1s - loss: 0.2721 - accuracy: 0.9182\n",
      "Epoch 106/1000\n",
      "350/350 - 1s - loss: 0.2714 - accuracy: 0.9188\n",
      "Epoch 107/1000\n",
      "350/350 - 1s - loss: 0.2714 - accuracy: 0.9184\n",
      "Epoch 108/1000\n",
      "350/350 - 1s - loss: 0.2694 - accuracy: 0.9189\n",
      "Epoch 109/1000\n",
      "350/350 - 1s - loss: 0.2677 - accuracy: 0.9207\n",
      "Epoch 110/1000\n",
      "350/350 - 1s - loss: 0.2701 - accuracy: 0.9183\n",
      "Epoch 111/1000\n",
      "350/350 - 1s - loss: 0.2689 - accuracy: 0.9193\n",
      "Epoch 112/1000\n",
      "350/350 - 1s - loss: 0.2669 - accuracy: 0.9196\n",
      "Epoch 113/1000\n",
      "350/350 - 1s - loss: 0.2683 - accuracy: 0.9192\n",
      "Epoch 114/1000\n",
      "350/350 - 1s - loss: 0.2667 - accuracy: 0.9194\n",
      "Epoch 115/1000\n",
      "350/350 - 1s - loss: 0.2654 - accuracy: 0.9210\n",
      "Epoch 116/1000\n",
      "350/350 - 1s - loss: 0.2665 - accuracy: 0.9203\n",
      "Epoch 117/1000\n",
      "350/350 - 1s - loss: 0.2641 - accuracy: 0.9200\n",
      "Epoch 118/1000\n",
      "350/350 - 1s - loss: 0.2649 - accuracy: 0.9204\n",
      "Epoch 119/1000\n",
      "350/350 - 1s - loss: 0.2645 - accuracy: 0.9208\n",
      "Epoch 120/1000\n",
      "350/350 - 1s - loss: 0.2634 - accuracy: 0.9199\n",
      "Epoch 121/1000\n",
      "350/350 - 1s - loss: 0.2626 - accuracy: 0.9212\n",
      "Epoch 122/1000\n",
      "350/350 - 1s - loss: 0.2616 - accuracy: 0.9205\n",
      "Epoch 123/1000\n",
      "350/350 - 1s - loss: 0.2611 - accuracy: 0.9217\n",
      "Epoch 124/1000\n",
      "350/350 - 1s - loss: 0.2613 - accuracy: 0.9202\n",
      "Epoch 125/1000\n",
      "350/350 - 1s - loss: 0.2604 - accuracy: 0.9200\n",
      "Epoch 126/1000\n",
      "350/350 - 1s - loss: 0.2600 - accuracy: 0.9202\n",
      "Epoch 127/1000\n",
      "350/350 - 1s - loss: 0.2628 - accuracy: 0.9209\n",
      "Epoch 128/1000\n",
      "350/350 - 1s - loss: 0.2601 - accuracy: 0.9227\n",
      "Epoch 129/1000\n",
      "350/350 - 1s - loss: 0.2595 - accuracy: 0.9213\n",
      "Epoch 130/1000\n",
      "350/350 - 1s - loss: 0.2586 - accuracy: 0.9213\n",
      "Epoch 131/1000\n",
      "350/350 - 1s - loss: 0.2561 - accuracy: 0.9207\n",
      "Epoch 132/1000\n",
      "350/350 - 1s - loss: 0.2562 - accuracy: 0.9215\n",
      "Epoch 133/1000\n",
      "350/350 - 1s - loss: 0.2576 - accuracy: 0.9220\n",
      "Epoch 134/1000\n",
      "350/350 - 1s - loss: 0.2553 - accuracy: 0.9220\n",
      "Epoch 135/1000\n",
      "350/350 - 1s - loss: 0.2525 - accuracy: 0.9226\n",
      "Epoch 136/1000\n",
      "350/350 - 1s - loss: 0.2544 - accuracy: 0.9215\n",
      "Epoch 137/1000\n",
      "350/350 - 1s - loss: 0.2530 - accuracy: 0.9218\n",
      "Epoch 138/1000\n",
      "350/350 - 1s - loss: 0.2523 - accuracy: 0.9226\n",
      "Epoch 139/1000\n",
      "350/350 - 1s - loss: 0.2541 - accuracy: 0.9222\n",
      "Epoch 140/1000\n",
      "350/350 - 1s - loss: 0.2534 - accuracy: 0.9221\n",
      "Epoch 141/1000\n",
      "350/350 - 1s - loss: 0.2508 - accuracy: 0.9230\n",
      "Epoch 142/1000\n",
      "350/350 - 1s - loss: 0.2508 - accuracy: 0.9221\n",
      "Epoch 143/1000\n",
      "350/350 - 1s - loss: 0.2505 - accuracy: 0.9232\n",
      "Epoch 144/1000\n",
      "350/350 - 1s - loss: 0.2494 - accuracy: 0.9229\n",
      "Epoch 145/1000\n",
      "350/350 - 1s - loss: 0.2484 - accuracy: 0.9223\n",
      "Epoch 146/1000\n",
      "350/350 - 1s - loss: 0.2492 - accuracy: 0.9231\n",
      "Epoch 147/1000\n",
      "350/350 - 1s - loss: 0.2497 - accuracy: 0.9221\n",
      "Epoch 148/1000\n",
      "350/350 - 1s - loss: 0.2533 - accuracy: 0.9212\n",
      "Epoch 149/1000\n",
      "350/350 - 1s - loss: 0.2472 - accuracy: 0.9226\n",
      "Epoch 150/1000\n",
      "350/350 - 1s - loss: 0.2474 - accuracy: 0.9225\n",
      "Epoch 151/1000\n",
      "350/350 - 1s - loss: 0.2487 - accuracy: 0.9222\n",
      "Epoch 152/1000\n",
      "350/350 - 1s - loss: 0.2468 - accuracy: 0.9234\n",
      "Epoch 153/1000\n",
      "350/350 - 1s - loss: 0.2465 - accuracy: 0.9229\n",
      "Epoch 154/1000\n",
      "350/350 - 1s - loss: 0.2457 - accuracy: 0.9227\n",
      "Epoch 155/1000\n",
      "350/350 - 1s - loss: 0.2445 - accuracy: 0.9232\n",
      "Epoch 156/1000\n",
      "350/350 - 1s - loss: 0.2453 - accuracy: 0.9246\n",
      "Epoch 157/1000\n",
      "350/350 - 1s - loss: 0.2429 - accuracy: 0.9239\n",
      "Epoch 158/1000\n",
      "350/350 - 1s - loss: 0.2441 - accuracy: 0.9230\n",
      "Epoch 159/1000\n",
      "350/350 - 1s - loss: 0.2426 - accuracy: 0.9247\n",
      "Epoch 160/1000\n",
      "350/350 - 1s - loss: 0.2442 - accuracy: 0.9230\n",
      "Epoch 161/1000\n",
      "350/350 - 1s - loss: 0.2431 - accuracy: 0.9232\n",
      "Epoch 162/1000\n",
      "350/350 - 1s - loss: 0.2411 - accuracy: 0.9235\n",
      "Epoch 163/1000\n",
      "350/350 - 1s - loss: 0.2391 - accuracy: 0.9241\n",
      "Epoch 164/1000\n",
      "350/350 - 1s - loss: 0.2384 - accuracy: 0.9250\n",
      "Epoch 165/1000\n",
      "350/350 - 1s - loss: 0.2417 - accuracy: 0.9228\n",
      "Epoch 166/1000\n",
      "350/350 - 1s - loss: 0.2397 - accuracy: 0.9237\n",
      "Epoch 167/1000\n",
      "350/350 - 1s - loss: 0.2379 - accuracy: 0.9247\n",
      "Epoch 168/1000\n",
      "350/350 - 1s - loss: 0.2386 - accuracy: 0.9243\n",
      "Epoch 169/1000\n",
      "350/350 - 1s - loss: 0.2368 - accuracy: 0.9246\n",
      "Epoch 170/1000\n",
      "350/350 - 1s - loss: 0.2362 - accuracy: 0.9238\n",
      "Epoch 171/1000\n",
      "350/350 - 1s - loss: 0.2361 - accuracy: 0.9239\n",
      "Epoch 172/1000\n",
      "350/350 - 1s - loss: 0.2372 - accuracy: 0.9235\n",
      "Epoch 173/1000\n",
      "350/350 - 1s - loss: 0.2353 - accuracy: 0.9248\n",
      "Epoch 174/1000\n",
      "350/350 - 1s - loss: 0.2362 - accuracy: 0.9237\n",
      "Epoch 175/1000\n",
      "350/350 - 1s - loss: 0.2369 - accuracy: 0.9241\n",
      "Epoch 176/1000\n",
      "350/350 - 1s - loss: 0.2356 - accuracy: 0.9232\n",
      "Epoch 177/1000\n",
      "350/350 - 1s - loss: 0.2356 - accuracy: 0.9234\n",
      "Epoch 178/1000\n",
      "350/350 - 1s - loss: 0.2341 - accuracy: 0.9251\n",
      "Epoch 179/1000\n",
      "350/350 - 0s - loss: 0.2345 - accuracy: 0.9243\n",
      "Epoch 180/1000\n",
      "350/350 - 1s - loss: 0.2335 - accuracy: 0.9254\n",
      "Epoch 181/1000\n",
      "350/350 - 1s - loss: 0.2350 - accuracy: 0.9245\n",
      "Epoch 182/1000\n",
      "350/350 - 1s - loss: 0.2346 - accuracy: 0.9232\n",
      "Epoch 183/1000\n",
      "350/350 - 1s - loss: 0.2318 - accuracy: 0.9238\n",
      "Epoch 184/1000\n",
      "350/350 - 1s - loss: 0.2333 - accuracy: 0.9251\n",
      "Epoch 185/1000\n",
      "350/350 - 1s - loss: 0.2322 - accuracy: 0.9241\n",
      "Epoch 186/1000\n",
      "350/350 - 1s - loss: 0.2326 - accuracy: 0.9237\n",
      "Epoch 187/1000\n",
      "350/350 - 1s - loss: 0.2307 - accuracy: 0.9247\n",
      "Epoch 188/1000\n",
      "350/350 - 1s - loss: 0.2284 - accuracy: 0.9250\n",
      "Epoch 189/1000\n",
      "350/350 - 1s - loss: 0.2300 - accuracy: 0.9246\n",
      "Epoch 190/1000\n",
      "350/350 - 1s - loss: 0.2292 - accuracy: 0.9258\n",
      "Epoch 191/1000\n",
      "350/350 - 1s - loss: 0.2292 - accuracy: 0.9248\n",
      "Epoch 192/1000\n",
      "350/350 - 1s - loss: 0.2277 - accuracy: 0.9258\n",
      "Epoch 193/1000\n",
      "350/350 - 1s - loss: 0.2285 - accuracy: 0.9255\n",
      "Epoch 194/1000\n",
      "350/350 - 1s - loss: 0.2299 - accuracy: 0.9249\n",
      "Epoch 195/1000\n",
      "350/350 - 1s - loss: 0.2266 - accuracy: 0.9254\n",
      "Epoch 196/1000\n",
      "350/350 - 1s - loss: 0.2281 - accuracy: 0.9252\n",
      "Epoch 197/1000\n",
      "350/350 - 1s - loss: 0.2261 - accuracy: 0.9256\n",
      "Epoch 198/1000\n",
      "350/350 - 1s - loss: 0.2265 - accuracy: 0.9241\n",
      "Epoch 199/1000\n",
      "350/350 - 1s - loss: 0.2269 - accuracy: 0.9249\n",
      "Epoch 200/1000\n",
      "350/350 - 1s - loss: 0.2263 - accuracy: 0.9261\n",
      "Epoch 201/1000\n",
      "350/350 - 1s - loss: 0.2267 - accuracy: 0.9264\n",
      "Epoch 202/1000\n",
      "350/350 - 1s - loss: 0.2257 - accuracy: 0.9262\n",
      "Epoch 203/1000\n",
      "350/350 - 1s - loss: 0.2245 - accuracy: 0.9248\n",
      "Epoch 204/1000\n",
      "350/350 - 1s - loss: 0.2234 - accuracy: 0.9249\n",
      "Epoch 205/1000\n",
      "350/350 - 1s - loss: 0.2257 - accuracy: 0.9232\n",
      "Epoch 206/1000\n",
      "350/350 - 1s - loss: 0.2220 - accuracy: 0.9251\n",
      "Epoch 207/1000\n",
      "350/350 - 1s - loss: 0.2238 - accuracy: 0.9249\n",
      "Epoch 208/1000\n",
      "350/350 - 1s - loss: 0.2208 - accuracy: 0.9257\n",
      "Epoch 209/1000\n",
      "350/350 - 1s - loss: 0.2212 - accuracy: 0.9255\n",
      "Epoch 210/1000\n",
      "350/350 - 1s - loss: 0.2196 - accuracy: 0.9250\n",
      "Epoch 211/1000\n",
      "350/350 - 1s - loss: 0.2241 - accuracy: 0.9260\n",
      "Epoch 212/1000\n",
      "350/350 - 1s - loss: 0.2226 - accuracy: 0.9257\n",
      "Epoch 213/1000\n",
      "350/350 - 1s - loss: 0.2213 - accuracy: 0.9259\n",
      "Epoch 214/1000\n",
      "350/350 - 1s - loss: 0.2205 - accuracy: 0.9250\n",
      "Epoch 215/1000\n",
      "350/350 - 1s - loss: 0.2194 - accuracy: 0.9266\n",
      "Epoch 216/1000\n",
      "350/350 - 1s - loss: 0.2170 - accuracy: 0.9265\n",
      "Epoch 217/1000\n",
      "350/350 - 1s - loss: 0.2194 - accuracy: 0.9261\n",
      "Epoch 218/1000\n",
      "350/350 - 1s - loss: 0.2216 - accuracy: 0.9242\n",
      "Epoch 219/1000\n",
      "350/350 - 1s - loss: 0.2223 - accuracy: 0.9250\n",
      "Epoch 220/1000\n",
      "350/350 - 1s - loss: 0.2195 - accuracy: 0.9268\n",
      "Epoch 221/1000\n",
      "350/350 - 1s - loss: 0.2162 - accuracy: 0.9269\n",
      "Epoch 222/1000\n",
      "350/350 - 1s - loss: 0.2163 - accuracy: 0.9265\n",
      "Epoch 223/1000\n",
      "350/350 - 1s - loss: 0.2185 - accuracy: 0.9259\n",
      "Epoch 224/1000\n",
      "350/350 - 1s - loss: 0.2176 - accuracy: 0.9262\n",
      "Epoch 225/1000\n",
      "350/350 - 1s - loss: 0.2145 - accuracy: 0.9273\n",
      "Epoch 226/1000\n",
      "350/350 - 1s - loss: 0.2152 - accuracy: 0.9281\n",
      "Epoch 227/1000\n",
      "350/350 - 0s - loss: 0.2164 - accuracy: 0.9268\n",
      "Epoch 228/1000\n",
      "350/350 - 1s - loss: 0.2159 - accuracy: 0.9260\n",
      "Epoch 229/1000\n",
      "350/350 - 1s - loss: 0.2152 - accuracy: 0.9259\n",
      "Epoch 230/1000\n",
      "350/350 - 1s - loss: 0.2117 - accuracy: 0.9275\n",
      "Epoch 231/1000\n",
      "350/350 - 1s - loss: 0.2134 - accuracy: 0.9282\n",
      "Epoch 232/1000\n",
      "350/350 - 1s - loss: 0.2128 - accuracy: 0.9269\n",
      "Epoch 233/1000\n",
      "350/350 - 1s - loss: 0.2145 - accuracy: 0.9269\n",
      "Epoch 234/1000\n",
      "350/350 - 1s - loss: 0.2131 - accuracy: 0.9263\n",
      "Epoch 235/1000\n",
      "350/350 - 1s - loss: 0.2125 - accuracy: 0.9292\n",
      "Epoch 236/1000\n",
      "350/350 - 1s - loss: 0.2115 - accuracy: 0.9281\n",
      "Epoch 237/1000\n",
      "350/350 - 1s - loss: 0.2117 - accuracy: 0.9287\n",
      "Epoch 238/1000\n",
      "350/350 - 1s - loss: 0.2126 - accuracy: 0.9272\n",
      "Epoch 239/1000\n",
      "350/350 - 1s - loss: 0.2127 - accuracy: 0.9265\n",
      "Epoch 240/1000\n",
      "350/350 - 0s - loss: 0.2118 - accuracy: 0.9262\n",
      "Epoch 241/1000\n",
      "350/350 - 1s - loss: 0.2093 - accuracy: 0.9290\n",
      "Epoch 242/1000\n",
      "350/350 - 1s - loss: 0.2129 - accuracy: 0.9268\n",
      "Epoch 243/1000\n",
      "350/350 - 1s - loss: 0.2121 - accuracy: 0.9282\n",
      "Epoch 244/1000\n",
      "350/350 - 0s - loss: 0.2091 - accuracy: 0.9269\n",
      "Epoch 245/1000\n",
      "350/350 - 1s - loss: 0.2085 - accuracy: 0.9273\n",
      "Epoch 246/1000\n",
      "350/350 - 1s - loss: 0.2077 - accuracy: 0.9279\n",
      "Epoch 247/1000\n",
      "350/350 - 1s - loss: 0.2130 - accuracy: 0.9260\n",
      "Epoch 248/1000\n",
      "350/350 - 1s - loss: 0.2103 - accuracy: 0.9279\n",
      "Epoch 249/1000\n",
      "350/350 - 1s - loss: 0.2091 - accuracy: 0.9286\n",
      "Epoch 250/1000\n",
      "350/350 - 1s - loss: 0.2077 - accuracy: 0.9284\n",
      "Epoch 251/1000\n",
      "350/350 - 1s - loss: 0.2084 - accuracy: 0.9275\n",
      "Epoch 252/1000\n",
      "350/350 - 1s - loss: 0.2097 - accuracy: 0.9259\n",
      "Epoch 253/1000\n",
      "350/350 - 1s - loss: 0.2064 - accuracy: 0.9280\n",
      "Epoch 254/1000\n",
      "350/350 - 1s - loss: 0.2067 - accuracy: 0.9281\n",
      "Epoch 255/1000\n",
      "350/350 - 1s - loss: 0.2084 - accuracy: 0.9283\n",
      "Epoch 256/1000\n",
      "350/350 - 1s - loss: 0.2032 - accuracy: 0.9278\n",
      "Epoch 257/1000\n",
      "350/350 - 1s - loss: 0.2073 - accuracy: 0.9298\n",
      "Epoch 258/1000\n",
      "350/350 - 1s - loss: 0.2057 - accuracy: 0.9284\n",
      "Epoch 259/1000\n",
      "350/350 - 1s - loss: 0.2042 - accuracy: 0.9286\n",
      "Epoch 260/1000\n",
      "350/350 - 1s - loss: 0.2062 - accuracy: 0.9265\n",
      "Epoch 261/1000\n",
      "350/350 - 1s - loss: 0.2083 - accuracy: 0.9276\n",
      "Epoch 262/1000\n",
      "350/350 - 1s - loss: 0.2062 - accuracy: 0.9298\n",
      "Epoch 263/1000\n",
      "350/350 - 1s - loss: 0.2057 - accuracy: 0.9291\n",
      "Epoch 264/1000\n",
      "350/350 - 1s - loss: 0.2074 - accuracy: 0.9285\n",
      "Epoch 265/1000\n",
      "350/350 - 1s - loss: 0.2036 - accuracy: 0.9284\n",
      "Epoch 266/1000\n",
      "350/350 - 1s - loss: 0.2013 - accuracy: 0.9297\n",
      "Epoch 267/1000\n",
      "350/350 - 1s - loss: 0.2075 - accuracy: 0.9276\n",
      "Epoch 268/1000\n",
      "350/350 - 1s - loss: 0.2018 - accuracy: 0.9289\n",
      "Epoch 269/1000\n",
      "350/350 - 1s - loss: 0.2021 - accuracy: 0.9293\n",
      "Epoch 270/1000\n",
      "350/350 - 1s - loss: 0.2036 - accuracy: 0.9298\n",
      "Epoch 271/1000\n",
      "350/350 - 1s - loss: 0.2023 - accuracy: 0.9291\n",
      "Epoch 272/1000\n",
      "350/350 - 1s - loss: 0.2036 - accuracy: 0.9292\n",
      "Epoch 273/1000\n",
      "350/350 - 1s - loss: 0.2050 - accuracy: 0.9281\n",
      "Epoch 274/1000\n",
      "350/350 - 1s - loss: 0.2034 - accuracy: 0.9300\n",
      "Epoch 275/1000\n",
      "350/350 - 1s - loss: 0.2037 - accuracy: 0.9297\n",
      "Epoch 276/1000\n",
      "350/350 - 1s - loss: 0.1996 - accuracy: 0.9311\n",
      "Epoch 277/1000\n",
      "350/350 - 1s - loss: 0.1987 - accuracy: 0.9302\n",
      "Epoch 278/1000\n",
      "350/350 - 1s - loss: 0.2011 - accuracy: 0.9299\n",
      "Epoch 279/1000\n",
      "350/350 - 1s - loss: 0.1999 - accuracy: 0.9280\n",
      "Epoch 280/1000\n",
      "350/350 - 1s - loss: 0.1985 - accuracy: 0.9297\n",
      "Epoch 281/1000\n",
      "350/350 - 1s - loss: 0.1976 - accuracy: 0.9300\n",
      "Epoch 282/1000\n",
      "350/350 - 1s - loss: 0.1971 - accuracy: 0.9296\n",
      "Epoch 283/1000\n",
      "350/350 - 1s - loss: 0.2005 - accuracy: 0.9279\n",
      "Epoch 284/1000\n",
      "350/350 - 1s - loss: 0.2004 - accuracy: 0.9295\n",
      "Epoch 285/1000\n",
      "350/350 - 1s - loss: 0.2006 - accuracy: 0.9314\n",
      "Epoch 286/1000\n",
      "350/350 - 1s - loss: 0.1970 - accuracy: 0.9307\n",
      "Epoch 287/1000\n",
      "350/350 - 1s - loss: 0.1980 - accuracy: 0.9294\n",
      "Epoch 288/1000\n",
      "350/350 - 1s - loss: 0.1948 - accuracy: 0.9305\n",
      "Epoch 289/1000\n",
      "350/350 - 1s - loss: 0.1965 - accuracy: 0.9308\n",
      "Epoch 290/1000\n",
      "350/350 - 1s - loss: 0.1989 - accuracy: 0.9307\n",
      "Epoch 291/1000\n",
      "350/350 - 1s - loss: 0.1958 - accuracy: 0.9311\n",
      "Epoch 292/1000\n",
      "350/350 - 1s - loss: 0.1927 - accuracy: 0.9311\n",
      "Epoch 293/1000\n",
      "350/350 - 1s - loss: 0.1967 - accuracy: 0.9307\n",
      "Epoch 294/1000\n",
      "350/350 - 1s - loss: 0.1943 - accuracy: 0.9320\n",
      "Epoch 295/1000\n",
      "350/350 - 1s - loss: 0.1981 - accuracy: 0.9305\n",
      "Epoch 296/1000\n",
      "350/350 - 1s - loss: 0.1954 - accuracy: 0.9295\n",
      "Epoch 297/1000\n",
      "350/350 - 1s - loss: 0.1967 - accuracy: 0.9299\n",
      "Epoch 298/1000\n",
      "350/350 - 1s - loss: 0.1948 - accuracy: 0.9307\n",
      "Epoch 299/1000\n",
      "350/350 - 1s - loss: 0.1952 - accuracy: 0.9306\n",
      "Epoch 300/1000\n",
      "350/350 - 1s - loss: 0.1946 - accuracy: 0.9302\n",
      "Epoch 301/1000\n",
      "350/350 - 1s - loss: 0.1949 - accuracy: 0.9310\n",
      "Epoch 302/1000\n",
      "350/350 - 1s - loss: 0.1947 - accuracy: 0.9297\n",
      "Epoch 303/1000\n",
      "350/350 - 1s - loss: 0.1909 - accuracy: 0.9308\n",
      "Epoch 304/1000\n",
      "350/350 - 1s - loss: 0.1963 - accuracy: 0.9306\n",
      "Epoch 305/1000\n",
      "350/350 - 1s - loss: 0.1920 - accuracy: 0.9309\n",
      "Epoch 306/1000\n",
      "350/350 - 1s - loss: 0.1929 - accuracy: 0.9313\n",
      "Epoch 307/1000\n",
      "350/350 - 1s - loss: 0.1917 - accuracy: 0.9301\n",
      "Epoch 308/1000\n",
      "350/350 - 1s - loss: 0.1941 - accuracy: 0.9314\n",
      "Epoch 309/1000\n",
      "350/350 - 1s - loss: 0.1893 - accuracy: 0.9317\n",
      "Epoch 310/1000\n",
      "350/350 - 1s - loss: 0.1975 - accuracy: 0.9305\n",
      "Epoch 311/1000\n",
      "350/350 - 1s - loss: 0.1916 - accuracy: 0.9298\n",
      "Epoch 312/1000\n",
      "350/350 - 1s - loss: 0.1933 - accuracy: 0.9312\n",
      "Epoch 313/1000\n",
      "350/350 - 1s - loss: 0.1931 - accuracy: 0.9304\n",
      "Epoch 314/1000\n",
      "350/350 - 1s - loss: 0.1897 - accuracy: 0.9325\n",
      "Epoch 315/1000\n",
      "350/350 - 1s - loss: 0.1882 - accuracy: 0.9324\n",
      "Epoch 316/1000\n",
      "350/350 - 1s - loss: 0.1886 - accuracy: 0.9320\n",
      "Epoch 317/1000\n",
      "350/350 - 1s - loss: 0.1932 - accuracy: 0.9307\n",
      "Epoch 318/1000\n",
      "350/350 - 1s - loss: 0.1940 - accuracy: 0.9290\n",
      "Epoch 319/1000\n",
      "350/350 - 1s - loss: 0.1876 - accuracy: 0.9327\n",
      "Epoch 320/1000\n",
      "350/350 - 0s - loss: 0.1891 - accuracy: 0.9323\n",
      "Epoch 321/1000\n",
      "350/350 - 1s - loss: 0.1894 - accuracy: 0.9328\n",
      "Epoch 322/1000\n",
      "350/350 - 1s - loss: 0.1921 - accuracy: 0.9311\n",
      "Epoch 323/1000\n",
      "350/350 - 1s - loss: 0.1878 - accuracy: 0.9329\n",
      "Epoch 324/1000\n",
      "350/350 - 1s - loss: 0.1871 - accuracy: 0.9312\n",
      "Epoch 325/1000\n",
      "350/350 - 1s - loss: 0.1856 - accuracy: 0.9334\n",
      "Epoch 326/1000\n",
      "350/350 - 1s - loss: 0.1925 - accuracy: 0.9325\n",
      "Epoch 327/1000\n",
      "350/350 - 1s - loss: 0.1881 - accuracy: 0.9315\n",
      "Epoch 328/1000\n",
      "350/350 - 1s - loss: 0.1895 - accuracy: 0.9320\n",
      "Epoch 329/1000\n",
      "350/350 - 1s - loss: 0.1846 - accuracy: 0.9320\n",
      "Epoch 330/1000\n",
      "350/350 - 1s - loss: 0.1901 - accuracy: 0.9307\n",
      "Epoch 331/1000\n",
      "350/350 - 1s - loss: 0.1870 - accuracy: 0.9319\n",
      "Epoch 332/1000\n",
      "350/350 - 1s - loss: 0.1869 - accuracy: 0.9321\n",
      "Epoch 333/1000\n",
      "350/350 - 1s - loss: 0.1829 - accuracy: 0.9332\n",
      "Epoch 334/1000\n",
      "350/350 - 1s - loss: 0.1866 - accuracy: 0.9319\n",
      "Epoch 335/1000\n",
      "350/350 - 1s - loss: 0.1847 - accuracy: 0.9319\n",
      "Epoch 336/1000\n",
      "350/350 - 1s - loss: 0.1868 - accuracy: 0.9337\n",
      "Epoch 337/1000\n",
      "350/350 - 1s - loss: 0.1844 - accuracy: 0.9307\n",
      "Epoch 338/1000\n",
      "350/350 - 1s - loss: 0.1875 - accuracy: 0.9324\n",
      "Epoch 339/1000\n",
      "350/350 - 1s - loss: 0.1860 - accuracy: 0.9324\n",
      "Epoch 340/1000\n",
      "350/350 - 1s - loss: 0.1815 - accuracy: 0.9334\n",
      "Epoch 341/1000\n",
      "350/350 - 1s - loss: 0.1835 - accuracy: 0.9322\n",
      "Epoch 342/1000\n",
      "350/350 - 1s - loss: 0.1887 - accuracy: 0.9304\n",
      "Epoch 343/1000\n",
      "350/350 - 1s - loss: 0.1829 - accuracy: 0.9329\n",
      "Epoch 344/1000\n",
      "350/350 - 1s - loss: 0.1842 - accuracy: 0.9324\n",
      "Epoch 345/1000\n",
      "350/350 - 1s - loss: 0.1863 - accuracy: 0.9324\n",
      "Epoch 346/1000\n",
      "350/350 - 1s - loss: 0.1840 - accuracy: 0.9324\n",
      "Epoch 347/1000\n",
      "350/350 - 1s - loss: 0.1833 - accuracy: 0.9344\n",
      "Epoch 348/1000\n",
      "350/350 - 1s - loss: 0.1845 - accuracy: 0.9330\n",
      "Epoch 349/1000\n",
      "350/350 - 1s - loss: 0.1862 - accuracy: 0.9324\n",
      "Epoch 350/1000\n",
      "350/350 - 1s - loss: 0.1833 - accuracy: 0.9337\n",
      "Epoch 351/1000\n",
      "350/350 - 1s - loss: 0.1834 - accuracy: 0.9314\n",
      "Epoch 352/1000\n",
      "350/350 - 1s - loss: 0.1860 - accuracy: 0.9326\n",
      "Epoch 353/1000\n",
      "350/350 - 1s - loss: 0.1826 - accuracy: 0.9333\n",
      "Epoch 354/1000\n",
      "350/350 - 1s - loss: 0.1825 - accuracy: 0.9317\n",
      "Epoch 355/1000\n",
      "350/350 - 1s - loss: 0.1849 - accuracy: 0.9331\n",
      "Epoch 356/1000\n",
      "350/350 - 1s - loss: 0.1847 - accuracy: 0.9332\n",
      "Epoch 357/1000\n",
      "350/350 - 1s - loss: 0.1831 - accuracy: 0.9334\n",
      "Epoch 358/1000\n",
      "350/350 - 1s - loss: 0.1814 - accuracy: 0.9340\n",
      "Epoch 359/1000\n",
      "350/350 - 1s - loss: 0.1805 - accuracy: 0.9334\n",
      "Epoch 360/1000\n",
      "350/350 - 1s - loss: 0.1823 - accuracy: 0.9347\n",
      "Epoch 361/1000\n",
      "350/350 - 1s - loss: 0.1791 - accuracy: 0.9345\n",
      "Epoch 362/1000\n",
      "350/350 - 1s - loss: 0.1843 - accuracy: 0.9334\n",
      "Epoch 363/1000\n",
      "350/350 - 1s - loss: 0.1797 - accuracy: 0.9349\n",
      "Epoch 364/1000\n",
      "350/350 - 1s - loss: 0.1850 - accuracy: 0.9337\n",
      "Epoch 365/1000\n",
      "350/350 - 1s - loss: 0.1815 - accuracy: 0.9329\n",
      "Epoch 366/1000\n",
      "350/350 - 1s - loss: 0.1815 - accuracy: 0.9343\n",
      "Epoch 367/1000\n",
      "350/350 - 1s - loss: 0.1809 - accuracy: 0.9344\n",
      "Epoch 368/1000\n",
      "350/350 - 1s - loss: 0.1791 - accuracy: 0.9346\n",
      "Epoch 369/1000\n",
      "350/350 - 1s - loss: 0.1807 - accuracy: 0.9339\n",
      "Epoch 370/1000\n",
      "350/350 - 1s - loss: 0.1769 - accuracy: 0.9348\n",
      "Epoch 371/1000\n",
      "350/350 - 1s - loss: 0.1787 - accuracy: 0.9349\n",
      "Epoch 372/1000\n",
      "350/350 - 1s - loss: 0.1798 - accuracy: 0.9351\n",
      "Epoch 373/1000\n",
      "350/350 - 1s - loss: 0.1778 - accuracy: 0.9358\n",
      "Epoch 374/1000\n",
      "350/350 - 1s - loss: 0.1786 - accuracy: 0.9331\n",
      "Epoch 375/1000\n",
      "350/350 - 1s - loss: 0.1791 - accuracy: 0.9348\n",
      "Epoch 376/1000\n",
      "350/350 - 1s - loss: 0.1819 - accuracy: 0.9325\n",
      "Epoch 377/1000\n",
      "350/350 - 1s - loss: 0.1801 - accuracy: 0.9328\n",
      "Epoch 378/1000\n",
      "350/350 - 1s - loss: 0.1786 - accuracy: 0.9341\n",
      "Epoch 379/1000\n",
      "350/350 - 1s - loss: 0.1772 - accuracy: 0.9348\n",
      "Epoch 380/1000\n",
      "350/350 - 1s - loss: 0.1791 - accuracy: 0.9342\n",
      "Epoch 381/1000\n",
      "350/350 - 1s - loss: 0.1770 - accuracy: 0.9348\n",
      "Epoch 382/1000\n",
      "350/350 - 1s - loss: 0.1826 - accuracy: 0.9330\n",
      "Epoch 383/1000\n",
      "350/350 - 1s - loss: 0.1773 - accuracy: 0.9350\n",
      "Epoch 384/1000\n",
      "350/350 - 1s - loss: 0.1775 - accuracy: 0.9327\n",
      "Epoch 385/1000\n",
      "350/350 - 1s - loss: 0.1763 - accuracy: 0.9338\n",
      "Epoch 386/1000\n",
      "350/350 - 1s - loss: 0.1803 - accuracy: 0.9341\n",
      "Epoch 387/1000\n",
      "350/350 - 1s - loss: 0.1760 - accuracy: 0.9356\n",
      "Epoch 388/1000\n",
      "350/350 - 1s - loss: 0.1767 - accuracy: 0.9353\n",
      "Epoch 389/1000\n",
      "350/350 - 1s - loss: 0.1773 - accuracy: 0.9344\n",
      "Epoch 390/1000\n",
      "350/350 - 1s - loss: 0.1778 - accuracy: 0.9345\n",
      "Epoch 391/1000\n",
      "350/350 - 1s - loss: 0.1760 - accuracy: 0.9352\n",
      "Epoch 392/1000\n",
      "350/350 - 1s - loss: 0.1778 - accuracy: 0.9338\n",
      "Epoch 393/1000\n",
      "350/350 - 1s - loss: 0.1772 - accuracy: 0.9330\n",
      "Epoch 394/1000\n",
      "350/350 - 1s - loss: 0.1768 - accuracy: 0.9341\n",
      "Epoch 395/1000\n",
      "350/350 - 1s - loss: 0.1779 - accuracy: 0.9344\n",
      "Epoch 396/1000\n",
      "350/350 - 1s - loss: 0.1790 - accuracy: 0.9337\n",
      "Epoch 397/1000\n",
      "350/350 - 1s - loss: 0.1761 - accuracy: 0.9330\n",
      "Epoch 398/1000\n",
      "350/350 - 1s - loss: 0.1771 - accuracy: 0.9338\n",
      "Epoch 399/1000\n",
      "350/350 - 1s - loss: 0.1731 - accuracy: 0.9347\n",
      "Epoch 400/1000\n",
      "350/350 - 1s - loss: 0.1783 - accuracy: 0.9341\n",
      "Epoch 401/1000\n",
      "350/350 - 1s - loss: 0.1752 - accuracy: 0.9351\n",
      "Epoch 402/1000\n",
      "350/350 - 1s - loss: 0.1743 - accuracy: 0.9337\n",
      "Epoch 403/1000\n",
      "350/350 - 1s - loss: 0.1774 - accuracy: 0.9368\n",
      "Epoch 404/1000\n",
      "350/350 - 1s - loss: 0.1757 - accuracy: 0.9332\n",
      "Epoch 405/1000\n",
      "350/350 - 1s - loss: 0.1758 - accuracy: 0.9335\n",
      "Epoch 406/1000\n",
      "350/350 - 1s - loss: 0.1768 - accuracy: 0.9332\n",
      "Epoch 407/1000\n",
      "350/350 - 1s - loss: 0.1746 - accuracy: 0.9324\n",
      "Epoch 408/1000\n",
      "350/350 - 1s - loss: 0.1752 - accuracy: 0.9357\n",
      "Epoch 409/1000\n",
      "350/350 - 1s - loss: 0.1696 - accuracy: 0.9367\n",
      "Epoch 410/1000\n",
      "350/350 - 1s - loss: 0.1736 - accuracy: 0.9356\n",
      "Epoch 411/1000\n",
      "350/350 - 1s - loss: 0.1750 - accuracy: 0.9335\n",
      "Epoch 412/1000\n",
      "350/350 - 1s - loss: 0.1776 - accuracy: 0.9354\n",
      "Epoch 413/1000\n",
      "350/350 - 1s - loss: 0.1724 - accuracy: 0.9361\n",
      "Epoch 414/1000\n",
      "350/350 - 1s - loss: 0.1731 - accuracy: 0.9362\n",
      "Epoch 415/1000\n",
      "350/350 - 1s - loss: 0.1716 - accuracy: 0.9356\n",
      "Epoch 416/1000\n",
      "350/350 - 1s - loss: 0.1753 - accuracy: 0.9344\n",
      "Epoch 417/1000\n",
      "350/350 - 1s - loss: 0.1735 - accuracy: 0.9358\n",
      "Epoch 418/1000\n",
      "350/350 - 0s - loss: 0.1711 - accuracy: 0.9358\n",
      "Epoch 419/1000\n",
      "350/350 - 1s - loss: 0.1696 - accuracy: 0.9368\n",
      "Epoch 420/1000\n",
      "350/350 - 1s - loss: 0.1724 - accuracy: 0.9357\n",
      "Epoch 421/1000\n",
      "350/350 - 1s - loss: 0.1681 - accuracy: 0.9366\n",
      "Epoch 422/1000\n",
      "350/350 - 1s - loss: 0.1738 - accuracy: 0.9349\n",
      "Epoch 423/1000\n",
      "350/350 - 1s - loss: 0.1713 - accuracy: 0.9347\n",
      "Epoch 424/1000\n",
      "350/350 - 1s - loss: 0.1778 - accuracy: 0.9328\n",
      "Epoch 425/1000\n",
      "350/350 - 1s - loss: 0.1711 - accuracy: 0.9337\n",
      "Epoch 426/1000\n",
      "350/350 - 1s - loss: 0.1714 - accuracy: 0.9346\n",
      "Epoch 427/1000\n",
      "350/350 - 1s - loss: 0.1708 - accuracy: 0.9358\n",
      "Epoch 428/1000\n",
      "350/350 - 1s - loss: 0.1691 - accuracy: 0.9351\n",
      "Epoch 429/1000\n",
      "350/350 - 1s - loss: 0.1736 - accuracy: 0.9360\n",
      "Epoch 430/1000\n",
      "350/350 - 1s - loss: 0.1723 - accuracy: 0.9350\n",
      "Epoch 431/1000\n",
      "350/350 - 1s - loss: 0.1778 - accuracy: 0.9356\n",
      "Epoch 432/1000\n",
      "350/350 - 1s - loss: 0.1710 - accuracy: 0.9371\n",
      "Epoch 433/1000\n",
      "350/350 - 1s - loss: 0.1703 - accuracy: 0.9361\n",
      "Epoch 434/1000\n",
      "350/350 - 1s - loss: 0.1714 - accuracy: 0.9356\n",
      "Epoch 435/1000\n",
      "350/350 - 1s - loss: 0.1700 - accuracy: 0.9366\n",
      "Epoch 436/1000\n",
      "350/350 - 1s - loss: 0.1683 - accuracy: 0.9371\n",
      "Epoch 437/1000\n",
      "350/350 - 1s - loss: 0.1689 - accuracy: 0.9370\n",
      "Epoch 438/1000\n",
      "350/350 - 1s - loss: 0.1643 - accuracy: 0.9370\n",
      "Epoch 439/1000\n",
      "350/350 - 1s - loss: 0.1724 - accuracy: 0.9358\n",
      "Epoch 440/1000\n",
      "350/350 - 1s - loss: 0.1667 - accuracy: 0.9370\n",
      "Epoch 441/1000\n",
      "350/350 - 1s - loss: 0.1681 - accuracy: 0.9366\n",
      "Epoch 442/1000\n",
      "350/350 - 1s - loss: 0.1700 - accuracy: 0.9341\n",
      "Epoch 443/1000\n",
      "350/350 - 1s - loss: 0.1683 - accuracy: 0.9368\n",
      "Epoch 444/1000\n",
      "350/350 - 1s - loss: 0.1688 - accuracy: 0.9355\n",
      "Epoch 445/1000\n",
      "350/350 - 1s - loss: 0.1678 - accuracy: 0.9353\n",
      "Epoch 446/1000\n",
      "350/350 - 1s - loss: 0.1684 - accuracy: 0.9365\n",
      "Epoch 447/1000\n",
      "350/350 - 1s - loss: 0.1700 - accuracy: 0.9361\n",
      "Epoch 448/1000\n",
      "350/350 - 1s - loss: 0.1669 - accuracy: 0.9363\n",
      "Epoch 449/1000\n",
      "350/350 - 1s - loss: 0.1665 - accuracy: 0.9378\n",
      "Epoch 450/1000\n",
      "350/350 - 1s - loss: 0.1718 - accuracy: 0.9355\n",
      "Epoch 451/1000\n",
      "350/350 - 1s - loss: 0.1660 - accuracy: 0.9375\n",
      "Epoch 452/1000\n",
      "350/350 - 1s - loss: 0.1674 - accuracy: 0.9370\n",
      "Epoch 453/1000\n",
      "350/350 - 1s - loss: 0.1696 - accuracy: 0.9350\n",
      "Epoch 454/1000\n",
      "350/350 - 0s - loss: 0.1671 - accuracy: 0.9372\n",
      "Epoch 455/1000\n",
      "350/350 - 1s - loss: 0.1663 - accuracy: 0.9366\n",
      "Epoch 456/1000\n",
      "350/350 - 1s - loss: 0.1661 - accuracy: 0.9366\n",
      "Epoch 457/1000\n",
      "350/350 - 1s - loss: 0.1658 - accuracy: 0.9379\n",
      "Epoch 458/1000\n",
      "350/350 - 1s - loss: 0.1698 - accuracy: 0.9364\n",
      "Epoch 459/1000\n",
      "350/350 - 1s - loss: 0.1704 - accuracy: 0.9369\n",
      "Epoch 460/1000\n",
      "350/350 - 0s - loss: 0.1672 - accuracy: 0.9364\n",
      "Epoch 461/1000\n",
      "350/350 - 1s - loss: 0.1612 - accuracy: 0.9399\n",
      "Epoch 462/1000\n",
      "350/350 - 1s - loss: 0.1683 - accuracy: 0.9363\n",
      "Epoch 463/1000\n",
      "350/350 - 1s - loss: 0.1663 - accuracy: 0.9358\n",
      "Epoch 464/1000\n",
      "350/350 - 1s - loss: 0.1665 - accuracy: 0.9356\n",
      "Epoch 465/1000\n",
      "350/350 - 1s - loss: 0.1647 - accuracy: 0.9364\n",
      "Epoch 466/1000\n",
      "350/350 - 1s - loss: 0.1752 - accuracy: 0.9344\n",
      "Epoch 467/1000\n",
      "350/350 - 1s - loss: 0.1650 - accuracy: 0.9358\n",
      "Epoch 468/1000\n",
      "350/350 - 1s - loss: 0.1655 - accuracy: 0.9361\n",
      "Epoch 469/1000\n",
      "350/350 - 1s - loss: 0.1671 - accuracy: 0.9364\n",
      "Epoch 470/1000\n",
      "350/350 - 1s - loss: 0.1649 - accuracy: 0.9384\n",
      "Epoch 471/1000\n",
      "350/350 - 1s - loss: 0.1650 - accuracy: 0.9368\n",
      "Epoch 472/1000\n",
      "350/350 - 0s - loss: 0.1628 - accuracy: 0.9381\n",
      "Epoch 473/1000\n",
      "350/350 - 1s - loss: 0.1652 - accuracy: 0.9377\n",
      "Epoch 474/1000\n",
      "350/350 - 1s - loss: 0.1658 - accuracy: 0.9377\n",
      "Epoch 475/1000\n",
      "350/350 - 1s - loss: 0.1682 - accuracy: 0.9358\n",
      "Epoch 476/1000\n",
      "350/350 - 1s - loss: 0.1638 - accuracy: 0.9382\n",
      "Epoch 477/1000\n",
      "350/350 - 1s - loss: 0.1620 - accuracy: 0.9379\n",
      "Epoch 478/1000\n",
      "350/350 - 0s - loss: 0.1639 - accuracy: 0.9379\n",
      "Epoch 479/1000\n",
      "350/350 - 1s - loss: 0.1648 - accuracy: 0.9372\n",
      "Epoch 480/1000\n",
      "350/350 - 0s - loss: 0.1683 - accuracy: 0.9350\n",
      "Epoch 481/1000\n",
      "350/350 - 0s - loss: 0.1623 - accuracy: 0.9374\n",
      "Epoch 482/1000\n",
      "350/350 - 0s - loss: 0.1648 - accuracy: 0.9371\n",
      "Epoch 483/1000\n",
      "350/350 - 1s - loss: 0.1642 - accuracy: 0.9366\n",
      "Epoch 484/1000\n",
      "350/350 - 1s - loss: 0.1661 - accuracy: 0.9366\n",
      "Epoch 485/1000\n",
      "350/350 - 1s - loss: 0.1607 - accuracy: 0.9380\n",
      "Epoch 486/1000\n",
      "350/350 - 1s - loss: 0.1660 - accuracy: 0.9383\n",
      "Epoch 487/1000\n",
      "350/350 - 1s - loss: 0.1612 - accuracy: 0.9390\n",
      "Epoch 488/1000\n",
      "350/350 - 1s - loss: 0.1620 - accuracy: 0.9377\n",
      "Epoch 489/1000\n",
      "350/350 - 1s - loss: 0.1622 - accuracy: 0.9381\n",
      "Epoch 490/1000\n",
      "350/350 - 1s - loss: 0.1629 - accuracy: 0.9374\n",
      "Epoch 491/1000\n",
      "350/350 - 1s - loss: 0.1640 - accuracy: 0.9369\n",
      "Epoch 492/1000\n",
      "350/350 - 1s - loss: 0.1658 - accuracy: 0.9366\n",
      "Epoch 493/1000\n",
      "350/350 - 1s - loss: 0.1656 - accuracy: 0.9369\n",
      "Epoch 494/1000\n",
      "350/350 - 1s - loss: 0.1616 - accuracy: 0.9366\n",
      "Epoch 495/1000\n",
      "350/350 - 1s - loss: 0.1630 - accuracy: 0.9375\n",
      "Epoch 496/1000\n",
      "350/350 - 1s - loss: 0.1621 - accuracy: 0.9376\n",
      "Epoch 497/1000\n",
      "350/350 - 1s - loss: 0.1617 - accuracy: 0.9369\n",
      "Epoch 498/1000\n",
      "350/350 - 1s - loss: 0.1664 - accuracy: 0.9385\n",
      "Epoch 499/1000\n",
      "350/350 - 1s - loss: 0.1642 - accuracy: 0.9381\n",
      "Epoch 500/1000\n",
      "350/350 - 1s - loss: 0.1651 - accuracy: 0.9371\n",
      "Epoch 501/1000\n",
      "350/350 - 1s - loss: 0.1629 - accuracy: 0.9384\n",
      "Epoch 502/1000\n",
      "350/350 - 1s - loss: 0.1638 - accuracy: 0.9377\n",
      "Epoch 503/1000\n",
      "350/350 - 1s - loss: 0.1598 - accuracy: 0.9366\n",
      "Epoch 504/1000\n",
      "350/350 - 1s - loss: 0.1615 - accuracy: 0.9377\n",
      "Epoch 505/1000\n",
      "350/350 - 1s - loss: 0.1615 - accuracy: 0.9382\n",
      "Epoch 506/1000\n",
      "350/350 - 1s - loss: 0.1653 - accuracy: 0.9363\n",
      "Epoch 507/1000\n",
      "350/350 - 1s - loss: 0.1622 - accuracy: 0.9383\n",
      "Epoch 508/1000\n",
      "350/350 - 1s - loss: 0.1587 - accuracy: 0.9397\n",
      "Epoch 509/1000\n",
      "350/350 - 1s - loss: 0.1646 - accuracy: 0.9366\n",
      "Epoch 510/1000\n",
      "350/350 - 1s - loss: 0.1600 - accuracy: 0.9375\n",
      "Epoch 511/1000\n",
      "350/350 - 1s - loss: 0.1624 - accuracy: 0.9378\n",
      "Epoch 512/1000\n",
      "350/350 - 1s - loss: 0.1603 - accuracy: 0.9373\n",
      "Epoch 513/1000\n",
      "350/350 - 1s - loss: 0.1597 - accuracy: 0.9399\n",
      "Epoch 514/1000\n",
      "350/350 - 1s - loss: 0.1604 - accuracy: 0.9385\n",
      "Epoch 515/1000\n",
      "350/350 - 1s - loss: 0.1595 - accuracy: 0.9389\n",
      "Epoch 516/1000\n",
      "350/350 - 1s - loss: 0.1605 - accuracy: 0.9392\n",
      "Epoch 517/1000\n",
      "350/350 - 0s - loss: 0.1590 - accuracy: 0.9389\n",
      "Epoch 518/1000\n",
      "350/350 - 1s - loss: 0.1629 - accuracy: 0.9379\n",
      "Epoch 519/1000\n",
      "350/350 - 1s - loss: 0.1611 - accuracy: 0.9387\n",
      "Epoch 520/1000\n",
      "350/350 - 1s - loss: 0.1615 - accuracy: 0.9391\n",
      "Epoch 521/1000\n",
      "350/350 - 1s - loss: 0.1585 - accuracy: 0.9393\n",
      "Epoch 522/1000\n",
      "350/350 - 1s - loss: 0.1628 - accuracy: 0.9377\n",
      "Epoch 523/1000\n",
      "350/350 - 1s - loss: 0.1588 - accuracy: 0.9407\n",
      "Epoch 524/1000\n",
      "350/350 - 1s - loss: 0.1597 - accuracy: 0.9379\n",
      "Epoch 525/1000\n",
      "350/350 - 1s - loss: 0.1634 - accuracy: 0.9381\n",
      "Epoch 526/1000\n",
      "350/350 - 1s - loss: 0.1622 - accuracy: 0.9370\n",
      "Epoch 527/1000\n",
      "350/350 - 0s - loss: 0.1630 - accuracy: 0.9358\n",
      "Epoch 528/1000\n",
      "350/350 - 0s - loss: 0.1586 - accuracy: 0.9386\n",
      "Epoch 529/1000\n",
      "350/350 - 0s - loss: 0.1601 - accuracy: 0.9393\n",
      "Epoch 530/1000\n",
      "350/350 - 0s - loss: 0.1615 - accuracy: 0.9394\n",
      "Epoch 531/1000\n",
      "350/350 - 1s - loss: 0.1625 - accuracy: 0.9381\n",
      "Epoch 532/1000\n",
      "350/350 - 0s - loss: 0.1586 - accuracy: 0.9386\n",
      "Epoch 533/1000\n",
      "350/350 - 1s - loss: 0.1585 - accuracy: 0.9401\n",
      "Epoch 534/1000\n",
      "350/350 - 1s - loss: 0.1589 - accuracy: 0.9394\n",
      "Epoch 535/1000\n",
      "350/350 - 1s - loss: 0.1613 - accuracy: 0.9374\n",
      "Epoch 536/1000\n",
      "350/350 - 1s - loss: 0.1631 - accuracy: 0.9380\n",
      "Epoch 537/1000\n",
      "350/350 - 0s - loss: 0.1599 - accuracy: 0.9381\n",
      "Epoch 538/1000\n",
      "350/350 - 0s - loss: 0.1595 - accuracy: 0.9392\n",
      "Epoch 539/1000\n",
      "350/350 - 0s - loss: 0.1624 - accuracy: 0.9388\n",
      "Epoch 540/1000\n",
      "350/350 - 1s - loss: 0.1576 - accuracy: 0.9392\n",
      "Epoch 541/1000\n",
      "350/350 - 1s - loss: 0.1574 - accuracy: 0.9383\n",
      "Epoch 542/1000\n",
      "350/350 - 1s - loss: 0.1620 - accuracy: 0.9384\n",
      "Epoch 543/1000\n",
      "350/350 - 0s - loss: 0.1592 - accuracy: 0.9377\n",
      "Epoch 544/1000\n",
      "350/350 - 1s - loss: 0.1584 - accuracy: 0.9397\n",
      "Epoch 545/1000\n",
      "350/350 - 0s - loss: 0.1617 - accuracy: 0.9395\n",
      "Epoch 546/1000\n",
      "350/350 - 0s - loss: 0.1570 - accuracy: 0.9408\n",
      "Epoch 547/1000\n",
      "350/350 - 1s - loss: 0.1544 - accuracy: 0.9401\n",
      "Epoch 548/1000\n",
      "350/350 - 1s - loss: 0.1606 - accuracy: 0.9368\n",
      "Epoch 549/1000\n",
      "350/350 - 1s - loss: 0.1595 - accuracy: 0.9398\n",
      "Epoch 550/1000\n",
      "350/350 - 1s - loss: 0.1561 - accuracy: 0.9396\n",
      "Epoch 551/1000\n",
      "350/350 - 1s - loss: 0.1642 - accuracy: 0.9377\n",
      "Epoch 552/1000\n",
      "350/350 - 1s - loss: 0.1562 - accuracy: 0.9380\n",
      "Epoch 553/1000\n",
      "350/350 - 1s - loss: 0.1609 - accuracy: 0.9385\n",
      "Epoch 554/1000\n",
      "350/350 - 1s - loss: 0.1550 - accuracy: 0.9392\n",
      "Epoch 555/1000\n",
      "350/350 - 1s - loss: 0.1559 - accuracy: 0.9401\n",
      "Epoch 556/1000\n",
      "350/350 - 1s - loss: 0.1570 - accuracy: 0.9396\n",
      "Epoch 557/1000\n",
      "350/350 - 1s - loss: 0.1562 - accuracy: 0.9406\n",
      "Epoch 558/1000\n",
      "350/350 - 1s - loss: 0.1564 - accuracy: 0.9401\n",
      "Epoch 559/1000\n",
      "350/350 - 1s - loss: 0.1613 - accuracy: 0.9388\n",
      "Epoch 560/1000\n",
      "350/350 - 1s - loss: 0.1556 - accuracy: 0.9402\n",
      "Epoch 561/1000\n",
      "350/350 - 1s - loss: 0.1563 - accuracy: 0.9395\n",
      "Epoch 562/1000\n",
      "350/350 - 1s - loss: 0.1565 - accuracy: 0.9415\n",
      "Epoch 563/1000\n",
      "350/350 - 1s - loss: 0.1529 - accuracy: 0.9406\n",
      "Epoch 564/1000\n",
      "350/350 - 1s - loss: 0.1522 - accuracy: 0.9411\n",
      "Epoch 565/1000\n",
      "350/350 - 1s - loss: 0.1593 - accuracy: 0.9391\n",
      "Epoch 566/1000\n",
      "350/350 - 1s - loss: 0.1559 - accuracy: 0.9398\n",
      "Epoch 567/1000\n",
      "350/350 - 1s - loss: 0.1562 - accuracy: 0.9416\n",
      "Epoch 568/1000\n",
      "350/350 - 1s - loss: 0.1590 - accuracy: 0.9401\n",
      "Epoch 569/1000\n",
      "350/350 - 1s - loss: 0.1560 - accuracy: 0.9394\n",
      "Epoch 570/1000\n",
      "350/350 - 1s - loss: 0.1568 - accuracy: 0.9374\n",
      "Epoch 571/1000\n",
      "350/350 - 1s - loss: 0.1558 - accuracy: 0.9398\n",
      "Epoch 572/1000\n",
      "350/350 - 1s - loss: 0.1555 - accuracy: 0.9406\n",
      "Epoch 573/1000\n",
      "350/350 - 1s - loss: 0.1563 - accuracy: 0.9392\n",
      "Epoch 574/1000\n",
      "350/350 - 1s - loss: 0.1540 - accuracy: 0.9404\n",
      "Epoch 575/1000\n",
      "350/350 - 1s - loss: 0.1564 - accuracy: 0.9408\n",
      "Epoch 576/1000\n",
      "350/350 - 0s - loss: 0.1568 - accuracy: 0.9402\n",
      "Epoch 577/1000\n",
      "350/350 - 1s - loss: 0.1522 - accuracy: 0.9400\n",
      "Epoch 578/1000\n",
      "350/350 - 1s - loss: 0.1555 - accuracy: 0.9409\n",
      "Epoch 579/1000\n",
      "350/350 - 1s - loss: 0.1578 - accuracy: 0.9393\n",
      "Epoch 580/1000\n",
      "350/350 - 1s - loss: 0.1577 - accuracy: 0.9377\n",
      "Epoch 581/1000\n",
      "350/350 - 0s - loss: 0.1532 - accuracy: 0.9410\n",
      "Epoch 582/1000\n",
      "350/350 - 0s - loss: 0.1551 - accuracy: 0.9396\n",
      "Epoch 583/1000\n",
      "350/350 - 0s - loss: 0.1541 - accuracy: 0.9396\n",
      "Epoch 584/1000\n",
      "350/350 - 1s - loss: 0.1557 - accuracy: 0.9388\n",
      "Epoch 585/1000\n",
      "350/350 - 1s - loss: 0.1545 - accuracy: 0.9411\n",
      "Epoch 586/1000\n",
      "350/350 - 1s - loss: 0.1528 - accuracy: 0.9409\n",
      "Epoch 587/1000\n",
      "350/350 - 1s - loss: 0.1521 - accuracy: 0.9409\n",
      "Epoch 588/1000\n",
      "350/350 - 1s - loss: 0.1550 - accuracy: 0.9397\n",
      "Epoch 589/1000\n",
      "350/350 - 1s - loss: 0.1547 - accuracy: 0.9422\n",
      "Epoch 590/1000\n",
      "350/350 - 1s - loss: 0.1536 - accuracy: 0.9413\n",
      "Epoch 591/1000\n",
      "350/350 - 1s - loss: 0.1538 - accuracy: 0.9414\n",
      "Epoch 592/1000\n",
      "350/350 - 1s - loss: 0.1556 - accuracy: 0.9409\n",
      "Epoch 593/1000\n",
      "350/350 - 1s - loss: 0.1549 - accuracy: 0.9392\n",
      "Epoch 594/1000\n",
      "350/350 - 1s - loss: 0.1509 - accuracy: 0.9404\n",
      "Epoch 595/1000\n",
      "350/350 - 1s - loss: 0.1535 - accuracy: 0.9401\n",
      "Epoch 596/1000\n",
      "350/350 - 1s - loss: 0.1598 - accuracy: 0.9382\n",
      "Epoch 597/1000\n",
      "350/350 - 1s - loss: 0.1537 - accuracy: 0.9424\n",
      "Epoch 598/1000\n",
      "350/350 - 1s - loss: 0.1580 - accuracy: 0.9386\n",
      "Epoch 599/1000\n",
      "350/350 - 1s - loss: 0.1524 - accuracy: 0.9411\n",
      "Epoch 600/1000\n",
      "350/350 - 1s - loss: 0.1571 - accuracy: 0.9391\n",
      "Epoch 601/1000\n",
      "350/350 - 1s - loss: 0.1507 - accuracy: 0.9411\n",
      "Epoch 602/1000\n",
      "350/350 - 1s - loss: 0.1517 - accuracy: 0.9414\n",
      "Epoch 603/1000\n",
      "350/350 - 1s - loss: 0.1538 - accuracy: 0.9414\n",
      "Epoch 604/1000\n",
      "350/350 - 1s - loss: 0.1510 - accuracy: 0.9412\n",
      "Epoch 605/1000\n",
      "350/350 - 1s - loss: 0.1482 - accuracy: 0.9414\n",
      "Epoch 606/1000\n",
      "350/350 - 1s - loss: 0.1518 - accuracy: 0.9409\n",
      "Epoch 607/1000\n",
      "350/350 - 1s - loss: 0.1544 - accuracy: 0.9389\n",
      "Epoch 608/1000\n",
      "350/350 - 1s - loss: 0.1536 - accuracy: 0.9392\n",
      "Epoch 609/1000\n",
      "350/350 - 1s - loss: 0.1548 - accuracy: 0.9409\n",
      "Epoch 610/1000\n",
      "350/350 - 1s - loss: 0.1553 - accuracy: 0.9407\n",
      "Epoch 611/1000\n",
      "350/350 - 1s - loss: 0.1523 - accuracy: 0.9419\n",
      "Epoch 612/1000\n",
      "350/350 - 1s - loss: 0.1532 - accuracy: 0.9417\n",
      "Epoch 613/1000\n",
      "350/350 - 1s - loss: 0.1532 - accuracy: 0.9407\n",
      "Epoch 614/1000\n",
      "350/350 - 1s - loss: 0.1561 - accuracy: 0.9413\n",
      "Epoch 615/1000\n",
      "350/350 - 1s - loss: 0.1506 - accuracy: 0.9413\n",
      "Epoch 616/1000\n",
      "350/350 - 1s - loss: 0.1563 - accuracy: 0.9391\n",
      "Epoch 617/1000\n",
      "350/350 - 1s - loss: 0.1484 - accuracy: 0.9426\n",
      "Epoch 618/1000\n",
      "350/350 - 1s - loss: 0.1558 - accuracy: 0.9408\n",
      "Epoch 619/1000\n",
      "350/350 - 1s - loss: 0.1536 - accuracy: 0.9401\n",
      "Epoch 620/1000\n",
      "350/350 - 1s - loss: 0.1505 - accuracy: 0.9420\n",
      "Epoch 621/1000\n",
      "350/350 - 1s - loss: 0.1593 - accuracy: 0.9394\n",
      "Epoch 622/1000\n",
      "350/350 - 1s - loss: 0.1513 - accuracy: 0.9414\n",
      "Epoch 623/1000\n",
      "350/350 - 1s - loss: 0.1511 - accuracy: 0.9409\n",
      "Epoch 624/1000\n",
      "350/350 - 1s - loss: 0.1533 - accuracy: 0.9409\n",
      "Epoch 625/1000\n",
      "350/350 - 1s - loss: 0.1530 - accuracy: 0.9410\n",
      "Epoch 626/1000\n",
      "350/350 - 1s - loss: 0.1497 - accuracy: 0.9411\n",
      "Epoch 627/1000\n",
      "350/350 - 1s - loss: 0.1502 - accuracy: 0.9418\n",
      "Epoch 628/1000\n",
      "350/350 - 1s - loss: 0.1474 - accuracy: 0.9427\n",
      "Epoch 629/1000\n",
      "350/350 - 1s - loss: 0.1514 - accuracy: 0.9422\n",
      "Epoch 630/1000\n",
      "350/350 - 1s - loss: 0.1507 - accuracy: 0.9411\n",
      "Epoch 631/1000\n",
      "350/350 - 1s - loss: 0.1544 - accuracy: 0.9418\n",
      "Epoch 632/1000\n",
      "350/350 - 1s - loss: 0.1548 - accuracy: 0.9400\n",
      "Epoch 633/1000\n",
      "350/350 - 1s - loss: 0.1494 - accuracy: 0.9425\n",
      "Epoch 634/1000\n",
      "350/350 - 1s - loss: 0.1500 - accuracy: 0.9407\n",
      "Epoch 635/1000\n",
      "350/350 - 1s - loss: 0.1519 - accuracy: 0.9407\n",
      "Epoch 636/1000\n",
      "350/350 - 1s - loss: 0.1501 - accuracy: 0.9418\n",
      "Epoch 637/1000\n",
      "350/350 - 1s - loss: 0.1483 - accuracy: 0.9423\n",
      "Epoch 638/1000\n",
      "350/350 - 1s - loss: 0.1511 - accuracy: 0.9416\n",
      "Epoch 639/1000\n",
      "350/350 - 1s - loss: 0.1504 - accuracy: 0.9423\n",
      "Epoch 640/1000\n",
      "350/350 - 1s - loss: 0.1498 - accuracy: 0.9418\n",
      "Epoch 641/1000\n",
      "350/350 - 1s - loss: 0.1483 - accuracy: 0.9425\n",
      "Epoch 642/1000\n",
      "350/350 - 1s - loss: 0.1485 - accuracy: 0.9401\n",
      "Epoch 643/1000\n",
      "350/350 - 1s - loss: 0.1530 - accuracy: 0.9410\n",
      "Epoch 644/1000\n",
      "350/350 - 1s - loss: 0.1489 - accuracy: 0.9412\n",
      "Epoch 645/1000\n",
      "350/350 - 1s - loss: 0.1475 - accuracy: 0.9440\n",
      "Epoch 646/1000\n",
      "350/350 - 0s - loss: 0.1449 - accuracy: 0.9435\n",
      "Epoch 647/1000\n",
      "350/350 - 0s - loss: 0.1525 - accuracy: 0.9409\n",
      "Epoch 648/1000\n",
      "350/350 - 0s - loss: 0.1491 - accuracy: 0.9422\n",
      "Epoch 649/1000\n",
      "350/350 - 1s - loss: 0.1499 - accuracy: 0.9406\n",
      "Epoch 650/1000\n",
      "350/350 - 0s - loss: 0.1518 - accuracy: 0.9408\n",
      "Epoch 651/1000\n",
      "350/350 - 1s - loss: 0.1511 - accuracy: 0.9409\n",
      "Epoch 652/1000\n",
      "350/350 - 0s - loss: 0.1486 - accuracy: 0.9430\n",
      "Epoch 653/1000\n",
      "350/350 - 1s - loss: 0.1508 - accuracy: 0.9422\n",
      "Epoch 654/1000\n",
      "350/350 - 1s - loss: 0.1468 - accuracy: 0.9420\n",
      "Epoch 655/1000\n",
      "350/350 - 1s - loss: 0.1480 - accuracy: 0.9433\n",
      "Epoch 656/1000\n",
      "350/350 - 0s - loss: 0.1518 - accuracy: 0.9412\n",
      "Epoch 657/1000\n",
      "350/350 - 0s - loss: 0.1517 - accuracy: 0.9400\n",
      "Epoch 658/1000\n",
      "350/350 - 0s - loss: 0.1503 - accuracy: 0.9398\n",
      "Epoch 659/1000\n",
      "350/350 - 1s - loss: 0.1455 - accuracy: 0.9452\n",
      "Epoch 660/1000\n",
      "350/350 - 0s - loss: 0.1479 - accuracy: 0.9419\n",
      "Epoch 661/1000\n",
      "350/350 - 0s - loss: 0.1515 - accuracy: 0.9410\n",
      "Epoch 662/1000\n",
      "350/350 - 0s - loss: 0.1501 - accuracy: 0.9409\n",
      "Epoch 663/1000\n",
      "350/350 - 0s - loss: 0.1493 - accuracy: 0.9432\n",
      "Epoch 664/1000\n",
      "350/350 - 0s - loss: 0.1475 - accuracy: 0.9419\n",
      "Epoch 665/1000\n",
      "350/350 - 1s - loss: 0.1485 - accuracy: 0.9415\n",
      "Epoch 666/1000\n",
      "350/350 - 0s - loss: 0.1490 - accuracy: 0.9417\n",
      "Epoch 667/1000\n",
      "350/350 - 1s - loss: 0.1464 - accuracy: 0.9439\n",
      "Epoch 668/1000\n",
      "350/350 - 0s - loss: 0.1474 - accuracy: 0.9419\n",
      "Epoch 669/1000\n",
      "350/350 - 1s - loss: 0.1494 - accuracy: 0.9413\n",
      "Epoch 670/1000\n",
      "350/350 - 0s - loss: 0.1506 - accuracy: 0.9426\n",
      "Epoch 671/1000\n",
      "350/350 - 0s - loss: 0.1490 - accuracy: 0.9426\n",
      "Epoch 672/1000\n",
      "350/350 - 0s - loss: 0.1434 - accuracy: 0.9429\n",
      "Epoch 673/1000\n",
      "350/350 - 1s - loss: 0.1492 - accuracy: 0.9400\n",
      "Epoch 674/1000\n",
      "350/350 - 0s - loss: 0.1476 - accuracy: 0.9422\n",
      "Epoch 675/1000\n",
      "350/350 - 0s - loss: 0.1460 - accuracy: 0.9437\n",
      "Epoch 676/1000\n",
      "350/350 - 1s - loss: 0.1484 - accuracy: 0.9426\n",
      "Epoch 677/1000\n",
      "350/350 - 0s - loss: 0.1499 - accuracy: 0.9425\n",
      "Epoch 678/1000\n",
      "350/350 - 0s - loss: 0.1492 - accuracy: 0.9411\n",
      "Epoch 679/1000\n",
      "350/350 - 1s - loss: 0.1492 - accuracy: 0.9436\n",
      "Epoch 680/1000\n",
      "350/350 - 1s - loss: 0.1445 - accuracy: 0.9438\n",
      "Epoch 681/1000\n",
      "350/350 - 0s - loss: 0.1505 - accuracy: 0.9426\n",
      "Epoch 682/1000\n",
      "350/350 - 0s - loss: 0.1502 - accuracy: 0.9410\n",
      "Epoch 683/1000\n",
      "350/350 - 0s - loss: 0.1463 - accuracy: 0.9435\n",
      "Epoch 684/1000\n",
      "350/350 - 1s - loss: 0.1467 - accuracy: 0.9422\n",
      "Epoch 685/1000\n",
      "350/350 - 0s - loss: 0.1496 - accuracy: 0.9424\n",
      "Epoch 686/1000\n",
      "350/350 - 0s - loss: 0.1489 - accuracy: 0.9413\n",
      "Epoch 687/1000\n",
      "350/350 - 0s - loss: 0.1467 - accuracy: 0.9429\n",
      "Epoch 688/1000\n",
      "350/350 - 1s - loss: 0.1422 - accuracy: 0.9438\n",
      "Epoch 689/1000\n",
      "350/350 - 1s - loss: 0.1495 - accuracy: 0.9426\n",
      "Epoch 690/1000\n",
      "350/350 - 1s - loss: 0.1475 - accuracy: 0.9418\n",
      "Epoch 691/1000\n",
      "350/350 - 1s - loss: 0.1455 - accuracy: 0.9407\n",
      "Epoch 692/1000\n",
      "350/350 - 0s - loss: 0.1476 - accuracy: 0.9422\n",
      "Epoch 693/1000\n",
      "350/350 - 1s - loss: 0.1488 - accuracy: 0.9424\n",
      "Epoch 694/1000\n",
      "350/350 - 0s - loss: 0.1456 - accuracy: 0.9432\n",
      "Epoch 695/1000\n",
      "350/350 - 0s - loss: 0.1467 - accuracy: 0.9428\n",
      "Epoch 696/1000\n",
      "350/350 - 1s - loss: 0.1427 - accuracy: 0.9437\n",
      "Epoch 697/1000\n",
      "350/350 - 0s - loss: 0.1444 - accuracy: 0.9432\n",
      "Epoch 698/1000\n",
      "350/350 - 0s - loss: 0.1493 - accuracy: 0.9435\n",
      "Epoch 699/1000\n",
      "350/350 - 0s - loss: 0.1460 - accuracy: 0.9407\n",
      "Epoch 700/1000\n",
      "350/350 - 0s - loss: 0.1452 - accuracy: 0.9435\n",
      "Epoch 701/1000\n",
      "350/350 - 1s - loss: 0.1436 - accuracy: 0.9427\n",
      "Epoch 702/1000\n",
      "350/350 - 1s - loss: 0.1502 - accuracy: 0.9422\n",
      "Epoch 703/1000\n",
      "350/350 - 0s - loss: 0.1484 - accuracy: 0.9427\n",
      "Epoch 704/1000\n",
      "350/350 - 0s - loss: 0.1441 - accuracy: 0.9418\n",
      "Epoch 705/1000\n",
      "350/350 - 1s - loss: 0.1477 - accuracy: 0.9422\n",
      "Epoch 706/1000\n",
      "350/350 - 1s - loss: 0.1449 - accuracy: 0.9418\n",
      "Epoch 707/1000\n",
      "350/350 - 0s - loss: 0.1449 - accuracy: 0.9428\n",
      "Epoch 708/1000\n",
      "350/350 - 0s - loss: 0.1450 - accuracy: 0.9435\n",
      "Epoch 709/1000\n",
      "350/350 - 1s - loss: 0.1459 - accuracy: 0.9431\n",
      "Epoch 710/1000\n",
      "350/350 - 1s - loss: 0.1480 - accuracy: 0.9418\n",
      "Epoch 711/1000\n",
      "350/350 - 1s - loss: 0.1476 - accuracy: 0.9431\n",
      "Epoch 712/1000\n",
      "350/350 - 0s - loss: 0.1450 - accuracy: 0.9438\n",
      "Epoch 713/1000\n",
      "350/350 - 0s - loss: 0.1442 - accuracy: 0.9437\n",
      "Epoch 714/1000\n",
      "350/350 - 0s - loss: 0.1432 - accuracy: 0.9437\n",
      "Epoch 715/1000\n",
      "350/350 - 0s - loss: 0.1440 - accuracy: 0.9430\n",
      "Epoch 716/1000\n",
      "350/350 - 0s - loss: 0.1462 - accuracy: 0.9426\n",
      "Epoch 717/1000\n",
      "350/350 - 0s - loss: 0.1470 - accuracy: 0.9427\n",
      "Epoch 718/1000\n",
      "350/350 - 0s - loss: 0.1417 - accuracy: 0.9433\n",
      "Epoch 719/1000\n",
      "350/350 - 0s - loss: 0.1436 - accuracy: 0.9422\n",
      "Epoch 720/1000\n",
      "350/350 - 0s - loss: 0.1432 - accuracy: 0.9435\n",
      "Epoch 721/1000\n",
      "350/350 - 1s - loss: 0.1465 - accuracy: 0.9432\n",
      "Epoch 722/1000\n",
      "350/350 - 1s - loss: 0.1443 - accuracy: 0.9421\n",
      "Epoch 723/1000\n",
      "350/350 - 1s - loss: 0.1468 - accuracy: 0.9418\n",
      "Epoch 724/1000\n",
      "350/350 - 0s - loss: 0.1428 - accuracy: 0.9435\n",
      "Epoch 725/1000\n",
      "350/350 - 0s - loss: 0.1476 - accuracy: 0.9432\n",
      "Epoch 726/1000\n",
      "350/350 - 0s - loss: 0.1468 - accuracy: 0.9427\n",
      "Epoch 727/1000\n",
      "350/350 - 0s - loss: 0.1473 - accuracy: 0.9426\n",
      "Epoch 728/1000\n",
      "350/350 - 0s - loss: 0.1448 - accuracy: 0.9434\n",
      "Epoch 729/1000\n",
      "350/350 - 0s - loss: 0.1441 - accuracy: 0.9431\n",
      "Epoch 730/1000\n",
      "350/350 - 0s - loss: 0.1434 - accuracy: 0.9429\n",
      "Epoch 731/1000\n",
      "350/350 - 0s - loss: 0.1432 - accuracy: 0.9433\n",
      "Epoch 732/1000\n",
      "350/350 - 0s - loss: 0.1455 - accuracy: 0.9435\n",
      "Epoch 733/1000\n",
      "350/350 - 0s - loss: 0.1464 - accuracy: 0.9422\n",
      "Epoch 734/1000\n",
      "350/350 - 0s - loss: 0.1431 - accuracy: 0.9454\n",
      "Epoch 735/1000\n",
      "350/350 - 0s - loss: 0.1460 - accuracy: 0.9441\n",
      "Epoch 736/1000\n",
      "350/350 - 0s - loss: 0.1395 - accuracy: 0.9452\n",
      "Epoch 737/1000\n",
      "350/350 - 1s - loss: 0.1437 - accuracy: 0.9450\n",
      "Epoch 738/1000\n",
      "350/350 - 1s - loss: 0.1468 - accuracy: 0.9433\n",
      "Epoch 739/1000\n",
      "350/350 - 1s - loss: 0.1445 - accuracy: 0.9418\n",
      "Epoch 740/1000\n",
      "350/350 - 0s - loss: 0.1431 - accuracy: 0.9446\n",
      "Epoch 741/1000\n",
      "350/350 - 1s - loss: 0.1477 - accuracy: 0.9439\n",
      "Epoch 742/1000\n",
      "350/350 - 0s - loss: 0.1444 - accuracy: 0.9444\n",
      "Epoch 743/1000\n",
      "350/350 - 0s - loss: 0.1444 - accuracy: 0.9437\n",
      "Epoch 744/1000\n",
      "350/350 - 0s - loss: 0.1453 - accuracy: 0.9448\n",
      "Epoch 745/1000\n",
      "350/350 - 0s - loss: 0.1428 - accuracy: 0.9422\n",
      "Epoch 746/1000\n",
      "350/350 - 1s - loss: 0.1419 - accuracy: 0.9438\n",
      "Epoch 747/1000\n",
      "350/350 - 0s - loss: 0.1435 - accuracy: 0.9441\n",
      "Epoch 748/1000\n",
      "350/350 - 0s - loss: 0.1403 - accuracy: 0.9443\n",
      "Epoch 749/1000\n",
      "350/350 - 0s - loss: 0.1426 - accuracy: 0.9435\n",
      "Epoch 750/1000\n",
      "350/350 - 0s - loss: 0.1436 - accuracy: 0.9428\n",
      "Epoch 751/1000\n",
      "350/350 - 0s - loss: 0.1466 - accuracy: 0.9430\n",
      "Epoch 752/1000\n",
      "350/350 - 0s - loss: 0.1421 - accuracy: 0.9417\n",
      "Epoch 753/1000\n",
      "350/350 - 0s - loss: 0.1435 - accuracy: 0.9435\n",
      "Epoch 754/1000\n",
      "350/350 - 0s - loss: 0.1491 - accuracy: 0.9421\n",
      "Epoch 755/1000\n",
      "350/350 - 0s - loss: 0.1419 - accuracy: 0.9448\n",
      "Epoch 756/1000\n",
      "350/350 - 0s - loss: 0.1415 - accuracy: 0.9452\n",
      "Epoch 757/1000\n",
      "350/350 - 0s - loss: 0.1398 - accuracy: 0.9443\n",
      "Epoch 758/1000\n",
      "350/350 - 0s - loss: 0.1428 - accuracy: 0.9450\n",
      "Epoch 759/1000\n",
      "350/350 - 1s - loss: 0.1409 - accuracy: 0.9429\n",
      "Epoch 760/1000\n",
      "350/350 - 0s - loss: 0.1464 - accuracy: 0.9442\n",
      "Epoch 761/1000\n",
      "350/350 - 0s - loss: 0.1427 - accuracy: 0.9435\n",
      "Epoch 762/1000\n",
      "350/350 - 0s - loss: 0.1446 - accuracy: 0.9412\n",
      "Epoch 763/1000\n",
      "350/350 - 0s - loss: 0.1422 - accuracy: 0.9435\n",
      "Epoch 764/1000\n",
      "350/350 - 0s - loss: 0.1378 - accuracy: 0.9450\n",
      "Epoch 765/1000\n",
      "350/350 - 0s - loss: 0.1406 - accuracy: 0.9423\n",
      "Epoch 766/1000\n",
      "350/350 - 0s - loss: 0.1407 - accuracy: 0.9452\n",
      "Epoch 767/1000\n",
      "350/350 - 0s - loss: 0.1429 - accuracy: 0.9428\n",
      "Epoch 768/1000\n",
      "350/350 - 0s - loss: 0.1406 - accuracy: 0.9450\n",
      "Epoch 769/1000\n",
      "350/350 - 0s - loss: 0.1449 - accuracy: 0.9434\n",
      "Epoch 770/1000\n",
      "350/350 - 0s - loss: 0.1424 - accuracy: 0.9445\n",
      "Epoch 771/1000\n",
      "350/350 - 0s - loss: 0.1473 - accuracy: 0.9424\n",
      "Epoch 772/1000\n",
      "350/350 - 0s - loss: 0.1390 - accuracy: 0.9440\n",
      "Epoch 773/1000\n",
      "350/350 - 1s - loss: 0.1398 - accuracy: 0.9434\n",
      "Epoch 774/1000\n",
      "350/350 - 0s - loss: 0.1394 - accuracy: 0.9456\n",
      "Epoch 775/1000\n",
      "350/350 - 0s - loss: 0.1433 - accuracy: 0.9434\n",
      "Epoch 776/1000\n",
      "350/350 - 0s - loss: 0.1405 - accuracy: 0.9438\n",
      "Epoch 777/1000\n",
      "350/350 - 1s - loss: 0.1448 - accuracy: 0.9431\n",
      "Epoch 778/1000\n",
      "350/350 - 0s - loss: 0.1416 - accuracy: 0.9443\n",
      "Epoch 779/1000\n",
      "350/350 - 1s - loss: 0.1399 - accuracy: 0.9446\n",
      "Epoch 780/1000\n",
      "350/350 - 0s - loss: 0.1405 - accuracy: 0.9444\n",
      "Epoch 781/1000\n",
      "350/350 - 0s - loss: 0.1448 - accuracy: 0.9432\n",
      "Epoch 782/1000\n",
      "350/350 - 0s - loss: 0.1421 - accuracy: 0.9445\n",
      "Epoch 783/1000\n",
      "350/350 - 0s - loss: 0.1451 - accuracy: 0.9432\n",
      "Epoch 784/1000\n",
      "350/350 - 1s - loss: 0.1415 - accuracy: 0.9445\n",
      "Epoch 785/1000\n",
      "350/350 - 0s - loss: 0.1378 - accuracy: 0.9457\n",
      "Epoch 786/1000\n",
      "350/350 - 0s - loss: 0.1437 - accuracy: 0.9429\n",
      "Epoch 787/1000\n",
      "350/350 - 0s - loss: 0.1448 - accuracy: 0.9454\n",
      "Epoch 788/1000\n",
      "350/350 - 1s - loss: 0.1449 - accuracy: 0.9421\n",
      "Epoch 789/1000\n",
      "350/350 - 0s - loss: 0.1387 - accuracy: 0.9454\n",
      "Epoch 790/1000\n",
      "350/350 - 0s - loss: 0.1379 - accuracy: 0.9452\n",
      "Epoch 791/1000\n",
      "350/350 - 0s - loss: 0.1419 - accuracy: 0.9443\n",
      "Epoch 792/1000\n",
      "350/350 - 0s - loss: 0.1425 - accuracy: 0.9455\n",
      "Epoch 793/1000\n",
      "350/350 - 0s - loss: 0.1375 - accuracy: 0.9449\n",
      "Epoch 794/1000\n",
      "350/350 - 0s - loss: 0.1416 - accuracy: 0.9431\n",
      "Epoch 795/1000\n",
      "350/350 - 0s - loss: 0.1430 - accuracy: 0.9444\n",
      "Epoch 796/1000\n",
      "350/350 - 1s - loss: 0.1381 - accuracy: 0.9457\n",
      "Epoch 797/1000\n",
      "350/350 - 0s - loss: 0.1421 - accuracy: 0.9443\n",
      "Epoch 798/1000\n",
      "350/350 - 0s - loss: 0.1409 - accuracy: 0.9428\n",
      "Epoch 799/1000\n",
      "350/350 - 0s - loss: 0.1436 - accuracy: 0.9425\n",
      "Epoch 800/1000\n",
      "350/350 - 0s - loss: 0.1376 - accuracy: 0.9454\n",
      "Epoch 801/1000\n",
      "350/350 - 0s - loss: 0.1415 - accuracy: 0.9433\n",
      "Epoch 802/1000\n",
      "350/350 - 0s - loss: 0.1422 - accuracy: 0.9439\n",
      "Epoch 803/1000\n",
      "350/350 - 0s - loss: 0.1435 - accuracy: 0.9445\n",
      "Epoch 804/1000\n",
      "350/350 - 0s - loss: 0.1397 - accuracy: 0.9451\n",
      "Epoch 805/1000\n",
      "350/350 - 0s - loss: 0.1408 - accuracy: 0.9453\n",
      "Epoch 806/1000\n",
      "350/350 - 0s - loss: 0.1410 - accuracy: 0.9437\n",
      "Epoch 807/1000\n",
      "350/350 - 0s - loss: 0.1414 - accuracy: 0.9444\n",
      "Epoch 808/1000\n",
      "350/350 - 0s - loss: 0.1380 - accuracy: 0.9448\n",
      "Epoch 809/1000\n",
      "350/350 - 0s - loss: 0.1415 - accuracy: 0.9448\n",
      "Epoch 810/1000\n",
      "350/350 - 0s - loss: 0.1375 - accuracy: 0.9459\n",
      "Epoch 811/1000\n",
      "350/350 - 0s - loss: 0.1376 - accuracy: 0.9449\n",
      "Epoch 812/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9472\n",
      "Epoch 813/1000\n",
      "350/350 - 0s - loss: 0.1406 - accuracy: 0.9443\n",
      "Epoch 814/1000\n",
      "350/350 - 0s - loss: 0.1439 - accuracy: 0.9440\n",
      "Epoch 815/1000\n",
      "350/350 - 0s - loss: 0.1397 - accuracy: 0.9432\n",
      "Epoch 816/1000\n",
      "350/350 - 0s - loss: 0.1380 - accuracy: 0.9452\n",
      "Epoch 817/1000\n",
      "350/350 - 0s - loss: 0.1414 - accuracy: 0.9439\n",
      "Epoch 818/1000\n",
      "350/350 - 1s - loss: 0.1427 - accuracy: 0.9429\n",
      "Epoch 819/1000\n",
      "350/350 - 0s - loss: 0.1369 - accuracy: 0.9454\n",
      "Epoch 820/1000\n",
      "350/350 - 1s - loss: 0.1425 - accuracy: 0.9422\n",
      "Epoch 821/1000\n",
      "350/350 - 1s - loss: 0.1397 - accuracy: 0.9438\n",
      "Epoch 822/1000\n",
      "350/350 - 0s - loss: 0.1386 - accuracy: 0.9440\n",
      "Epoch 823/1000\n",
      "350/350 - 0s - loss: 0.1426 - accuracy: 0.9437\n",
      "Epoch 824/1000\n",
      "350/350 - 1s - loss: 0.1465 - accuracy: 0.9426\n",
      "Epoch 825/1000\n",
      "350/350 - 1s - loss: 0.1380 - accuracy: 0.9439\n",
      "Epoch 826/1000\n",
      "350/350 - 0s - loss: 0.1382 - accuracy: 0.9461\n",
      "Epoch 827/1000\n",
      "350/350 - 0s - loss: 0.1409 - accuracy: 0.9452\n",
      "Epoch 828/1000\n",
      "350/350 - 1s - loss: 0.1397 - accuracy: 0.9451\n",
      "Epoch 829/1000\n",
      "350/350 - 0s - loss: 0.1385 - accuracy: 0.9452\n",
      "Epoch 830/1000\n",
      "350/350 - 0s - loss: 0.1360 - accuracy: 0.9457\n",
      "Epoch 831/1000\n",
      "350/350 - 0s - loss: 0.1434 - accuracy: 0.9435\n",
      "Epoch 832/1000\n",
      "350/350 - 0s - loss: 0.1382 - accuracy: 0.9460\n",
      "Epoch 833/1000\n",
      "350/350 - 0s - loss: 0.1381 - accuracy: 0.9447\n",
      "Epoch 834/1000\n",
      "350/350 - 0s - loss: 0.1411 - accuracy: 0.9434\n",
      "Epoch 835/1000\n",
      "350/350 - 0s - loss: 0.1389 - accuracy: 0.9444\n",
      "Epoch 836/1000\n",
      "350/350 - 0s - loss: 0.1391 - accuracy: 0.9436\n",
      "Epoch 837/1000\n",
      "350/350 - 1s - loss: 0.1392 - accuracy: 0.9443\n",
      "Epoch 838/1000\n",
      "350/350 - 0s - loss: 0.1364 - accuracy: 0.9443\n",
      "Epoch 839/1000\n",
      "350/350 - 0s - loss: 0.1339 - accuracy: 0.9474\n",
      "Epoch 840/1000\n",
      "350/350 - 0s - loss: 0.1375 - accuracy: 0.9454\n",
      "Epoch 841/1000\n",
      "350/350 - 0s - loss: 0.1395 - accuracy: 0.9441\n",
      "Epoch 842/1000\n",
      "350/350 - 0s - loss: 0.1408 - accuracy: 0.9448\n",
      "Epoch 843/1000\n",
      "350/350 - 0s - loss: 0.1388 - accuracy: 0.9462\n",
      "Epoch 844/1000\n",
      "350/350 - 1s - loss: 0.1398 - accuracy: 0.9440\n",
      "Epoch 845/1000\n",
      "350/350 - 0s - loss: 0.1424 - accuracy: 0.9428\n",
      "Epoch 846/1000\n",
      "350/350 - 1s - loss: 0.1400 - accuracy: 0.9449\n",
      "Epoch 847/1000\n",
      "350/350 - 1s - loss: 0.1379 - accuracy: 0.9448\n",
      "Epoch 848/1000\n",
      "350/350 - 0s - loss: 0.1372 - accuracy: 0.9451\n",
      "Epoch 849/1000\n",
      "350/350 - 0s - loss: 0.1372 - accuracy: 0.9452\n",
      "Epoch 850/1000\n",
      "350/350 - 0s - loss: 0.1363 - accuracy: 0.9455\n",
      "Epoch 851/1000\n",
      "350/350 - 0s - loss: 0.1367 - accuracy: 0.9459\n",
      "Epoch 852/1000\n",
      "350/350 - 0s - loss: 0.1410 - accuracy: 0.9452\n",
      "Epoch 853/1000\n",
      "350/350 - 0s - loss: 0.1385 - accuracy: 0.9443\n",
      "Epoch 854/1000\n",
      "350/350 - 1s - loss: 0.1397 - accuracy: 0.9452\n",
      "Epoch 855/1000\n",
      "350/350 - 0s - loss: 0.1388 - accuracy: 0.9452\n",
      "Epoch 856/1000\n",
      "350/350 - 1s - loss: 0.1405 - accuracy: 0.9435\n",
      "Epoch 857/1000\n",
      "350/350 - 1s - loss: 0.1440 - accuracy: 0.9452\n",
      "Epoch 858/1000\n",
      "350/350 - 1s - loss: 0.1356 - accuracy: 0.9458\n",
      "Epoch 859/1000\n",
      "350/350 - 0s - loss: 0.1387 - accuracy: 0.9443\n",
      "Epoch 860/1000\n",
      "350/350 - 0s - loss: 0.1349 - accuracy: 0.9449\n",
      "Epoch 861/1000\n",
      "350/350 - 0s - loss: 0.1412 - accuracy: 0.9443\n",
      "Epoch 862/1000\n",
      "350/350 - 0s - loss: 0.1368 - accuracy: 0.9458\n",
      "Epoch 863/1000\n",
      "350/350 - 0s - loss: 0.1352 - accuracy: 0.9465\n",
      "Epoch 864/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9456\n",
      "Epoch 865/1000\n",
      "350/350 - 0s - loss: 0.1400 - accuracy: 0.9453\n",
      "Epoch 866/1000\n",
      "350/350 - 0s - loss: 0.1346 - accuracy: 0.9456\n",
      "Epoch 867/1000\n",
      "350/350 - 0s - loss: 0.1391 - accuracy: 0.9455\n",
      "Epoch 868/1000\n",
      "350/350 - 0s - loss: 0.1373 - accuracy: 0.9447\n",
      "Epoch 869/1000\n",
      "350/350 - 0s - loss: 0.1394 - accuracy: 0.9436\n",
      "Epoch 870/1000\n",
      "350/350 - 0s - loss: 0.1335 - accuracy: 0.9459\n",
      "Epoch 871/1000\n",
      "350/350 - 1s - loss: 0.1363 - accuracy: 0.9455\n",
      "Epoch 872/1000\n",
      "350/350 - 0s - loss: 0.1379 - accuracy: 0.9469\n",
      "Epoch 873/1000\n",
      "350/350 - 1s - loss: 0.1357 - accuracy: 0.9445\n",
      "Epoch 874/1000\n",
      "350/350 - 0s - loss: 0.1416 - accuracy: 0.9445\n",
      "Epoch 875/1000\n",
      "350/350 - 0s - loss: 0.1384 - accuracy: 0.9452\n",
      "Epoch 876/1000\n",
      "350/350 - 0s - loss: 0.1383 - accuracy: 0.9440\n",
      "Epoch 877/1000\n",
      "350/350 - 0s - loss: 0.1397 - accuracy: 0.9435\n",
      "Epoch 878/1000\n",
      "350/350 - 0s - loss: 0.1370 - accuracy: 0.9445\n",
      "Epoch 879/1000\n",
      "350/350 - 0s - loss: 0.1331 - accuracy: 0.9479\n",
      "Epoch 880/1000\n",
      "350/350 - 0s - loss: 0.1347 - accuracy: 0.9468\n",
      "Epoch 881/1000\n",
      "350/350 - 0s - loss: 0.1426 - accuracy: 0.9440\n",
      "Epoch 882/1000\n",
      "350/350 - 0s - loss: 0.1405 - accuracy: 0.9446\n",
      "Epoch 883/1000\n",
      "350/350 - 0s - loss: 0.1365 - accuracy: 0.9457\n",
      "Epoch 884/1000\n",
      "350/350 - 1s - loss: 0.1374 - accuracy: 0.9452\n",
      "Epoch 885/1000\n",
      "350/350 - 0s - loss: 0.1363 - accuracy: 0.9435\n",
      "Epoch 886/1000\n",
      "350/350 - 0s - loss: 0.1391 - accuracy: 0.9439\n",
      "Epoch 887/1000\n",
      "350/350 - 0s - loss: 0.1372 - accuracy: 0.9459\n",
      "Epoch 888/1000\n",
      "350/350 - 0s - loss: 0.1345 - accuracy: 0.9456\n",
      "Epoch 889/1000\n",
      "350/350 - 0s - loss: 0.1362 - accuracy: 0.9451\n",
      "Epoch 890/1000\n",
      "350/350 - 0s - loss: 0.1377 - accuracy: 0.9444\n",
      "Epoch 891/1000\n",
      "350/350 - 0s - loss: 0.1384 - accuracy: 0.9444\n",
      "Epoch 892/1000\n",
      "350/350 - 0s - loss: 0.1376 - accuracy: 0.9444\n",
      "Epoch 893/1000\n",
      "350/350 - 0s - loss: 0.1347 - accuracy: 0.9450\n",
      "Epoch 894/1000\n",
      "350/350 - 0s - loss: 0.1416 - accuracy: 0.9433\n",
      "Epoch 895/1000\n",
      "350/350 - 0s - loss: 0.1378 - accuracy: 0.9447\n",
      "Epoch 896/1000\n",
      "350/350 - 0s - loss: 0.1389 - accuracy: 0.9452\n",
      "Epoch 897/1000\n",
      "350/350 - 0s - loss: 0.1377 - accuracy: 0.9452\n",
      "Epoch 898/1000\n",
      "350/350 - 0s - loss: 0.1379 - accuracy: 0.9458\n",
      "Epoch 899/1000\n",
      "350/350 - 0s - loss: 0.1371 - accuracy: 0.9462\n",
      "Epoch 900/1000\n",
      "350/350 - 0s - loss: 0.1361 - accuracy: 0.9443\n",
      "Epoch 901/1000\n",
      "350/350 - 0s - loss: 0.1381 - accuracy: 0.9446\n",
      "Epoch 902/1000\n",
      "350/350 - 0s - loss: 0.1384 - accuracy: 0.9460\n",
      "Epoch 903/1000\n",
      "350/350 - 0s - loss: 0.1340 - accuracy: 0.9464\n",
      "Epoch 904/1000\n",
      "350/350 - 0s - loss: 0.1311 - accuracy: 0.9474\n",
      "Epoch 905/1000\n",
      "350/350 - 0s - loss: 0.1384 - accuracy: 0.9443\n",
      "Epoch 906/1000\n",
      "350/350 - 0s - loss: 0.1359 - accuracy: 0.9453\n",
      "Epoch 907/1000\n",
      "350/350 - 0s - loss: 0.1380 - accuracy: 0.9445\n",
      "Epoch 908/1000\n",
      "350/350 - 0s - loss: 0.1394 - accuracy: 0.9452\n",
      "Epoch 909/1000\n",
      "350/350 - 0s - loss: 0.1345 - accuracy: 0.9471\n",
      "Epoch 910/1000\n",
      "350/350 - 0s - loss: 0.1357 - accuracy: 0.9446\n",
      "Epoch 911/1000\n",
      "350/350 - 0s - loss: 0.1328 - accuracy: 0.9467\n",
      "Epoch 912/1000\n",
      "350/350 - 0s - loss: 0.1397 - accuracy: 0.9449\n",
      "Epoch 913/1000\n",
      "350/350 - 0s - loss: 0.1401 - accuracy: 0.9451\n",
      "Epoch 914/1000\n",
      "350/350 - 0s - loss: 0.1353 - accuracy: 0.9471\n",
      "Epoch 915/1000\n",
      "350/350 - 0s - loss: 0.1351 - accuracy: 0.9467\n",
      "Epoch 916/1000\n",
      "350/350 - 0s - loss: 0.1361 - accuracy: 0.9461\n",
      "Epoch 917/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9450\n",
      "Epoch 918/1000\n",
      "350/350 - 0s - loss: 0.1375 - accuracy: 0.9446\n",
      "Epoch 919/1000\n",
      "350/350 - 0s - loss: 0.1342 - accuracy: 0.9472\n",
      "Epoch 920/1000\n",
      "350/350 - 0s - loss: 0.1370 - accuracy: 0.9470\n",
      "Epoch 921/1000\n",
      "350/350 - 0s - loss: 0.1327 - accuracy: 0.9469\n",
      "Epoch 922/1000\n",
      "350/350 - 0s - loss: 0.1350 - accuracy: 0.9459\n",
      "Epoch 923/1000\n",
      "350/350 - 0s - loss: 0.1316 - accuracy: 0.9463\n",
      "Epoch 924/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9463\n",
      "Epoch 925/1000\n",
      "350/350 - 0s - loss: 0.1374 - accuracy: 0.9467\n",
      "Epoch 926/1000\n",
      "350/350 - 0s - loss: 0.1379 - accuracy: 0.9456\n",
      "Epoch 927/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9463\n",
      "Epoch 928/1000\n",
      "350/350 - 0s - loss: 0.1331 - accuracy: 0.9452\n",
      "Epoch 929/1000\n",
      "350/350 - 0s - loss: 0.1342 - accuracy: 0.9456\n",
      "Epoch 930/1000\n",
      "350/350 - 0s - loss: 0.1336 - accuracy: 0.9454\n",
      "Epoch 931/1000\n",
      "350/350 - 0s - loss: 0.1353 - accuracy: 0.9467\n",
      "Epoch 932/1000\n",
      "350/350 - 0s - loss: 0.1386 - accuracy: 0.9445\n",
      "Epoch 933/1000\n",
      "350/350 - 0s - loss: 0.1386 - accuracy: 0.9447\n",
      "Epoch 934/1000\n",
      "350/350 - 0s - loss: 0.1375 - accuracy: 0.9448\n",
      "Epoch 935/1000\n",
      "350/350 - 0s - loss: 0.1370 - accuracy: 0.9461\n",
      "Epoch 936/1000\n",
      "350/350 - 0s - loss: 0.1352 - accuracy: 0.9460\n",
      "Epoch 937/1000\n",
      "350/350 - 0s - loss: 0.1346 - accuracy: 0.9464\n",
      "Epoch 938/1000\n",
      "350/350 - 0s - loss: 0.1355 - accuracy: 0.9466\n",
      "Epoch 939/1000\n",
      "350/350 - 0s - loss: 0.1353 - accuracy: 0.9454\n",
      "Epoch 940/1000\n",
      "350/350 - 0s - loss: 0.1349 - accuracy: 0.9463\n",
      "Epoch 941/1000\n",
      "350/350 - 1s - loss: 0.1313 - accuracy: 0.9469\n",
      "Epoch 942/1000\n",
      "350/350 - 1s - loss: 0.1365 - accuracy: 0.9453\n",
      "Epoch 943/1000\n",
      "350/350 - 0s - loss: 0.1332 - accuracy: 0.9462\n",
      "Epoch 944/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9458\n",
      "Epoch 945/1000\n",
      "350/350 - 0s - loss: 0.1351 - accuracy: 0.9452\n",
      "Epoch 946/1000\n",
      "350/350 - 0s - loss: 0.1344 - accuracy: 0.9457\n",
      "Epoch 947/1000\n",
      "350/350 - 0s - loss: 0.1339 - accuracy: 0.9464\n",
      "Epoch 948/1000\n",
      "350/350 - 0s - loss: 0.1305 - accuracy: 0.9473\n",
      "Epoch 949/1000\n",
      "350/350 - 0s - loss: 0.1386 - accuracy: 0.9453\n",
      "Epoch 950/1000\n",
      "350/350 - 0s - loss: 0.1404 - accuracy: 0.9454\n",
      "Epoch 951/1000\n",
      "350/350 - 0s - loss: 0.1342 - accuracy: 0.9470\n",
      "Epoch 952/1000\n",
      "350/350 - 0s - loss: 0.1349 - accuracy: 0.9484\n",
      "Epoch 953/1000\n",
      "350/350 - 0s - loss: 0.1313 - accuracy: 0.9469\n",
      "Epoch 954/1000\n",
      "350/350 - 0s - loss: 0.1367 - accuracy: 0.9460\n",
      "Epoch 955/1000\n",
      "350/350 - 0s - loss: 0.1340 - accuracy: 0.9460\n",
      "Epoch 956/1000\n",
      "350/350 - 0s - loss: 0.1362 - accuracy: 0.9438\n",
      "Epoch 957/1000\n",
      "350/350 - 0s - loss: 0.1340 - accuracy: 0.9460\n",
      "Epoch 958/1000\n",
      "350/350 - 0s - loss: 0.1348 - accuracy: 0.9461\n",
      "Epoch 959/1000\n",
      "350/350 - 0s - loss: 0.1321 - accuracy: 0.9472\n",
      "Epoch 960/1000\n",
      "350/350 - 0s - loss: 0.1356 - accuracy: 0.9471\n",
      "Epoch 961/1000\n",
      "350/350 - 1s - loss: 0.1344 - accuracy: 0.9454\n",
      "Epoch 962/1000\n",
      "350/350 - 0s - loss: 0.1361 - accuracy: 0.9440\n",
      "Epoch 963/1000\n",
      "350/350 - 0s - loss: 0.1334 - accuracy: 0.9462\n",
      "Epoch 964/1000\n",
      "350/350 - 0s - loss: 0.1323 - accuracy: 0.9473\n",
      "Epoch 965/1000\n",
      "350/350 - 0s - loss: 0.1352 - accuracy: 0.9460\n",
      "Epoch 966/1000\n",
      "350/350 - 0s - loss: 0.1344 - accuracy: 0.9468\n",
      "Epoch 967/1000\n",
      "350/350 - 0s - loss: 0.1327 - accuracy: 0.9466\n",
      "Epoch 968/1000\n",
      "350/350 - 0s - loss: 0.1341 - accuracy: 0.9458\n",
      "Epoch 969/1000\n",
      "350/350 - 0s - loss: 0.1348 - accuracy: 0.9446\n",
      "Epoch 970/1000\n",
      "350/350 - 0s - loss: 0.1387 - accuracy: 0.9433\n",
      "Epoch 971/1000\n",
      "350/350 - 0s - loss: 0.1329 - accuracy: 0.9464\n",
      "Epoch 972/1000\n",
      "350/350 - 0s - loss: 0.1358 - accuracy: 0.9460\n",
      "Epoch 973/1000\n",
      "350/350 - 0s - loss: 0.1290 - accuracy: 0.9475\n",
      "Epoch 974/1000\n",
      "350/350 - 0s - loss: 0.1368 - accuracy: 0.9442\n",
      "Epoch 975/1000\n",
      "350/350 - 0s - loss: 0.1320 - accuracy: 0.9477\n",
      "Epoch 976/1000\n",
      "350/350 - 0s - loss: 0.1306 - accuracy: 0.9477\n",
      "Epoch 977/1000\n",
      "350/350 - 0s - loss: 0.1355 - accuracy: 0.9460\n",
      "Epoch 978/1000\n",
      "350/350 - 0s - loss: 0.1330 - accuracy: 0.9459\n",
      "Epoch 979/1000\n",
      "350/350 - 0s - loss: 0.1334 - accuracy: 0.9469\n",
      "Epoch 980/1000\n",
      "350/350 - 0s - loss: 0.1332 - accuracy: 0.9467\n",
      "Epoch 981/1000\n",
      "350/350 - 0s - loss: 0.1345 - accuracy: 0.9457\n",
      "Epoch 982/1000\n",
      "350/350 - 0s - loss: 0.1333 - accuracy: 0.9477\n",
      "Epoch 983/1000\n",
      "350/350 - 0s - loss: 0.1353 - accuracy: 0.9449\n",
      "Epoch 984/1000\n",
      "350/350 - 0s - loss: 0.1382 - accuracy: 0.9444\n",
      "Epoch 985/1000\n",
      "350/350 - 0s - loss: 0.1349 - accuracy: 0.9460\n",
      "Epoch 986/1000\n",
      "350/350 - 0s - loss: 0.1338 - accuracy: 0.9449\n",
      "Epoch 987/1000\n",
      "350/350 - 0s - loss: 0.1333 - accuracy: 0.9462\n",
      "Epoch 988/1000\n",
      "350/350 - 0s - loss: 0.1343 - accuracy: 0.9460\n",
      "Epoch 989/1000\n",
      "350/350 - 0s - loss: 0.1291 - accuracy: 0.9485\n",
      "Epoch 990/1000\n",
      "350/350 - 0s - loss: 0.1342 - accuracy: 0.9468\n",
      "Epoch 991/1000\n",
      "350/350 - 0s - loss: 0.1316 - accuracy: 0.9469\n",
      "Epoch 992/1000\n",
      "350/350 - 0s - loss: 0.1344 - accuracy: 0.9466\n",
      "Epoch 993/1000\n",
      "350/350 - 0s - loss: 0.1344 - accuracy: 0.9459\n",
      "Epoch 994/1000\n",
      "350/350 - 0s - loss: 0.1331 - accuracy: 0.9476\n",
      "Epoch 995/1000\n",
      "350/350 - 1s - loss: 0.1371 - accuracy: 0.9452\n",
      "Epoch 996/1000\n",
      "350/350 - 1s - loss: 0.1347 - accuracy: 0.9466\n",
      "Epoch 997/1000\n",
      "350/350 - 0s - loss: 0.1332 - accuracy: 0.9463\n",
      "Epoch 998/1000\n",
      "350/350 - 0s - loss: 0.1360 - accuracy: 0.9459\n",
      "Epoch 999/1000\n",
      "350/350 - 0s - loss: 0.1323 - accuracy: 0.9467\n",
      "Epoch 1000/1000\n",
      "350/350 - 0s - loss: 0.1300 - accuracy: 0.9466\n"
     ]
    }
   ],
   "source": [
    "## Compile and train the deep learning model\n",
    "fire_model_v1.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "modelHistory_v1 = fire_model_v1.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=NoOfRuns,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT MODEL ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,4))\n",
    "\n",
    "ax[0].plot(modelHistory_v1.history['loss'])\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "\n",
    "ax[1].plot(modelHistory_v1.history['accuracy'])\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 - 0s - loss: 0.6654 - accuracy: 0.8935\n",
      "Loss: 0.6653604507446289, Accuracy: 0.8934513926506042\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = fire_model_v1.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [[9.99999881e-01 4.62594478e-08 1.55661510e-07]\n",
      " [9.99965668e-01 3.21269226e-06 3.10614414e-05]\n",
      " [4.86784309e-01 2.45792910e-01 2.67422676e-01]\n",
      " ...\n",
      " [8.88982415e-01 2.86429329e-03 1.08153269e-01]\n",
      " [8.61757159e-01 7.61422887e-02 6.21005744e-02]\n",
      " [9.99980092e-01 1.13899404e-07 1.98063735e-05]]\n",
      "Predicted class: 279\n"
     ]
    }
   ],
   "source": [
    "### Making Predictions with new data\n",
    "# new_data = X_scaler.transform(np.array([[-1.2, 0.3, 0.4]]))\n",
    "new_data = X_test_scaled\n",
    "\n",
    "print(f\"Model output: {fire_model_v1.predict(new_data)}\")\n",
    "print(f\"Predicted class: {np.argmax(fire_model_v1.predict(new_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions_v1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>P(0) model1</th>\n",
       "      <th>P(100) model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99997</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48678</td>\n",
       "      <td>0.24579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>0.00018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88473</td>\n",
       "      <td>0.10692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54068</td>\n",
       "      <td>0.45905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96799</td>\n",
       "      <td>0.03084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88898</td>\n",
       "      <td>0.00286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.86176</td>\n",
       "      <td>0.07614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3726 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predictions_v1  Actual  P(0) model1  P(100) model1\n",
       "0                  0       0      1.00000        0.00000\n",
       "1                  0       0      0.99997        0.00000\n",
       "2                  0       0      0.48678        0.24579\n",
       "3                  0       0      0.99660        0.00018\n",
       "4                  0       0      0.88473        0.10692\n",
       "...              ...     ...          ...            ...\n",
       "3721               0       0      0.54068        0.45905\n",
       "3722               0       0      0.96799        0.03084\n",
       "3723               0       0      0.88898        0.00286\n",
       "3724               0       0      0.86176        0.07614\n",
       "3725               0       0      0.99998        0.00000\n",
       "\n",
       "[3726 rows x 4 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### View prediction probabilities\n",
    "predictions_v1 = np.argmax(fire_model_v1.predict(X_test_scaled), axis=1)\n",
    "probs_v1 = fire_model_v1.predict(X_test_scaled)\n",
    "\n",
    "# Change the shape of y\n",
    "old_y_test = y_test\n",
    "new_y_test = np.array(old_y_test)\n",
    "y_test = new_y_test.reshape(-1, 1) \n",
    "y_test\n",
    "y_test_df = y_test.ravel()\n",
    "y_test_df\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Predictions_v1\": predictions_v1,\n",
    "    \"Actual\": y_test_df, \n",
    "    \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "    \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "    })\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING MODEL\n",
    "# !pip install dill\n",
    "# import dill\n",
    "\n",
    "# with open('NN_fireClassModel.pkl', 'wb') as f:\n",
    "#     dill.dump(fire_model_v1, f)\n",
    "\n",
    "final_model_path = os.path.join(\"..\", \"static\", \"model\", \"fires_class_model_v1.h5\")\n",
    "temp_model_path = os.path.join(\"fires_class_model_v2.h5\")\n",
    "\n",
    "fire_model_v1.save(temp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVING MODEL\n",
    "# # save your model by updating \"your_name\" with your name\n",
    "# # and \"your_model\" with your model variable\n",
    "# # be sure to turn this in to BCS\n",
    "# # if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "# import joblib\n",
    "# filename = 'NN_fireClassModel.sav'\n",
    "# joblib.dump(fire_model_v1, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELOAD AND RUN TEST RUN ON NEW MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### VIEW PREDICTION AND PROBABILITIES\n",
    "# predictions_v1 = np.argmax(fire_model_v1.predict(X_test_scaled), axis=1)\n",
    "# probs_v1 = fire_model_v1.predict(X_test_scaled)\n",
    "\n",
    "# # Change the shape of y\n",
    "# old_y_test = y_test\n",
    "# new_y_test = np.array(old_y_test)\n",
    "# y_test = new_y_test.reshape(-1, 1) \n",
    "# y_test\n",
    "# y_test_df = y_test.ravel()\n",
    "# y_test_df\n",
    "\n",
    "\n",
    "# pred_df = pd.DataFrame({\n",
    "#     \"Predictions_v1\": predictions_v1,\n",
    "#     \"Actual\": y_test_df, \n",
    "#     \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "#     \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "#     })\n",
    "\n",
    "# pred_df\n",
    "\n",
    "# # FILTER FOR CLASS G (6) FIRES\n",
    "# highFire_df=pred_df.loc[(pred_df[\"Predictions_v1\"] >= 1) & (pred_df[\"Actual\"] >= 1)]\n",
    "# highFire_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN RESULTS TO LOOK AT THE INPUTS FOR THE EXTREME VALUES\n",
    "# real_6s = [120,121,325,326,384,385, 401,402,459,460,712,713,737,738,841,844,845,854,855,963,964,1045,1046 ]\n",
    "# model_6s = [30,31,120,121,334,335,546,547,677,678,683,684,850,851,909,910,952,953,963,964,998,999,1045,1046]\n",
    "# both_6s = [120,963,1045,2231,3130,3389]\n",
    "# ExTrain = [9,34,40,42,52,53,55,70,87,88]\n",
    "\n",
    "# for i in both_6s:\n",
    "#     print(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD MODEL\n",
    "# import keras.models\n",
    "\n",
    "# New_model = keras.models.load_model('fires_class_model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST/RUN NEW MODEL\n",
    "# model_loss, model_accuracy = New_model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Making Predictions with new data\n",
    "# new_data = X_test_scaled\n",
    "\n",
    "# print(f\"Model output: {New_model.predict(new_data)}\")\n",
    "# print(f\"Predicted class: {np.argmax(New_model.predict(new_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST MODEL WITH NEW DATA\n",
    "# # --------------------------------------------------------------- #\n",
    "\n",
    "# # IMPORT CSV FOR DF\n",
    "# X_input_dfFormat = os.path.join(\"..\", \"Data\", \"X_input_dfFormat_v2.csv\")\n",
    "\n",
    "# # Open the CSV Files, Convert to a Dataframe, and Save as a Variable\n",
    "# X_input_dfFormat_df = pd.read_csv(X_input_dfFormat)\n",
    "\n",
    "# # X_input_dfFormat_df['NAME_Lincoln']\n",
    "\n",
    "# # PREP X VALUES FOR MODEL\n",
    "# # --------------------------------------------------------------- #\n",
    "# # # Reshape X from df to array v1\n",
    "# newInput = X_input_dfFormat_df.values.reshape(-1, 58)\n",
    "\n",
    "# # # # View output\n",
    "# # print(f\"Shape of X Input is {X.shape}\")\n",
    "# # print(f\"Type of X input is {type(X)}\")\n",
    "\n",
    "# # RUN TEST\n",
    "# # --------------------------------------------------------------- #\n",
    "# # print(f\"Model output: {np.argmax(fire_model_v1.predict(newInput), axis=1)}\")\n",
    "# # np.argmax(New_model.predict(new_data))\n",
    "\n",
    "# # CREATE TO VIEW PREDICTIONS\n",
    "# # --------------------------------------------------------------- #\n",
    "# predictions_newInput = np.argmax(fire_model_v1.predict(newInput), axis=1)\n",
    "# probs_v1 = fire_model_v1.predict(newInput)\n",
    "\n",
    "# pred_df = pd.DataFrame({\n",
    "#     \"Predictions_v1\": predictions_newInput,\n",
    "#     \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "#     \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "#     })\n",
    "\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
