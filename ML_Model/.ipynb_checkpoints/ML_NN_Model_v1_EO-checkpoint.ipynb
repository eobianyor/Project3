{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DEPENDENCIES\n",
    "# FOR DATA\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "# import requests\n",
    "# import datefinder\n",
    "\n",
    "# # FOR SQL LITE\n",
    "# from sqlalchemy import create_engine\n",
    "# from datetime import date\n",
    "\n",
    "# # FOR PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "# FOR MODELING\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# FOR KNN AND OTHER MODELING\n",
    "# from scipy.optimize import curve_fit\n",
    "# # from splinter import Browser\n",
    "# # from bs4 import BeautifulSoup as BS\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.datasets import make_blobs\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "\n",
    "# FOR TF MODELS\n",
    "import keras.models\n",
    "import keras.layers\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "idahoCounties = ['Ada', 'Adams', 'Bannock', 'Bear Lake', 'Benewah', 'Bingham', 'Blaine', 'Boise', 'Bonner', 'Bonneville', 'Boundary','Butte', \n",
    " 'Camas', 'Canyon', 'Caribou', 'Cassia', 'Clark', 'Clearwater', 'Custer', 'Elmore', 'Franklin', 'Fremont', 'Gem', 'Gooding', \n",
    " 'Idaho', 'Jefferson', 'Jerome' 'Kootenai', 'Latah', 'Lemhi', 'Lewis', 'Lincoln', 'Madison', 'Minidoka','Nez Perce', \n",
    " 'Oneida', 'Owyhee', 'Payette', 'Power', 'Shoshone', 'Teton', 'Twin Falls', 'Valley', 'Washington']\n",
    "        \n",
    "\n",
    "notIdahoCounties = ['Baker', 'Beaverhead', 'Box Elder', 'Elko', 'Gallatin', 'Malheur', 'Mineral', 'Missoula', 'Ravalli', 'Sanders']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the CSV Files\n",
    "idahoFireWeatherDrought = os.path.join(\"..\", \"Data\", \"fires_Idaho_2000_2015_drought_weather.csv\")\n",
    "\n",
    "# Open the CSV Files, Convert to a Dataframe, and Save as a Variable\n",
    "idaho_Fire_Weather_Drought_df = pd.read_csv(idahoFireWeatherDrought)\n",
    "# fires_Idaho_df = pd.read_csv(idahoFires, dtype={\"LOCAL_INCIDENT_ID\": 'string', \"FIRE_NAME\": 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FPA_ID</th>\n",
       "      <th>SOURCE_SYSTEM_TYPE</th>\n",
       "      <th>SOURCE_SYSTEM</th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "      <th>FIRE_DAYS</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>DISCOVERY_MONTH_CONVERTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>155</td>\n",
       "      <td>FS-1419238</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.08</td>\n",
       "      <td>69.98</td>\n",
       "      <td>71.06</td>\n",
       "      <td>1</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>FS-1419278</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.04</td>\n",
       "      <td>62.06</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>FS-1419291</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>FS-1419292</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>FS-1419293</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64.94</td>\n",
       "      <td>68.00</td>\n",
       "      <td>71.96</td>\n",
       "      <td>71.96</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15481</td>\n",
       "      <td>15481</td>\n",
       "      <td>1847545</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847545</td>\n",
       "      <td>300274025</td>\n",
       "      <td>SFO-2015IDIDL6102015028</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.58</td>\n",
       "      <td>60.80</td>\n",
       "      <td>59.90</td>\n",
       "      <td>60.62</td>\n",
       "      <td>2</td>\n",
       "      <td>Boise</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15483</td>\n",
       "      <td>15483</td>\n",
       "      <td>1847684</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847684</td>\n",
       "      <td>300274204</td>\n",
       "      <td>SFO-2015IDIDL2102015023</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.28</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15484</td>\n",
       "      <td>15484</td>\n",
       "      <td>1847710</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847710</td>\n",
       "      <td>300274236</td>\n",
       "      <td>SFO-2015IDIDL2102015021</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15485</td>\n",
       "      <td>15485</td>\n",
       "      <td>1847762</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847762</td>\n",
       "      <td>300274306</td>\n",
       "      <td>SFO-2015IDIDL9802015030</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.28</td>\n",
       "      <td>58.46</td>\n",
       "      <td>61.52</td>\n",
       "      <td>63.68</td>\n",
       "      <td>1</td>\n",
       "      <td>Valley</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15486</td>\n",
       "      <td>15486</td>\n",
       "      <td>1848009</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1848009</td>\n",
       "      <td>300274600</td>\n",
       "      <td>SFO-2015IDIDL2102015024</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.18</td>\n",
       "      <td>51.80</td>\n",
       "      <td>53.06</td>\n",
       "      <td>55.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14902 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  OBJECTID  Shape  Join_Count  TARGET_FID     FOD_ID  \\\n",
       "0               0       152  Point           1         152        155   \n",
       "1               1       169  Point           1         169        172   \n",
       "2               2       173  Point           1         173        176   \n",
       "3               3       174  Point           1         174        177   \n",
       "4               4       175  Point           1         175        178   \n",
       "...           ...       ...    ...         ...         ...        ...   \n",
       "15481       15481   1847545  Point           1     1847545  300274025   \n",
       "15483       15483   1847684  Point           1     1847684  300274204   \n",
       "15484       15484   1847710  Point           1     1847710  300274236   \n",
       "15485       15485   1847762  Point           1     1847762  300274306   \n",
       "15486       15486   1848009  Point           1     1848009  300274600   \n",
       "\n",
       "                        FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
       "0                   FS-1419238                FED   FS-FIRESTAT   \n",
       "1                   FS-1419278                FED   FS-FIRESTAT   \n",
       "2                   FS-1419291                FED   FS-FIRESTAT   \n",
       "3                   FS-1419292                FED   FS-FIRESTAT   \n",
       "4                   FS-1419293                FED   FS-FIRESTAT   \n",
       "...                        ...                ...           ...   \n",
       "15481  SFO-2015IDIDL6102015028             NONFED       ST-NASF   \n",
       "15483  SFO-2015IDIDL2102015023             NONFED       ST-NASF   \n",
       "15484  SFO-2015IDIDL2102015021             NONFED       ST-NASF   \n",
       "15485  SFO-2015IDIDL9802015030             NONFED       ST-NASF   \n",
       "15486  SFO-2015IDIDL2102015024             NONFED       ST-NASF   \n",
       "\n",
       "      NWCG_REPORTING_AGENCY  ... DAY_PRCP_2 DAY_PRCP_3 DAY_PRCP_4  \\\n",
       "0                        FS  ...        0.0        0.0        0.0   \n",
       "1                        FS  ...        0.0        0.0        0.0   \n",
       "2                        FS  ...        0.0        0.0        0.0   \n",
       "3                        FS  ...        0.0        0.0        0.0   \n",
       "4                        FS  ...        0.0        0.0        0.8   \n",
       "...                     ...  ...        ...        ...        ...   \n",
       "15481                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15483                ST/C&L  ...        0.0        0.9        0.0   \n",
       "15484                ST/C&L  ...        0.9        0.0        0.0   \n",
       "15485                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15486                ST/C&L  ...        0.0        0.0        0.0   \n",
       "\n",
       "      DAY_AVG_TEMP_1  DAY_AVG_TEMP_2 DAY_AVG_TEMP_3 DAY_AVG_TEMP_4 FIRE_DAYS  \\\n",
       "0              77.00           69.08          69.98          71.06         1   \n",
       "1              64.04           62.06          69.08          66.92         1   \n",
       "2              69.08           66.92          64.04          64.94         1   \n",
       "3              69.08           66.92          64.04          64.94         1   \n",
       "4              64.94           68.00          71.96          71.96         1   \n",
       "...              ...             ...            ...            ...       ...   \n",
       "15481          64.58           60.80          59.90          60.62         2   \n",
       "15483          58.28           60.08          66.74          59.36         2   \n",
       "15484          60.08           66.74          59.36          50.00         1   \n",
       "15485          67.28           58.46          61.52          63.68         1   \n",
       "15486          50.18           51.80          53.06          55.40         2   \n",
       "\n",
       "      COUNTY_NAME DISCOVERY_MONTH_CONVERTED  \n",
       "0         Fremont                         7  \n",
       "1         Bannock                         7  \n",
       "2         Bannock                         7  \n",
       "3         Bannock                         7  \n",
       "4         Bannock                         7  \n",
       "...           ...                       ...  \n",
       "15481       Boise                        10  \n",
       "15483    Boundary                        10  \n",
       "15484    Boundary                        10  \n",
       "15485      Valley                        10  \n",
       "15486    Boundary                        10  \n",
       "\n",
       "[14902 rows x 119 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT DATE TO DATETIME FORMAT\n",
    "idaho_Fire_Weather_Drought_df['DISCOVERY_DATE_CONVERTED'] = pd.to_datetime(idaho_Fire_Weather_Drought_df['DISCOVERY_DATE_CONVERTED'])\n",
    "idaho_Fire_Weather_Drought_df['CONT_DATE_CONVERTED'] = pd.to_datetime(idaho_Fire_Weather_Drought_df['CONT_DATE_CONVERTED'])\n",
    "\n",
    "# CREATE COLUMNS WE NEED\n",
    "idaho_Fire_Weather_Drought_df['FIRE_DAYS'] = (((idaho_Fire_Weather_Drought_df['CONT_DOY']) + 1) - idaho_Fire_Weather_Drought_df['DISCOVERY_DOY'])\n",
    "idaho_Fire_Weather_Drought_df['COUNTY_NAME'] = (idaho_Fire_Weather_Drought_df['FIPS_NAME'])\n",
    "# Create month column\n",
    "idaho_Fire_Weather_Drought_df['DISCOVERY_MONTH_CONVERTED']=idaho_Fire_Weather_Drought_df['DISCOVERY_DATE_CONVERTED'].apply(lambda x: int(x.strftime('%m')))\n",
    "\n",
    "# FILTER ROWS FOR FIRES IN COUNTIES OUTSIDE IDAHO\n",
    "idaho_Fire_Weather_Drought_df = idaho_Fire_Weather_Drought_df[idaho_Fire_Weather_Drought_df['NAME'].isin(idahoCounties)]\n",
    "\n",
    "# View the Data in the Dataframe\n",
    "# print(idaho_Fire_Weather_df.keys())\n",
    "idaho_Fire_Weather_Drought_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OUTPUT THE AND UPDATED CSV FILE\n",
    "\n",
    "# output_path = os.path.join(\"..\", \"Data\", \"fires_Idaho_2000_2015_drought_weather_Plus.csv\")\n",
    "# with open(output_path, 'w') as csvfile:\n",
    "#         idaho_Fire_Weather_Drought_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEAN UP AND REMOVE UNWANTED COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get dummy variables for nominal property column\n",
    "# # idaho_Fire_Weather_df = pd.get_dummies(idaho_Fire_Weather_df, columns=[\"FIRE_SIZE_CLASS\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"CITY\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"NAME\"])\n",
    "\n",
    "# # FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# # # replace values in each column according to the dictionaries above\n",
    "# # clean_fires_Idaho_2000_2015_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "# idaho_Fire_Weather_Drought_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables for nominal property column\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "# idaho_Fire_Weather_Drought_df = pd.get_dummies(idaho_Fire_Weather_Drought_df, columns=[\"NAME\"])\n",
    "\n",
    "# FIRE_SIZE_CLASS_NOS  = {'A' : 1, 'B' : 2, 'C' : 3, 'D' : 4, 'E' : 5, 'F' : 6, 'G' : 7}\n",
    "\n",
    "# # replace values in each column according to the dictionaries above\n",
    "# idaho_Fire_Weather_Drought_df.replace({'FIRE_SIZE_CLASS': FIRE_SIZE_CLASS_NOS}, inplace=True) \n",
    "                    \n",
    "# idaho_Fire_Weather_Drought_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and associate cities using the lat lng coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FPA_ID</th>\n",
       "      <th>SOURCE_SYSTEM_TYPE</th>\n",
       "      <th>SOURCE_SYSTEM</th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>...</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "      <th>FIRE_DAYS</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>DISCOVERY_MONTH_CONVERTED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>155</td>\n",
       "      <td>FS-1419238</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>69.08</td>\n",
       "      <td>69.98</td>\n",
       "      <td>71.06</td>\n",
       "      <td>1</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>FS-1419278</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.04</td>\n",
       "      <td>62.06</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>FS-1419291</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>FS-1419292</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.08</td>\n",
       "      <td>66.92</td>\n",
       "      <td>64.04</td>\n",
       "      <td>64.94</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>FS-1419293</td>\n",
       "      <td>FED</td>\n",
       "      <td>FS-FIRESTAT</td>\n",
       "      <td>FS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>64.94</td>\n",
       "      <td>68.00</td>\n",
       "      <td>71.96</td>\n",
       "      <td>71.96</td>\n",
       "      <td>1</td>\n",
       "      <td>Bannock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15481</td>\n",
       "      <td>15481</td>\n",
       "      <td>1847545</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847545</td>\n",
       "      <td>300274025</td>\n",
       "      <td>SFO-2015IDIDL6102015028</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.58</td>\n",
       "      <td>60.80</td>\n",
       "      <td>59.90</td>\n",
       "      <td>60.62</td>\n",
       "      <td>2</td>\n",
       "      <td>Boise</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15483</td>\n",
       "      <td>15483</td>\n",
       "      <td>1847684</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847684</td>\n",
       "      <td>300274204</td>\n",
       "      <td>SFO-2015IDIDL2102015023</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.28</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15484</td>\n",
       "      <td>15484</td>\n",
       "      <td>1847710</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847710</td>\n",
       "      <td>300274236</td>\n",
       "      <td>SFO-2015IDIDL2102015021</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.08</td>\n",
       "      <td>66.74</td>\n",
       "      <td>59.36</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15485</td>\n",
       "      <td>15485</td>\n",
       "      <td>1847762</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1847762</td>\n",
       "      <td>300274306</td>\n",
       "      <td>SFO-2015IDIDL9802015030</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.28</td>\n",
       "      <td>58.46</td>\n",
       "      <td>61.52</td>\n",
       "      <td>63.68</td>\n",
       "      <td>1</td>\n",
       "      <td>Valley</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15486</td>\n",
       "      <td>15486</td>\n",
       "      <td>1848009</td>\n",
       "      <td>Point</td>\n",
       "      <td>1</td>\n",
       "      <td>1848009</td>\n",
       "      <td>300274600</td>\n",
       "      <td>SFO-2015IDIDL2102015024</td>\n",
       "      <td>NONFED</td>\n",
       "      <td>ST-NASF</td>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.18</td>\n",
       "      <td>51.80</td>\n",
       "      <td>53.06</td>\n",
       "      <td>55.40</td>\n",
       "      <td>2</td>\n",
       "      <td>Boundary</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14902 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  OBJECTID  Shape  Join_Count  TARGET_FID     FOD_ID  \\\n",
       "0               0       152  Point           1         152        155   \n",
       "1               1       169  Point           1         169        172   \n",
       "2               2       173  Point           1         173        176   \n",
       "3               3       174  Point           1         174        177   \n",
       "4               4       175  Point           1         175        178   \n",
       "...           ...       ...    ...         ...         ...        ...   \n",
       "15481       15481   1847545  Point           1     1847545  300274025   \n",
       "15483       15483   1847684  Point           1     1847684  300274204   \n",
       "15484       15484   1847710  Point           1     1847710  300274236   \n",
       "15485       15485   1847762  Point           1     1847762  300274306   \n",
       "15486       15486   1848009  Point           1     1848009  300274600   \n",
       "\n",
       "                        FPA_ID SOURCE_SYSTEM_TYPE SOURCE_SYSTEM  \\\n",
       "0                   FS-1419238                FED   FS-FIRESTAT   \n",
       "1                   FS-1419278                FED   FS-FIRESTAT   \n",
       "2                   FS-1419291                FED   FS-FIRESTAT   \n",
       "3                   FS-1419292                FED   FS-FIRESTAT   \n",
       "4                   FS-1419293                FED   FS-FIRESTAT   \n",
       "...                        ...                ...           ...   \n",
       "15481  SFO-2015IDIDL6102015028             NONFED       ST-NASF   \n",
       "15483  SFO-2015IDIDL2102015023             NONFED       ST-NASF   \n",
       "15484  SFO-2015IDIDL2102015021             NONFED       ST-NASF   \n",
       "15485  SFO-2015IDIDL9802015030             NONFED       ST-NASF   \n",
       "15486  SFO-2015IDIDL2102015024             NONFED       ST-NASF   \n",
       "\n",
       "      NWCG_REPORTING_AGENCY  ... DAY_PRCP_2 DAY_PRCP_3 DAY_PRCP_4  \\\n",
       "0                        FS  ...        0.0        0.0        0.0   \n",
       "1                        FS  ...        0.0        0.0        0.0   \n",
       "2                        FS  ...        0.0        0.0        0.0   \n",
       "3                        FS  ...        0.0        0.0        0.0   \n",
       "4                        FS  ...        0.0        0.0        0.8   \n",
       "...                     ...  ...        ...        ...        ...   \n",
       "15481                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15483                ST/C&L  ...        0.0        0.9        0.0   \n",
       "15484                ST/C&L  ...        0.9        0.0        0.0   \n",
       "15485                ST/C&L  ...        0.0        0.0        0.0   \n",
       "15486                ST/C&L  ...        0.0        0.0        0.0   \n",
       "\n",
       "      DAY_AVG_TEMP_1  DAY_AVG_TEMP_2 DAY_AVG_TEMP_3 DAY_AVG_TEMP_4 FIRE_DAYS  \\\n",
       "0              77.00           69.08          69.98          71.06         1   \n",
       "1              64.04           62.06          69.08          66.92         1   \n",
       "2              69.08           66.92          64.04          64.94         1   \n",
       "3              69.08           66.92          64.04          64.94         1   \n",
       "4              64.94           68.00          71.96          71.96         1   \n",
       "...              ...             ...            ...            ...       ...   \n",
       "15481          64.58           60.80          59.90          60.62         2   \n",
       "15483          58.28           60.08          66.74          59.36         2   \n",
       "15484          60.08           66.74          59.36          50.00         1   \n",
       "15485          67.28           58.46          61.52          63.68         1   \n",
       "15486          50.18           51.80          53.06          55.40         2   \n",
       "\n",
       "      COUNTY_NAME DISCOVERY_MONTH_CONVERTED  \n",
       "0         Fremont                         7  \n",
       "1         Bannock                         7  \n",
       "2         Bannock                         7  \n",
       "3         Bannock                         7  \n",
       "4         Bannock                         7  \n",
       "...           ...                       ...  \n",
       "15481       Boise                        10  \n",
       "15483    Boundary                        10  \n",
       "15484    Boundary                        10  \n",
       "15485      Valley                        10  \n",
       "15486    Boundary                        10  \n",
       "\n",
       "[14902 rows x 119 columns]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idaho_Fire_Weather_Drought_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Avg for values\n",
    "Day1_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_1'].mean()\n",
    "Day2_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_2'].mean()\n",
    "Day3_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_3'].mean()\n",
    "Day4_prcp = idaho_Fire_Weather_Drought_df['DAY_PRCP_4'].mean()\n",
    "Day1_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'].mean()\n",
    "Day2_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'].mean()\n",
    "Day3_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'].mean()\n",
    "Day4_temp = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'].mean()\n",
    "\n",
    "# Use Avg values to fill any null values\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_1'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_1'].fillna(Day1_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_2'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_2'].fillna(Day2_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_3'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_3'].fillna(Day3_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_PRCP_4'] = idaho_Fire_Weather_Drought_df['DAY_PRCP_4'].fillna(Day4_prcp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_1'].fillna(Day1_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_2'].fillna(Day2_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_3'].fillna(Day3_temp)\n",
    "idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'] = idaho_Fire_Weather_Drought_df['DAY_AVG_TEMP_4'].fillna(Day4_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>DISCOVERY_MONTH_CONVERTED</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>AVE_SIZE12</th>\n",
       "      <th>CROP_ACR12</th>\n",
       "      <th>None</th>\n",
       "      <th>D0</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>DAY_PRCP_1</th>\n",
       "      <th>DAY_PRCP_2</th>\n",
       "      <th>DAY_PRCP_3</th>\n",
       "      <th>DAY_PRCP_4</th>\n",
       "      <th>DAY_AVG_TEMP_1</th>\n",
       "      <th>DAY_AVG_TEMP_2</th>\n",
       "      <th>DAY_AVG_TEMP_3</th>\n",
       "      <th>DAY_AVG_TEMP_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>FIRE_SIZE_CLASS</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041246</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>0.163815</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>0.061832</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>-0.003069</td>\n",
       "      <td>-0.028075</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>-0.075665</td>\n",
       "      <td>-0.080226</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.043749</td>\n",
       "      <td>0.078619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DISCOVERY_MONTH_CONVERTED</td>\n",
       "      <td>-0.041246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.052756</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.114252</td>\n",
       "      <td>0.114252</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>0.155414</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>-0.031009</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>-0.038563</td>\n",
       "      <td>-0.065824</td>\n",
       "      <td>-0.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>FIRE_YEAR</td>\n",
       "      <td>-0.031566</td>\n",
       "      <td>-0.052756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.139417</td>\n",
       "      <td>-0.188559</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>-0.123206</td>\n",
       "      <td>-0.167924</td>\n",
       "      <td>-0.211975</td>\n",
       "      <td>-0.179604</td>\n",
       "      <td>-0.116881</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>0.036142</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0.113086</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.109455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVE_SIZE12</td>\n",
       "      <td>0.163815</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>-0.139417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577044</td>\n",
       "      <td>-0.132600</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.098384</td>\n",
       "      <td>0.094162</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.019457</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.014886</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.046041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CROP_ACR12</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.188559</td>\n",
       "      <td>0.577044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131695</td>\n",
       "      <td>0.131695</td>\n",
       "      <td>0.139625</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>0.136077</td>\n",
       "      <td>0.102025</td>\n",
       "      <td>-0.003605</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>-0.052992</td>\n",
       "      <td>-0.059147</td>\n",
       "      <td>-0.046783</td>\n",
       "      <td>-0.023749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>None</td>\n",
       "      <td>-0.061832</td>\n",
       "      <td>-0.114252</td>\n",
       "      <td>0.123206</td>\n",
       "      <td>-0.132600</td>\n",
       "      <td>-0.131695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.722797</td>\n",
       "      <td>-0.471042</td>\n",
       "      <td>-0.246894</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.036124</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>0.031823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D0</td>\n",
       "      <td>0.061832</td>\n",
       "      <td>0.114252</td>\n",
       "      <td>-0.123206</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.131695</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>0.471042</td>\n",
       "      <td>0.246894</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>-0.007870</td>\n",
       "      <td>-0.021974</td>\n",
       "      <td>-0.036124</td>\n",
       "      <td>-0.032575</td>\n",
       "      <td>-0.031823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D1</td>\n",
       "      <td>0.085644</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>-0.167924</td>\n",
       "      <td>0.141231</td>\n",
       "      <td>0.139625</td>\n",
       "      <td>-0.722797</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>0.371050</td>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>-0.032908</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>-0.030196</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.011003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D2</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>-0.211975</td>\n",
       "      <td>0.098384</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>-0.471042</td>\n",
       "      <td>0.471042</td>\n",
       "      <td>0.704019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585870</td>\n",
       "      <td>0.216305</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>-0.021172</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>-0.087505</td>\n",
       "      <td>-0.090341</td>\n",
       "      <td>-0.086722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D3</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.155414</td>\n",
       "      <td>-0.179604</td>\n",
       "      <td>0.094162</td>\n",
       "      <td>0.136077</td>\n",
       "      <td>-0.246894</td>\n",
       "      <td>0.246894</td>\n",
       "      <td>0.371050</td>\n",
       "      <td>0.585870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440823</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.012112</td>\n",
       "      <td>-0.020128</td>\n",
       "      <td>-0.016641</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.120978</td>\n",
       "      <td>-0.126993</td>\n",
       "      <td>-0.114686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>D4</td>\n",
       "      <td>-0.003069</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>-0.116881</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>0.102025</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>0.088997</td>\n",
       "      <td>0.134097</td>\n",
       "      <td>0.216305</td>\n",
       "      <td>0.440823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.056946</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>-0.077982</td>\n",
       "      <td>-0.073660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_1</td>\n",
       "      <td>-0.028075</td>\n",
       "      <td>-0.031009</td>\n",
       "      <td>0.034387</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.003605</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>-0.007993</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.024966</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136445</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>-0.117898</td>\n",
       "      <td>-0.153304</td>\n",
       "      <td>-0.124828</td>\n",
       "      <td>-0.094944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_2</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>-0.019457</td>\n",
       "      <td>-0.024724</td>\n",
       "      <td>-0.011623</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>-0.012112</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.136445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127114</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>-0.022026</td>\n",
       "      <td>-0.098343</td>\n",
       "      <td>-0.132457</td>\n",
       "      <td>-0.104374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_3</td>\n",
       "      <td>-0.075665</td>\n",
       "      <td>0.027465</td>\n",
       "      <td>0.028215</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>-0.008244</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>-0.006602</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>-0.020128</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.127114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092419</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>-0.014444</td>\n",
       "      <td>-0.076734</td>\n",
       "      <td>-0.138960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_PRCP_4</td>\n",
       "      <td>-0.080226</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.036142</td>\n",
       "      <td>-0.014886</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>-0.007870</td>\n",
       "      <td>-0.032908</td>\n",
       "      <td>-0.021172</td>\n",
       "      <td>-0.016641</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0.092419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>-0.080317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_1</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>-0.014133</td>\n",
       "      <td>0.117933</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>-0.052992</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>-0.021974</td>\n",
       "      <td>-0.017714</td>\n",
       "      <td>-0.074823</td>\n",
       "      <td>-0.115261</td>\n",
       "      <td>-0.056946</td>\n",
       "      <td>-0.117898</td>\n",
       "      <td>-0.022026</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.015917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877481</td>\n",
       "      <td>0.769969</td>\n",
       "      <td>0.695622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_2</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>-0.038563</td>\n",
       "      <td>0.113086</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>-0.059147</td>\n",
       "      <td>0.036124</td>\n",
       "      <td>-0.036124</td>\n",
       "      <td>-0.030196</td>\n",
       "      <td>-0.087505</td>\n",
       "      <td>-0.120978</td>\n",
       "      <td>-0.078471</td>\n",
       "      <td>-0.153304</td>\n",
       "      <td>-0.098343</td>\n",
       "      <td>-0.014444</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.877481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869587</td>\n",
       "      <td>0.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_3</td>\n",
       "      <td>0.043749</td>\n",
       "      <td>-0.065824</td>\n",
       "      <td>0.105979</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>-0.046783</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>-0.032575</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.090341</td>\n",
       "      <td>-0.126993</td>\n",
       "      <td>-0.077982</td>\n",
       "      <td>-0.124828</td>\n",
       "      <td>-0.132457</td>\n",
       "      <td>-0.076734</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.769969</td>\n",
       "      <td>0.869587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DAY_AVG_TEMP_4</td>\n",
       "      <td>0.078619</td>\n",
       "      <td>-0.117800</td>\n",
       "      <td>0.109455</td>\n",
       "      <td>0.046041</td>\n",
       "      <td>-0.023749</td>\n",
       "      <td>0.031823</td>\n",
       "      <td>-0.031823</td>\n",
       "      <td>-0.011003</td>\n",
       "      <td>-0.086722</td>\n",
       "      <td>-0.114686</td>\n",
       "      <td>-0.073660</td>\n",
       "      <td>-0.094944</td>\n",
       "      <td>-0.104374</td>\n",
       "      <td>-0.138960</td>\n",
       "      <td>-0.080317</td>\n",
       "      <td>0.695622</td>\n",
       "      <td>0.753000</td>\n",
       "      <td>0.849300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FIRE_SIZE_CLASS  DISCOVERY_MONTH_CONVERTED  \\\n",
       "FIRE_SIZE_CLASS                   1.000000                  -0.041246   \n",
       "DISCOVERY_MONTH_CONVERTED        -0.041246                   1.000000   \n",
       "FIRE_YEAR                        -0.031566                  -0.052756   \n",
       "AVE_SIZE12                        0.163815                   0.029308   \n",
       "CROP_ACR12                        0.153558                   0.005049   \n",
       "None                             -0.061832                  -0.114252   \n",
       "D0                                0.061832                   0.114252   \n",
       "D1                                0.085644                   0.093930   \n",
       "D2                                0.033487                   0.139979   \n",
       "D3                                0.004514                   0.155414   \n",
       "D4                               -0.003069                   0.046775   \n",
       "DAY_PRCP_1                       -0.028075                  -0.031009   \n",
       "DAY_PRCP_2                       -0.055122                   0.010065   \n",
       "DAY_PRCP_3                       -0.075665                   0.027465   \n",
       "DAY_PRCP_4                       -0.080226                   0.009608   \n",
       "DAY_AVG_TEMP_1                    0.011915                  -0.014133   \n",
       "DAY_AVG_TEMP_2                    0.009872                  -0.038563   \n",
       "DAY_AVG_TEMP_3                    0.043749                  -0.065824   \n",
       "DAY_AVG_TEMP_4                    0.078619                  -0.117800   \n",
       "\n",
       "                           FIRE_YEAR  AVE_SIZE12  CROP_ACR12      None  \\\n",
       "FIRE_SIZE_CLASS            -0.031566    0.163815    0.153558 -0.061832   \n",
       "DISCOVERY_MONTH_CONVERTED  -0.052756    0.029308    0.005049 -0.114252   \n",
       "FIRE_YEAR                   1.000000   -0.139417   -0.188559  0.123206   \n",
       "AVE_SIZE12                 -0.139417    1.000000    0.577044 -0.132600   \n",
       "CROP_ACR12                 -0.188559    0.577044    1.000000 -0.131695   \n",
       "None                        0.123206   -0.132600   -0.131695  1.000000   \n",
       "D0                         -0.123206    0.132600    0.131695 -1.000000   \n",
       "D1                         -0.167924    0.141231    0.139625 -0.722797   \n",
       "D2                         -0.211975    0.098384    0.109089 -0.471042   \n",
       "D3                         -0.179604    0.094162    0.136077 -0.246894   \n",
       "D4                         -0.116881    0.044858    0.102025 -0.088997   \n",
       "DAY_PRCP_1                  0.034387   -0.005764   -0.003605  0.007993   \n",
       "DAY_PRCP_2                  0.048676   -0.019457   -0.024724 -0.011623   \n",
       "DAY_PRCP_3                  0.028215   -0.006819   -0.031351 -0.008244   \n",
       "DAY_PRCP_4                  0.036142   -0.014886   -0.012383  0.007870   \n",
       "DAY_AVG_TEMP_1              0.117933    0.021817   -0.052992  0.021974   \n",
       "DAY_AVG_TEMP_2              0.113086    0.030689   -0.059147  0.036124   \n",
       "DAY_AVG_TEMP_3              0.105979    0.047380   -0.046783  0.032575   \n",
       "DAY_AVG_TEMP_4              0.109455    0.046041   -0.023749  0.031823   \n",
       "\n",
       "                                 D0        D1        D2        D3        D4  \\\n",
       "FIRE_SIZE_CLASS            0.061832  0.085644  0.033487  0.004514 -0.003069   \n",
       "DISCOVERY_MONTH_CONVERTED  0.114252  0.093930  0.139979  0.155414  0.046775   \n",
       "FIRE_YEAR                 -0.123206 -0.167924 -0.211975 -0.179604 -0.116881   \n",
       "AVE_SIZE12                 0.132600  0.141231  0.098384  0.094162  0.044858   \n",
       "CROP_ACR12                 0.131695  0.139625  0.109089  0.136077  0.102025   \n",
       "None                      -1.000000 -0.722797 -0.471042 -0.246894 -0.088997   \n",
       "D0                         1.000000  0.722797  0.471042  0.246894  0.088997   \n",
       "D1                         0.722797  1.000000  0.704019  0.371050  0.134097   \n",
       "D2                         0.471042  0.704019  1.000000  0.585870  0.216305   \n",
       "D3                         0.246894  0.371050  0.585870  1.000000  0.440823   \n",
       "D4                         0.088997  0.134097  0.216305  0.440823  1.000000   \n",
       "DAY_PRCP_1                -0.007993  0.006476  0.024966 -0.002278  0.001515   \n",
       "DAY_PRCP_2                 0.011623  0.009556  0.013385 -0.012112  0.001186   \n",
       "DAY_PRCP_3                 0.008244 -0.006602  0.009985 -0.020128  0.001011   \n",
       "DAY_PRCP_4                -0.007870 -0.032908 -0.021172 -0.016641 -0.002063   \n",
       "DAY_AVG_TEMP_1            -0.021974 -0.017714 -0.074823 -0.115261 -0.056946   \n",
       "DAY_AVG_TEMP_2            -0.036124 -0.030196 -0.087505 -0.120978 -0.078471   \n",
       "DAY_AVG_TEMP_3            -0.032575 -0.023075 -0.090341 -0.126993 -0.077982   \n",
       "DAY_AVG_TEMP_4            -0.031823 -0.011003 -0.086722 -0.114686 -0.073660   \n",
       "\n",
       "                           DAY_PRCP_1  DAY_PRCP_2  DAY_PRCP_3  DAY_PRCP_4  \\\n",
       "FIRE_SIZE_CLASS             -0.028075   -0.055122   -0.075665   -0.080226   \n",
       "DISCOVERY_MONTH_CONVERTED   -0.031009    0.010065    0.027465    0.009608   \n",
       "FIRE_YEAR                    0.034387    0.048676    0.028215    0.036142   \n",
       "AVE_SIZE12                  -0.005764   -0.019457   -0.006819   -0.014886   \n",
       "CROP_ACR12                  -0.003605   -0.024724   -0.031351   -0.012383   \n",
       "None                         0.007993   -0.011623   -0.008244    0.007870   \n",
       "D0                          -0.007993    0.011623    0.008244   -0.007870   \n",
       "D1                           0.006476    0.009556   -0.006602   -0.032908   \n",
       "D2                           0.024966    0.013385    0.009985   -0.021172   \n",
       "D3                          -0.002278   -0.012112   -0.020128   -0.016641   \n",
       "D4                           0.001515    0.001186    0.001011   -0.002063   \n",
       "DAY_PRCP_1                   1.000000    0.136445    0.051241    0.008809   \n",
       "DAY_PRCP_2                   0.136445    1.000000    0.127114    0.020576   \n",
       "DAY_PRCP_3                   0.051241    0.127114    1.000000    0.092419   \n",
       "DAY_PRCP_4                   0.008809    0.020576    0.092419    1.000000   \n",
       "DAY_AVG_TEMP_1              -0.117898   -0.022026    0.005253    0.015917   \n",
       "DAY_AVG_TEMP_2              -0.153304   -0.098343   -0.014444    0.021574   \n",
       "DAY_AVG_TEMP_3              -0.124828   -0.132457   -0.076734   -0.003134   \n",
       "DAY_AVG_TEMP_4              -0.094944   -0.104374   -0.138960   -0.080317   \n",
       "\n",
       "                           DAY_AVG_TEMP_1  DAY_AVG_TEMP_2  DAY_AVG_TEMP_3  \\\n",
       "FIRE_SIZE_CLASS                  0.011915        0.009872        0.043749   \n",
       "DISCOVERY_MONTH_CONVERTED       -0.014133       -0.038563       -0.065824   \n",
       "FIRE_YEAR                        0.117933        0.113086        0.105979   \n",
       "AVE_SIZE12                       0.021817        0.030689        0.047380   \n",
       "CROP_ACR12                      -0.052992       -0.059147       -0.046783   \n",
       "None                             0.021974        0.036124        0.032575   \n",
       "D0                              -0.021974       -0.036124       -0.032575   \n",
       "D1                              -0.017714       -0.030196       -0.023075   \n",
       "D2                              -0.074823       -0.087505       -0.090341   \n",
       "D3                              -0.115261       -0.120978       -0.126993   \n",
       "D4                              -0.056946       -0.078471       -0.077982   \n",
       "DAY_PRCP_1                      -0.117898       -0.153304       -0.124828   \n",
       "DAY_PRCP_2                      -0.022026       -0.098343       -0.132457   \n",
       "DAY_PRCP_3                       0.005253       -0.014444       -0.076734   \n",
       "DAY_PRCP_4                       0.015917        0.021574       -0.003134   \n",
       "DAY_AVG_TEMP_1                   1.000000        0.877481        0.769969   \n",
       "DAY_AVG_TEMP_2                   0.877481        1.000000        0.869587   \n",
       "DAY_AVG_TEMP_3                   0.769969        0.869587        1.000000   \n",
       "DAY_AVG_TEMP_4                   0.695622        0.753000        0.849300   \n",
       "\n",
       "                           DAY_AVG_TEMP_4  \n",
       "FIRE_SIZE_CLASS                  0.078619  \n",
       "DISCOVERY_MONTH_CONVERTED       -0.117800  \n",
       "FIRE_YEAR                        0.109455  \n",
       "AVE_SIZE12                       0.046041  \n",
       "CROP_ACR12                      -0.023749  \n",
       "None                             0.031823  \n",
       "D0                              -0.031823  \n",
       "D1                              -0.011003  \n",
       "D2                              -0.086722  \n",
       "D3                              -0.114686  \n",
       "D4                              -0.073660  \n",
       "DAY_PRCP_1                      -0.094944  \n",
       "DAY_PRCP_2                      -0.104374  \n",
       "DAY_PRCP_3                      -0.138960  \n",
       "DAY_PRCP_4                      -0.080317  \n",
       "DAY_AVG_TEMP_1                   0.695622  \n",
       "DAY_AVG_TEMP_2                   0.753000  \n",
       "DAY_AVG_TEMP_3                   0.849300  \n",
       "DAY_AVG_TEMP_4                   1.000000  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corr_df = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'DISCOVERY_MONTH_CONVERTED', 'DISCOVERY_DATE_CONVERTED', 'FIRE_YEAR', 'STAT_CAUSE_DESCR', 'AVE_SIZE12', 'CROP_ACR12', 'NAME', \n",
    "                                         'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', \n",
    "                                         'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# Corr_df = idaho_Fire_Weather_Drought_df[['NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "#                                    'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "    \n",
    "Corr_df['FIRE_SIZE_CLASS']= Corr_df['FIRE_SIZE_CLASS'].astype('category').cat.codes\n",
    "\n",
    "Corr_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING A NEURAL NETWORK MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # INVESTIGATING INPUTS\n",
    "# # Possible X columns\n",
    "# # [['DISCOVERY_MONTH_CONVERTED', 'FIRE_SIZE_CLASS', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', \n",
    "# #   'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# New_df = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_DATE_CONVERTED', 'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', \n",
    "#                                    'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', 'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "# New_df['FIRE_SIZE_CLASS']= New_df['FIRE_SIZE_CLASS'].astype('category').cat.codes\n",
    "# # New_df['AVE_FAM_SZ']= New_df['AVE_FAM_SZ'].apply(lambda x: x//1)\n",
    "\n",
    "# # Drop Y column\n",
    "# New_df = New_df.drop(['FIRE_SIZE_CLASS'], axis=1)\n",
    "# New_df = New_df.drop(['STAT_CAUSE_DESCR'], axis=1)\n",
    "\n",
    "# # Run PCA \n",
    "# from sklearn.decomposition import PCA\n",
    "# n_components=40\n",
    "# pca = PCA(n_components=n_components)\n",
    "\n",
    "# # Create multiple columns for County \"NAME\"\n",
    "# New_df = pd.get_dummies(New_df, columns=['NAME'])\n",
    "# # New_df = pd.get_dummies(New_df, columns=['STAT_CAUSE_DESCR'])\n",
    "\n",
    "# NoOfCols = n_components\n",
    "\n",
    "# X_Array = New_df.to_numpy()\n",
    "# pca.fit(X_Array)\n",
    "# # print(pca.singular_values_)\n",
    "# x = pca.transform(X_Array)\n",
    "# x\n",
    "# # print(x.shape)\n",
    "# # type(x)\n",
    "# # x\n",
    "\n",
    "# NoOfCols = n_components\n",
    "# NoOfRuns = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X Input is (14902, 58)\n",
      "Type of X input is <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  7., 100., 100., ...,   0.,   0.,   0.],\n",
       "       [  7., 100., 100., ...,   0.,   0.,   0.],\n",
       "       [  7., 100., 100., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [ 10., 100., 100., ...,   0.,   0.,   0.],\n",
       "       [ 10., 100., 100., ...,   0.,   1.,   0.],\n",
       "       [ 10., 100., 100., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE X VALUES\n",
    "# X by Keep\n",
    "X = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_MONTH_CONVERTED', 'DISCOVERY_DATE_CONVERTED', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', \n",
    "                                   'NAME', 'None', 'D0','D1', 'D2', 'D3', 'D4', 'DAY_PRCP_1', 'DAY_PRCP_2', 'DAY_PRCP_3', 'DAY_PRCP_4', 'DAY_AVG_TEMP_1', 'DAY_AVG_TEMP_2', \n",
    "                                   'DAY_AVG_TEMP_3', 'DAY_AVG_TEMP_4']]\n",
    "\n",
    "# ADD COLUMNS FIRE_SIZE_FLAG COLUMN AND IDAHO COLUMNS THAT HAVE NO FIRE INFO (FOR COMPLETENESS)\n",
    "X['NAME_Jerome'] = 0\n",
    "X['NAME_Kootenai'] = 0\n",
    "\n",
    "# DROP UNWANTED COLUMNS\n",
    "X = X.drop(['FIRE_SIZE_CLASS', 'STAT_CAUSE_DESCR', 'DISCOVERY_DATE_CONVERTED', 'AVE_FAM_SZ', 'NO_FARMS12', 'AVE_SIZE12', 'CROP_ACR12', 'None'], axis=1)\n",
    "# X = pd.get_dummies(X, columns=['STAT_CAUSE_DESCR'])\n",
    "X = pd.get_dummies(X, columns=['NAME'])\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# # TO OUTPUT CSVs FILTERED BY FIRE SIZE\n",
    "# # Filter \n",
    "# class1_df = X.loc[(X['FIRE_SIZE_CLASS']== 'A')]\n",
    "# class1_df\n",
    "\n",
    "# # # OUTPUT THE AND UPDATED CSV FILE\n",
    "# Class1_firesOutput_path = os.path.join(\"..\", \"Data\", \"Class1_fires.csv\")\n",
    "# with open(Class1_firesOutput_path, 'w') as csvfile:\n",
    "#         class1_df.to_csv(Class1_firesOutput_path, index=False)\n",
    "# --------------------------------------------------------------------------- #\n",
    "\n",
    "# # Interim views\n",
    "# print(X.dtypes)\n",
    "# print(len(X.columns))\n",
    "# print(X.columns)\n",
    "# # X\n",
    "\n",
    "# seed values for reshape and no of ML runs (epochs)\n",
    "NoOfCols = 58\n",
    "NoOfRuns = 1000\n",
    "\n",
    "# # Reshape X from df to array v1\n",
    "X = X.values.reshape(-1, NoOfCols)\n",
    "\n",
    "# # Reshape X from df to array v2\n",
    "# X = X.to_numpy()\n",
    "\n",
    "# # View output\n",
    "print(f\"Shape of X Input is {X.shape}\")\n",
    "print(f\"Type of X input is {type(X)}\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y is (14902, 1)\n",
      "Type of y is <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE y VALUES\n",
    "y = idaho_Fire_Weather_Drought_df[['FIRE_SIZE_CLASS']]\n",
    "\n",
    "# ADD COLUMNS FIRE_SIZE_FLAG COLUMN\n",
    "y['FIRE_SIZE_FLAG'] = 0\n",
    "\n",
    "# CREATE A FIRE CLASS SIZE SIZE E, F, G = FLAG 1, SIZE A, B, C, D = FLAG 0\n",
    "# y.loc[(y['FIRE_SIZE_CLASS'] == 'E') | (y['FIRE_SIZE_CLASS'] == 'F') | (y['FIRE_SIZE_CLASS'] == 'G'), 'FIRE_SIZE_FLAG'] = 1\n",
    "y.loc[(y['FIRE_SIZE_CLASS'] == 'F') | (y['FIRE_SIZE_CLASS'] == 'G'), 'FIRE_SIZE_FLAG'] = 2\n",
    "y.loc[(y['FIRE_SIZE_CLASS'] == 'D') | (y['FIRE_SIZE_CLASS'] == 'D'), 'FIRE_SIZE_FLAG'] = 1\n",
    "\n",
    "# DROP FIRE_SIZE_CLASS COLUMNS\n",
    "y = y.drop(['FIRE_SIZE_CLASS'], axis=1)\n",
    "\n",
    "# y = idaho_Fire_Weather_Drought_df[['STAT_CAUSE_DESCR', 'FIRE_SIZE_CLASS']]\n",
    "# y = pd.get_dummies(y, columns=[\"STAT_CAUSE_DESCR\"])\n",
    "\n",
    "# y = y.values.reshape(-1, 2)\n",
    "\n",
    "# print(y.shape)\n",
    "# # type(y)\n",
    "# y\n",
    "\n",
    "# LABEL ENCODE Y\n",
    "# Import required module\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create an object of the label encoder class\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# apply \"le.fit_transform\"\n",
    "old_y = y.apply(le.fit_transform)\n",
    "y = old_y\n",
    "\n",
    "# # Change the shape of y v1\n",
    "new_y = np.array(old_y)\n",
    "y = new_y.reshape(-1, 1) \n",
    "\n",
    "# View output\n",
    "print(f\"Shape of y is {y.shape}\")\n",
    "print(f\"Type of y is {type(y)}\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AND TRIAN SPLITS, SCALE X AND CATEGORIZE Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train: (11176, 1)\n",
      "X train: (11176, 58)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(f\"y train: {y_train.shape}\")\n",
    "print(f\"X train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11176, 58)\n"
     ]
    }
   ],
   "source": [
    "# # Scale your data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# # y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "# # Create variables to hold the scaled train & test data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "# # y_train_scaled = y_scaler.transform(y_train)\n",
    "# # y_test_scaled = y_scaler.transform(y_test)\n",
    "\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y train data: [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      " Categorical y training data: (11176, 3)\n",
      " Categorical y training data: [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "### Encode the categorical target variable to the necessary format for the model\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# preview data\n",
    "print(f\" y train data: {y_train}\")\n",
    "print(f\" Categorical y training data: {y_train_categorical.shape}\")\n",
    "print(f\" Categorical y training data: {y_train_categorical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11176, 58)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X Inputs\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11176, 58)\n",
      "(11176, 58)\n",
      "(11176, 3)\n"
     ]
    }
   ],
   "source": [
    "# X Inputs\n",
    "print(X_train.shape)\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "# Y Inputs\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 20)                1180      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 128)               2688      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 53,791\n",
      "Trainable params: 53,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Normal neural network with X inputs, 1 hidden layer, 10 nodes in hidden layer, and 7 outputs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "fire_model_v1 = Sequential()\n",
    "fire_model_v1.add(Dense(units=20, activation='sigmoid', input_dim=NoOfCols))\n",
    "fire_model_v1.add(Dense(128, activation='relu'))\n",
    "fire_model_v1.add(Dense(128, activation='sigmoid'))\n",
    "fire_model_v1.add(Dropout(.1))\n",
    "fire_model_v1.add(Dense(128, activation='relu'))\n",
    "fire_model_v1.add(Dense(128, activation='sigmoid'))\n",
    "fire_model_v1.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# view the model's architecture\n",
    "fire_model_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "350/350 - 1s - loss: 0.3407 - accuracy: 0.9167\n",
      "Epoch 2/1000\n",
      "350/350 - 0s - loss: 0.3205 - accuracy: 0.9191\n",
      "Epoch 3/1000\n",
      "350/350 - 0s - loss: 0.3198 - accuracy: 0.9191\n",
      "Epoch 4/1000\n",
      "350/350 - 0s - loss: 0.3172 - accuracy: 0.9191\n",
      "Epoch 5/1000\n",
      "350/350 - 0s - loss: 0.3164 - accuracy: 0.9191\n",
      "Epoch 6/1000\n",
      "350/350 - 0s - loss: 0.3163 - accuracy: 0.9191\n",
      "Epoch 7/1000\n",
      "350/350 - 0s - loss: 0.3161 - accuracy: 0.9191\n",
      "Epoch 8/1000\n",
      "350/350 - 0s - loss: 0.3146 - accuracy: 0.9191\n",
      "Epoch 9/1000\n",
      "350/350 - 0s - loss: 0.3134 - accuracy: 0.9191\n",
      "Epoch 10/1000\n",
      "350/350 - 0s - loss: 0.3141 - accuracy: 0.9191\n",
      "Epoch 11/1000\n",
      "350/350 - 0s - loss: 0.3123 - accuracy: 0.9191\n",
      "Epoch 12/1000\n",
      "350/350 - 0s - loss: 0.3108 - accuracy: 0.9191\n",
      "Epoch 13/1000\n",
      "350/350 - 0s - loss: 0.3097 - accuracy: 0.9191\n",
      "Epoch 14/1000\n",
      "350/350 - 0s - loss: 0.3098 - accuracy: 0.9191\n",
      "Epoch 15/1000\n",
      "350/350 - 0s - loss: 0.3087 - accuracy: 0.9191\n",
      "Epoch 16/1000\n",
      "350/350 - 0s - loss: 0.3070 - accuracy: 0.9191\n",
      "Epoch 17/1000\n",
      "350/350 - 0s - loss: 0.3074 - accuracy: 0.9191\n",
      "Epoch 18/1000\n",
      "350/350 - 0s - loss: 0.3055 - accuracy: 0.9191\n",
      "Epoch 19/1000\n",
      "350/350 - 0s - loss: 0.3056 - accuracy: 0.9191\n",
      "Epoch 20/1000\n",
      "350/350 - 0s - loss: 0.3047 - accuracy: 0.9191\n",
      "Epoch 21/1000\n",
      "350/350 - 0s - loss: 0.3045 - accuracy: 0.9191\n",
      "Epoch 22/1000\n",
      "350/350 - 0s - loss: 0.3032 - accuracy: 0.9191\n",
      "Epoch 23/1000\n",
      "350/350 - 0s - loss: 0.3020 - accuracy: 0.9191\n",
      "Epoch 24/1000\n",
      "350/350 - 0s - loss: 0.3018 - accuracy: 0.9191\n",
      "Epoch 25/1000\n",
      "350/350 - 0s - loss: 0.3015 - accuracy: 0.9191\n",
      "Epoch 26/1000\n",
      "350/350 - 0s - loss: 0.3004 - accuracy: 0.9191\n",
      "Epoch 27/1000\n",
      "350/350 - 0s - loss: 0.2998 - accuracy: 0.9191\n",
      "Epoch 28/1000\n",
      "350/350 - 0s - loss: 0.2996 - accuracy: 0.9191\n",
      "Epoch 29/1000\n",
      "350/350 - 0s - loss: 0.2976 - accuracy: 0.9191\n",
      "Epoch 30/1000\n",
      "350/350 - 0s - loss: 0.2972 - accuracy: 0.9191\n",
      "Epoch 31/1000\n",
      "350/350 - 0s - loss: 0.2976 - accuracy: 0.9191\n",
      "Epoch 32/1000\n",
      "350/350 - 0s - loss: 0.2964 - accuracy: 0.9191\n",
      "Epoch 33/1000\n",
      "350/350 - 0s - loss: 0.2953 - accuracy: 0.9191\n",
      "Epoch 34/1000\n",
      "350/350 - 0s - loss: 0.2936 - accuracy: 0.9191\n",
      "Epoch 35/1000\n",
      "350/350 - 0s - loss: 0.2952 - accuracy: 0.9191\n",
      "Epoch 36/1000\n",
      "350/350 - 0s - loss: 0.2926 - accuracy: 0.9191\n",
      "Epoch 37/1000\n",
      "350/350 - 0s - loss: 0.2930 - accuracy: 0.9191\n",
      "Epoch 38/1000\n",
      "350/350 - 0s - loss: 0.2898 - accuracy: 0.9191\n",
      "Epoch 39/1000\n",
      "350/350 - 0s - loss: 0.2900 - accuracy: 0.9191\n",
      "Epoch 40/1000\n",
      "350/350 - 0s - loss: 0.2896 - accuracy: 0.9191\n",
      "Epoch 41/1000\n",
      "350/350 - 0s - loss: 0.2897 - accuracy: 0.9191\n",
      "Epoch 42/1000\n",
      "350/350 - 0s - loss: 0.2873 - accuracy: 0.9191\n",
      "Epoch 43/1000\n",
      "350/350 - 0s - loss: 0.2861 - accuracy: 0.9191\n",
      "Epoch 44/1000\n",
      "350/350 - 0s - loss: 0.2853 - accuracy: 0.9191\n",
      "Epoch 45/1000\n",
      "350/350 - 0s - loss: 0.2843 - accuracy: 0.9191\n",
      "Epoch 46/1000\n",
      "350/350 - 0s - loss: 0.2836 - accuracy: 0.9191\n",
      "Epoch 47/1000\n",
      "350/350 - 0s - loss: 0.2830 - accuracy: 0.9191\n",
      "Epoch 48/1000\n",
      "350/350 - 0s - loss: 0.2817 - accuracy: 0.9191\n",
      "Epoch 49/1000\n",
      "350/350 - 0s - loss: 0.2811 - accuracy: 0.9191\n",
      "Epoch 50/1000\n",
      "350/350 - 0s - loss: 0.2795 - accuracy: 0.9191\n",
      "Epoch 51/1000\n",
      "350/350 - 0s - loss: 0.2796 - accuracy: 0.9191\n",
      "Epoch 52/1000\n",
      "350/350 - 0s - loss: 0.2774 - accuracy: 0.9191\n",
      "Epoch 53/1000\n",
      "350/350 - 0s - loss: 0.2770 - accuracy: 0.9193\n",
      "Epoch 54/1000\n",
      "350/350 - 0s - loss: 0.2765 - accuracy: 0.9191\n",
      "Epoch 55/1000\n",
      "350/350 - 0s - loss: 0.2737 - accuracy: 0.9192\n",
      "Epoch 56/1000\n",
      "350/350 - 0s - loss: 0.2723 - accuracy: 0.9193\n",
      "Epoch 57/1000\n",
      "350/350 - 0s - loss: 0.2729 - accuracy: 0.9193\n",
      "Epoch 58/1000\n",
      "350/350 - 0s - loss: 0.2736 - accuracy: 0.9190\n",
      "Epoch 59/1000\n",
      "350/350 - 0s - loss: 0.2697 - accuracy: 0.9196\n",
      "Epoch 60/1000\n",
      "350/350 - 0s - loss: 0.2699 - accuracy: 0.9192\n",
      "Epoch 61/1000\n",
      "350/350 - 0s - loss: 0.2709 - accuracy: 0.9189\n",
      "Epoch 62/1000\n",
      "350/350 - 0s - loss: 0.2683 - accuracy: 0.9186\n",
      "Epoch 63/1000\n",
      "350/350 - 0s - loss: 0.2665 - accuracy: 0.9191\n",
      "Epoch 64/1000\n",
      "350/350 - 0s - loss: 0.2658 - accuracy: 0.9196\n",
      "Epoch 65/1000\n",
      "350/350 - 0s - loss: 0.2653 - accuracy: 0.9193\n",
      "Epoch 66/1000\n",
      "350/350 - 0s - loss: 0.2655 - accuracy: 0.9199\n",
      "Epoch 67/1000\n",
      "350/350 - 0s - loss: 0.2647 - accuracy: 0.9195\n",
      "Epoch 68/1000\n",
      "350/350 - 0s - loss: 0.2643 - accuracy: 0.9200\n",
      "Epoch 69/1000\n",
      "350/350 - 0s - loss: 0.2623 - accuracy: 0.9197\n",
      "Epoch 70/1000\n",
      "350/350 - 0s - loss: 0.2632 - accuracy: 0.9196\n",
      "Epoch 71/1000\n",
      "350/350 - 0s - loss: 0.2605 - accuracy: 0.9202\n",
      "Epoch 72/1000\n",
      "350/350 - 0s - loss: 0.2578 - accuracy: 0.9211\n",
      "Epoch 73/1000\n",
      "350/350 - 1s - loss: 0.2573 - accuracy: 0.9216\n",
      "Epoch 74/1000\n",
      "350/350 - 1s - loss: 0.2574 - accuracy: 0.9210\n",
      "Epoch 75/1000\n",
      "350/350 - 0s - loss: 0.2570 - accuracy: 0.9213\n",
      "Epoch 76/1000\n",
      "350/350 - 1s - loss: 0.2569 - accuracy: 0.9205\n",
      "Epoch 77/1000\n",
      "350/350 - 1s - loss: 0.2531 - accuracy: 0.9228\n",
      "Epoch 78/1000\n",
      "350/350 - 0s - loss: 0.2558 - accuracy: 0.9205\n",
      "Epoch 79/1000\n",
      "350/350 - 1s - loss: 0.2543 - accuracy: 0.9218\n",
      "Epoch 80/1000\n",
      "350/350 - 1s - loss: 0.2521 - accuracy: 0.9219\n",
      "Epoch 81/1000\n",
      "350/350 - 1s - loss: 0.2528 - accuracy: 0.9222\n",
      "Epoch 82/1000\n",
      "350/350 - 0s - loss: 0.2501 - accuracy: 0.9222\n",
      "Epoch 83/1000\n",
      "350/350 - 1s - loss: 0.2492 - accuracy: 0.9235\n",
      "Epoch 84/1000\n",
      "350/350 - 1s - loss: 0.2472 - accuracy: 0.9234\n",
      "Epoch 85/1000\n",
      "350/350 - 1s - loss: 0.2478 - accuracy: 0.9236\n",
      "Epoch 86/1000\n",
      "350/350 - 0s - loss: 0.2453 - accuracy: 0.9228\n",
      "Epoch 87/1000\n",
      "350/350 - 1s - loss: 0.2468 - accuracy: 0.9214\n",
      "Epoch 88/1000\n",
      "350/350 - 0s - loss: 0.2457 - accuracy: 0.9227\n",
      "Epoch 89/1000\n",
      "350/350 - 1s - loss: 0.2460 - accuracy: 0.9234\n",
      "Epoch 90/1000\n",
      "350/350 - 0s - loss: 0.2439 - accuracy: 0.9235\n",
      "Epoch 91/1000\n",
      "350/350 - 1s - loss: 0.2423 - accuracy: 0.9230\n",
      "Epoch 92/1000\n",
      "350/350 - 1s - loss: 0.2417 - accuracy: 0.9232\n",
      "Epoch 93/1000\n",
      "350/350 - 1s - loss: 0.2395 - accuracy: 0.9249\n",
      "Epoch 94/1000\n",
      "350/350 - 1s - loss: 0.2412 - accuracy: 0.9247\n",
      "Epoch 95/1000\n",
      "350/350 - 1s - loss: 0.2394 - accuracy: 0.9242\n",
      "Epoch 96/1000\n",
      "350/350 - 1s - loss: 0.2375 - accuracy: 0.9247\n",
      "Epoch 97/1000\n",
      "350/350 - 1s - loss: 0.2379 - accuracy: 0.9253\n",
      "Epoch 98/1000\n",
      "350/350 - 1s - loss: 0.2395 - accuracy: 0.9240\n",
      "Epoch 99/1000\n",
      "350/350 - 1s - loss: 0.2364 - accuracy: 0.9230\n",
      "Epoch 100/1000\n",
      "350/350 - 1s - loss: 0.2340 - accuracy: 0.9251\n",
      "Epoch 101/1000\n",
      "350/350 - 1s - loss: 0.2323 - accuracy: 0.9256\n",
      "Epoch 102/1000\n",
      "350/350 - 1s - loss: 0.2348 - accuracy: 0.9243\n",
      "Epoch 103/1000\n",
      "350/350 - 1s - loss: 0.2318 - accuracy: 0.9255\n",
      "Epoch 104/1000\n",
      "350/350 - 1s - loss: 0.2315 - accuracy: 0.9266\n",
      "Epoch 105/1000\n",
      "350/350 - 1s - loss: 0.2318 - accuracy: 0.9257\n",
      "Epoch 106/1000\n",
      "350/350 - 1s - loss: 0.2279 - accuracy: 0.9252\n",
      "Epoch 107/1000\n",
      "350/350 - 1s - loss: 0.2296 - accuracy: 0.9242\n",
      "Epoch 108/1000\n",
      "350/350 - 1s - loss: 0.2305 - accuracy: 0.9263\n",
      "Epoch 109/1000\n",
      "350/350 - 1s - loss: 0.2292 - accuracy: 0.9264\n",
      "Epoch 110/1000\n",
      "350/350 - 0s - loss: 0.2264 - accuracy: 0.9250\n",
      "Epoch 111/1000\n",
      "350/350 - 1s - loss: 0.2271 - accuracy: 0.9271\n",
      "Epoch 112/1000\n",
      "350/350 - 1s - loss: 0.2254 - accuracy: 0.9260\n",
      "Epoch 113/1000\n",
      "350/350 - 1s - loss: 0.2238 - accuracy: 0.9268\n",
      "Epoch 114/1000\n",
      "350/350 - 1s - loss: 0.2240 - accuracy: 0.9275\n",
      "Epoch 115/1000\n",
      "350/350 - 1s - loss: 0.2217 - accuracy: 0.9278\n",
      "Epoch 116/1000\n",
      "350/350 - 1s - loss: 0.2206 - accuracy: 0.9281\n",
      "Epoch 117/1000\n",
      "350/350 - 1s - loss: 0.2222 - accuracy: 0.9273\n",
      "Epoch 118/1000\n",
      "350/350 - 1s - loss: 0.2206 - accuracy: 0.9278\n",
      "Epoch 119/1000\n",
      "350/350 - 1s - loss: 0.2223 - accuracy: 0.9267\n",
      "Epoch 120/1000\n",
      "350/350 - 1s - loss: 0.2201 - accuracy: 0.9273\n",
      "Epoch 121/1000\n",
      "350/350 - 1s - loss: 0.2183 - accuracy: 0.9273\n",
      "Epoch 122/1000\n",
      "350/350 - 1s - loss: 0.2166 - accuracy: 0.9280\n",
      "Epoch 123/1000\n",
      "350/350 - 1s - loss: 0.2146 - accuracy: 0.9288\n",
      "Epoch 124/1000\n",
      "350/350 - 1s - loss: 0.2124 - accuracy: 0.9297\n",
      "Epoch 125/1000\n",
      "350/350 - 1s - loss: 0.2167 - accuracy: 0.9282\n",
      "Epoch 126/1000\n",
      "350/350 - 1s - loss: 0.2158 - accuracy: 0.9297\n",
      "Epoch 127/1000\n",
      "350/350 - 1s - loss: 0.2141 - accuracy: 0.9285\n",
      "Epoch 128/1000\n",
      "350/350 - 1s - loss: 0.2097 - accuracy: 0.9294\n",
      "Epoch 129/1000\n",
      "350/350 - 1s - loss: 0.2132 - accuracy: 0.9273\n",
      "Epoch 130/1000\n",
      "350/350 - 1s - loss: 0.2093 - accuracy: 0.9307\n",
      "Epoch 131/1000\n",
      "350/350 - 1s - loss: 0.2106 - accuracy: 0.9288\n",
      "Epoch 132/1000\n",
      "350/350 - 1s - loss: 0.2063 - accuracy: 0.9298\n",
      "Epoch 133/1000\n",
      "350/350 - 1s - loss: 0.2123 - accuracy: 0.9289\n",
      "Epoch 134/1000\n",
      "350/350 - 1s - loss: 0.2088 - accuracy: 0.9299\n",
      "Epoch 135/1000\n",
      "350/350 - 1s - loss: 0.2068 - accuracy: 0.9304\n",
      "Epoch 136/1000\n",
      "350/350 - 1s - loss: 0.2093 - accuracy: 0.9298\n",
      "Epoch 137/1000\n",
      "350/350 - 1s - loss: 0.2060 - accuracy: 0.9315\n",
      "Epoch 138/1000\n",
      "350/350 - 1s - loss: 0.2078 - accuracy: 0.9281\n",
      "Epoch 139/1000\n",
      "350/350 - 1s - loss: 0.2070 - accuracy: 0.9300\n",
      "Epoch 140/1000\n",
      "350/350 - 1s - loss: 0.2047 - accuracy: 0.9308\n",
      "Epoch 141/1000\n",
      "350/350 - 1s - loss: 0.2042 - accuracy: 0.9315\n",
      "Epoch 142/1000\n",
      "350/350 - 1s - loss: 0.2025 - accuracy: 0.9304\n",
      "Epoch 143/1000\n",
      "350/350 - 1s - loss: 0.2005 - accuracy: 0.9317\n",
      "Epoch 144/1000\n",
      "350/350 - 1s - loss: 0.2023 - accuracy: 0.9308\n",
      "Epoch 145/1000\n",
      "350/350 - 1s - loss: 0.2002 - accuracy: 0.9325\n",
      "Epoch 146/1000\n",
      "350/350 - 1s - loss: 0.2033 - accuracy: 0.9310\n",
      "Epoch 147/1000\n",
      "350/350 - 1s - loss: 0.2008 - accuracy: 0.9307\n",
      "Epoch 148/1000\n",
      "350/350 - 1s - loss: 0.1988 - accuracy: 0.9310\n",
      "Epoch 149/1000\n",
      "350/350 - 1s - loss: 0.2015 - accuracy: 0.9309\n",
      "Epoch 150/1000\n",
      "350/350 - 1s - loss: 0.1990 - accuracy: 0.9306\n",
      "Epoch 151/1000\n",
      "350/350 - 1s - loss: 0.1955 - accuracy: 0.9336\n",
      "Epoch 152/1000\n",
      "350/350 - 1s - loss: 0.1934 - accuracy: 0.9342\n",
      "Epoch 153/1000\n",
      "350/350 - 1s - loss: 0.1971 - accuracy: 0.9323\n",
      "Epoch 154/1000\n",
      "350/350 - 1s - loss: 0.1955 - accuracy: 0.9335\n",
      "Epoch 155/1000\n",
      "350/350 - 1s - loss: 0.1948 - accuracy: 0.9324\n",
      "Epoch 156/1000\n",
      "350/350 - 1s - loss: 0.1934 - accuracy: 0.9322\n",
      "Epoch 157/1000\n",
      "350/350 - 1s - loss: 0.1932 - accuracy: 0.9332\n",
      "Epoch 158/1000\n",
      "350/350 - 1s - loss: 0.1915 - accuracy: 0.9329\n",
      "Epoch 159/1000\n",
      "350/350 - 1s - loss: 0.1934 - accuracy: 0.9332\n",
      "Epoch 160/1000\n",
      "350/350 - 1s - loss: 0.1936 - accuracy: 0.9339\n",
      "Epoch 161/1000\n",
      "350/350 - 1s - loss: 0.1919 - accuracy: 0.9352\n",
      "Epoch 162/1000\n",
      "350/350 - 1s - loss: 0.1892 - accuracy: 0.9332\n",
      "Epoch 163/1000\n",
      "350/350 - 1s - loss: 0.1899 - accuracy: 0.9332\n",
      "Epoch 164/1000\n",
      "350/350 - 1s - loss: 0.1909 - accuracy: 0.9332\n",
      "Epoch 165/1000\n",
      "350/350 - 1s - loss: 0.1883 - accuracy: 0.9337\n",
      "Epoch 166/1000\n",
      "350/350 - 1s - loss: 0.1874 - accuracy: 0.9363\n",
      "Epoch 167/1000\n",
      "350/350 - 1s - loss: 0.1891 - accuracy: 0.9335\n",
      "Epoch 168/1000\n",
      "350/350 - 1s - loss: 0.1856 - accuracy: 0.9324\n",
      "Epoch 169/1000\n",
      "350/350 - 1s - loss: 0.1827 - accuracy: 0.9349\n",
      "Epoch 170/1000\n",
      "350/350 - 1s - loss: 0.1853 - accuracy: 0.9343\n",
      "Epoch 171/1000\n",
      "350/350 - 1s - loss: 0.1813 - accuracy: 0.9366\n",
      "Epoch 172/1000\n",
      "350/350 - 1s - loss: 0.1856 - accuracy: 0.9365\n",
      "Epoch 173/1000\n",
      "350/350 - 1s - loss: 0.1797 - accuracy: 0.9375\n",
      "Epoch 174/1000\n",
      "350/350 - 1s - loss: 0.1843 - accuracy: 0.9349\n",
      "Epoch 175/1000\n",
      "350/350 - 0s - loss: 0.1811 - accuracy: 0.9372\n",
      "Epoch 176/1000\n",
      "350/350 - 1s - loss: 0.1830 - accuracy: 0.9366\n",
      "Epoch 177/1000\n",
      "350/350 - 1s - loss: 0.1768 - accuracy: 0.9386\n",
      "Epoch 178/1000\n",
      "350/350 - 1s - loss: 0.1798 - accuracy: 0.9351\n",
      "Epoch 179/1000\n",
      "350/350 - 1s - loss: 0.1779 - accuracy: 0.9368\n",
      "Epoch 180/1000\n",
      "350/350 - 1s - loss: 0.1778 - accuracy: 0.9375\n",
      "Epoch 181/1000\n",
      "350/350 - 1s - loss: 0.1802 - accuracy: 0.9352\n",
      "Epoch 182/1000\n",
      "350/350 - 1s - loss: 0.1792 - accuracy: 0.9372\n",
      "Epoch 183/1000\n",
      "350/350 - 0s - loss: 0.1764 - accuracy: 0.9349\n",
      "Epoch 184/1000\n",
      "350/350 - 1s - loss: 0.1740 - accuracy: 0.9377\n",
      "Epoch 185/1000\n",
      "350/350 - 1s - loss: 0.1782 - accuracy: 0.9366\n",
      "Epoch 186/1000\n",
      "350/350 - 1s - loss: 0.1748 - accuracy: 0.9371\n",
      "Epoch 187/1000\n",
      "350/350 - 1s - loss: 0.1737 - accuracy: 0.9384\n",
      "Epoch 188/1000\n",
      "350/350 - 1s - loss: 0.1748 - accuracy: 0.9374\n",
      "Epoch 189/1000\n",
      "350/350 - 1s - loss: 0.1737 - accuracy: 0.9374\n",
      "Epoch 190/1000\n",
      "350/350 - 1s - loss: 0.1732 - accuracy: 0.9391\n",
      "Epoch 191/1000\n",
      "350/350 - 1s - loss: 0.1719 - accuracy: 0.9390\n",
      "Epoch 192/1000\n",
      "350/350 - 1s - loss: 0.1716 - accuracy: 0.9375\n",
      "Epoch 193/1000\n",
      "350/350 - 1s - loss: 0.1703 - accuracy: 0.9388\n",
      "Epoch 194/1000\n",
      "350/350 - 1s - loss: 0.1728 - accuracy: 0.9391\n",
      "Epoch 195/1000\n",
      "350/350 - 1s - loss: 0.1734 - accuracy: 0.9366\n",
      "Epoch 196/1000\n",
      "350/350 - 1s - loss: 0.1715 - accuracy: 0.9377\n",
      "Epoch 197/1000\n",
      "350/350 - 1s - loss: 0.1690 - accuracy: 0.9386\n",
      "Epoch 198/1000\n",
      "350/350 - 1s - loss: 0.1696 - accuracy: 0.9389\n",
      "Epoch 199/1000\n",
      "350/350 - 1s - loss: 0.1663 - accuracy: 0.9386\n",
      "Epoch 200/1000\n",
      "350/350 - 1s - loss: 0.1709 - accuracy: 0.9372\n",
      "Epoch 201/1000\n",
      "350/350 - 1s - loss: 0.1681 - accuracy: 0.9381\n",
      "Epoch 202/1000\n",
      "350/350 - 1s - loss: 0.1635 - accuracy: 0.9401\n",
      "Epoch 203/1000\n",
      "350/350 - 1s - loss: 0.1657 - accuracy: 0.9393\n",
      "Epoch 204/1000\n",
      "350/350 - 1s - loss: 0.1640 - accuracy: 0.9412\n",
      "Epoch 205/1000\n",
      "350/350 - 1s - loss: 0.1642 - accuracy: 0.9403\n",
      "Epoch 206/1000\n",
      "350/350 - 1s - loss: 0.1661 - accuracy: 0.9385\n",
      "Epoch 207/1000\n",
      "350/350 - 1s - loss: 0.1648 - accuracy: 0.9400\n",
      "Epoch 208/1000\n",
      "350/350 - 1s - loss: 0.1642 - accuracy: 0.9401\n",
      "Epoch 209/1000\n",
      "350/350 - 1s - loss: 0.1622 - accuracy: 0.9409\n",
      "Epoch 210/1000\n",
      "350/350 - 0s - loss: 0.1620 - accuracy: 0.9403\n",
      "Epoch 211/1000\n",
      "350/350 - 1s - loss: 0.1596 - accuracy: 0.9416\n",
      "Epoch 212/1000\n",
      "350/350 - 1s - loss: 0.1596 - accuracy: 0.9405\n",
      "Epoch 213/1000\n",
      "350/350 - 1s - loss: 0.1613 - accuracy: 0.9393\n",
      "Epoch 214/1000\n",
      "350/350 - 1s - loss: 0.1595 - accuracy: 0.9414\n",
      "Epoch 215/1000\n",
      "350/350 - 1s - loss: 0.1602 - accuracy: 0.9407\n",
      "Epoch 216/1000\n",
      "350/350 - 1s - loss: 0.1583 - accuracy: 0.9412\n",
      "Epoch 217/1000\n",
      "350/350 - 1s - loss: 0.1552 - accuracy: 0.9426\n",
      "Epoch 218/1000\n",
      "350/350 - 1s - loss: 0.1583 - accuracy: 0.9418\n",
      "Epoch 219/1000\n",
      "350/350 - 1s - loss: 0.1565 - accuracy: 0.9425\n",
      "Epoch 220/1000\n",
      "350/350 - 1s - loss: 0.1578 - accuracy: 0.9418\n",
      "Epoch 221/1000\n",
      "350/350 - 1s - loss: 0.1558 - accuracy: 0.9418\n",
      "Epoch 222/1000\n",
      "350/350 - 1s - loss: 0.1573 - accuracy: 0.9419\n",
      "Epoch 223/1000\n",
      "350/350 - 1s - loss: 0.1561 - accuracy: 0.9418\n",
      "Epoch 224/1000\n",
      "350/350 - 1s - loss: 0.1561 - accuracy: 0.9418\n",
      "Epoch 225/1000\n",
      "350/350 - 1s - loss: 0.1529 - accuracy: 0.9417\n",
      "Epoch 226/1000\n",
      "350/350 - 1s - loss: 0.1537 - accuracy: 0.9415\n",
      "Epoch 227/1000\n",
      "350/350 - 1s - loss: 0.1532 - accuracy: 0.9425\n",
      "Epoch 228/1000\n",
      "350/350 - 1s - loss: 0.1513 - accuracy: 0.9430\n",
      "Epoch 229/1000\n",
      "350/350 - 1s - loss: 0.1498 - accuracy: 0.9440\n",
      "Epoch 230/1000\n",
      "350/350 - 1s - loss: 0.1496 - accuracy: 0.9420\n",
      "Epoch 231/1000\n",
      "350/350 - 1s - loss: 0.1520 - accuracy: 0.9417\n",
      "Epoch 232/1000\n",
      "350/350 - 1s - loss: 0.1533 - accuracy: 0.9425\n",
      "Epoch 233/1000\n",
      "350/350 - 1s - loss: 0.1502 - accuracy: 0.9442\n",
      "Epoch 234/1000\n",
      "350/350 - 1s - loss: 0.1481 - accuracy: 0.9435\n",
      "Epoch 235/1000\n",
      "350/350 - 1s - loss: 0.1496 - accuracy: 0.9424\n",
      "Epoch 236/1000\n",
      "350/350 - 1s - loss: 0.1492 - accuracy: 0.9418\n",
      "Epoch 237/1000\n",
      "350/350 - 1s - loss: 0.1511 - accuracy: 0.9442\n",
      "Epoch 238/1000\n",
      "350/350 - 1s - loss: 0.1503 - accuracy: 0.9428\n",
      "Epoch 239/1000\n",
      "350/350 - 1s - loss: 0.1515 - accuracy: 0.9435\n",
      "Epoch 240/1000\n",
      "350/350 - 1s - loss: 0.1477 - accuracy: 0.9435\n",
      "Epoch 241/1000\n",
      "350/350 - 1s - loss: 0.1474 - accuracy: 0.9428\n",
      "Epoch 242/1000\n",
      "350/350 - 1s - loss: 0.1484 - accuracy: 0.9439\n",
      "Epoch 243/1000\n",
      "350/350 - 1s - loss: 0.1443 - accuracy: 0.9461\n",
      "Epoch 244/1000\n",
      "350/350 - 1s - loss: 0.1467 - accuracy: 0.9441\n",
      "Epoch 245/1000\n",
      "350/350 - 1s - loss: 0.1417 - accuracy: 0.9455\n",
      "Epoch 246/1000\n",
      "350/350 - 1s - loss: 0.1439 - accuracy: 0.9438\n",
      "Epoch 247/1000\n",
      "350/350 - 1s - loss: 0.1437 - accuracy: 0.9453\n",
      "Epoch 248/1000\n",
      "350/350 - 1s - loss: 0.1430 - accuracy: 0.9460\n",
      "Epoch 249/1000\n",
      "350/350 - 1s - loss: 0.1434 - accuracy: 0.9444\n",
      "Epoch 250/1000\n",
      "350/350 - 1s - loss: 0.1442 - accuracy: 0.9445\n",
      "Epoch 251/1000\n",
      "350/350 - 1s - loss: 0.1436 - accuracy: 0.9449\n",
      "Epoch 252/1000\n",
      "350/350 - 0s - loss: 0.1379 - accuracy: 0.9478\n",
      "Epoch 253/1000\n",
      "350/350 - 1s - loss: 0.1448 - accuracy: 0.9432\n",
      "Epoch 254/1000\n",
      "350/350 - 1s - loss: 0.1411 - accuracy: 0.9471\n",
      "Epoch 255/1000\n",
      "350/350 - 1s - loss: 0.1386 - accuracy: 0.9475\n",
      "Epoch 256/1000\n",
      "350/350 - 0s - loss: 0.1417 - accuracy: 0.9456\n",
      "Epoch 257/1000\n",
      "350/350 - 1s - loss: 0.1372 - accuracy: 0.9465\n",
      "Epoch 258/1000\n",
      "350/350 - 1s - loss: 0.1454 - accuracy: 0.9441\n",
      "Epoch 259/1000\n",
      "350/350 - 1s - loss: 0.1399 - accuracy: 0.9454\n",
      "Epoch 260/1000\n",
      "350/350 - 1s - loss: 0.1351 - accuracy: 0.9487\n",
      "Epoch 261/1000\n",
      "350/350 - 1s - loss: 0.1388 - accuracy: 0.9456\n",
      "Epoch 262/1000\n",
      "350/350 - 1s - loss: 0.1373 - accuracy: 0.9475\n",
      "Epoch 263/1000\n",
      "350/350 - 1s - loss: 0.1372 - accuracy: 0.9460\n",
      "Epoch 264/1000\n",
      "350/350 - 1s - loss: 0.1397 - accuracy: 0.9449\n",
      "Epoch 265/1000\n",
      "350/350 - 1s - loss: 0.1359 - accuracy: 0.9470\n",
      "Epoch 266/1000\n",
      "350/350 - 1s - loss: 0.1352 - accuracy: 0.9472\n",
      "Epoch 267/1000\n",
      "350/350 - 1s - loss: 0.1387 - accuracy: 0.9467\n",
      "Epoch 268/1000\n",
      "350/350 - 1s - loss: 0.1382 - accuracy: 0.9466\n",
      "Epoch 269/1000\n",
      "350/350 - 1s - loss: 0.1386 - accuracy: 0.9467\n",
      "Epoch 270/1000\n",
      "350/350 - 1s - loss: 0.1366 - accuracy: 0.9482\n",
      "Epoch 271/1000\n",
      "350/350 - 1s - loss: 0.1334 - accuracy: 0.9482\n",
      "Epoch 272/1000\n",
      "350/350 - 1s - loss: 0.1364 - accuracy: 0.9469\n",
      "Epoch 273/1000\n",
      "350/350 - 1s - loss: 0.1350 - accuracy: 0.9465\n",
      "Epoch 274/1000\n",
      "350/350 - 1s - loss: 0.1332 - accuracy: 0.9489\n",
      "Epoch 275/1000\n",
      "350/350 - 1s - loss: 0.1349 - accuracy: 0.9473\n",
      "Epoch 276/1000\n",
      "350/350 - 1s - loss: 0.1363 - accuracy: 0.9479\n",
      "Epoch 277/1000\n",
      "350/350 - 1s - loss: 0.1318 - accuracy: 0.9468\n",
      "Epoch 278/1000\n",
      "350/350 - 1s - loss: 0.1342 - accuracy: 0.9485\n",
      "Epoch 279/1000\n",
      "350/350 - 1s - loss: 0.1342 - accuracy: 0.9480\n",
      "Epoch 280/1000\n",
      "350/350 - 1s - loss: 0.1323 - accuracy: 0.9495\n",
      "Epoch 281/1000\n",
      "350/350 - 1s - loss: 0.1290 - accuracy: 0.9499\n",
      "Epoch 282/1000\n",
      "350/350 - 1s - loss: 0.1311 - accuracy: 0.9492\n",
      "Epoch 283/1000\n",
      "350/350 - 1s - loss: 0.1332 - accuracy: 0.9473\n",
      "Epoch 284/1000\n",
      "350/350 - 1s - loss: 0.1301 - accuracy: 0.9469\n",
      "Epoch 285/1000\n",
      "350/350 - 1s - loss: 0.1307 - accuracy: 0.9494\n",
      "Epoch 286/1000\n",
      "350/350 - 1s - loss: 0.1314 - accuracy: 0.9488\n",
      "Epoch 287/1000\n",
      "350/350 - 1s - loss: 0.1277 - accuracy: 0.9486\n",
      "Epoch 288/1000\n",
      "350/350 - 1s - loss: 0.1258 - accuracy: 0.9499\n",
      "Epoch 289/1000\n",
      "350/350 - 1s - loss: 0.1325 - accuracy: 0.9480\n",
      "Epoch 290/1000\n",
      "350/350 - 1s - loss: 0.1274 - accuracy: 0.9493\n",
      "Epoch 291/1000\n",
      "350/350 - 1s - loss: 0.1313 - accuracy: 0.9484\n",
      "Epoch 292/1000\n",
      "350/350 - 1s - loss: 0.1311 - accuracy: 0.9482\n",
      "Epoch 293/1000\n",
      "350/350 - 1s - loss: 0.1264 - accuracy: 0.9508\n",
      "Epoch 294/1000\n",
      "350/350 - 1s - loss: 0.1382 - accuracy: 0.9461\n",
      "Epoch 295/1000\n",
      "350/350 - 1s - loss: 0.1320 - accuracy: 0.9478\n",
      "Epoch 296/1000\n",
      "350/350 - 1s - loss: 0.1254 - accuracy: 0.9520\n",
      "Epoch 297/1000\n",
      "350/350 - 1s - loss: 0.1242 - accuracy: 0.9505\n",
      "Epoch 298/1000\n",
      "350/350 - 1s - loss: 0.1243 - accuracy: 0.9509\n",
      "Epoch 299/1000\n",
      "350/350 - 1s - loss: 0.1279 - accuracy: 0.9495\n",
      "Epoch 300/1000\n",
      "350/350 - 1s - loss: 0.1259 - accuracy: 0.9494\n",
      "Epoch 301/1000\n",
      "350/350 - 1s - loss: 0.1292 - accuracy: 0.9488\n",
      "Epoch 302/1000\n",
      "350/350 - 1s - loss: 0.1237 - accuracy: 0.9500\n",
      "Epoch 303/1000\n",
      "350/350 - 1s - loss: 0.1233 - accuracy: 0.9518\n",
      "Epoch 304/1000\n",
      "350/350 - 1s - loss: 0.1296 - accuracy: 0.9507\n",
      "Epoch 305/1000\n",
      "350/350 - 1s - loss: 0.1325 - accuracy: 0.9494\n",
      "Epoch 306/1000\n",
      "350/350 - 1s - loss: 0.1224 - accuracy: 0.9514\n",
      "Epoch 307/1000\n",
      "350/350 - 1s - loss: 0.1217 - accuracy: 0.9521\n",
      "Epoch 308/1000\n",
      "350/350 - 1s - loss: 0.1232 - accuracy: 0.9502\n",
      "Epoch 309/1000\n",
      "350/350 - 1s - loss: 0.1248 - accuracy: 0.9493\n",
      "Epoch 310/1000\n",
      "350/350 - 1s - loss: 0.1217 - accuracy: 0.9500\n",
      "Epoch 311/1000\n",
      "350/350 - 1s - loss: 0.1256 - accuracy: 0.9512\n",
      "Epoch 312/1000\n",
      "350/350 - 1s - loss: 0.1218 - accuracy: 0.9529\n",
      "Epoch 313/1000\n",
      "350/350 - 1s - loss: 0.1254 - accuracy: 0.9500\n",
      "Epoch 314/1000\n",
      "350/350 - 1s - loss: 0.1223 - accuracy: 0.9512\n",
      "Epoch 315/1000\n",
      "350/350 - 1s - loss: 0.1221 - accuracy: 0.9493\n",
      "Epoch 316/1000\n",
      "350/350 - 1s - loss: 0.1225 - accuracy: 0.9518\n",
      "Epoch 317/1000\n",
      "350/350 - 1s - loss: 0.1226 - accuracy: 0.9506\n",
      "Epoch 318/1000\n",
      "350/350 - 1s - loss: 0.1189 - accuracy: 0.9519\n",
      "Epoch 319/1000\n",
      "350/350 - 1s - loss: 0.1223 - accuracy: 0.9512\n",
      "Epoch 320/1000\n",
      "350/350 - 1s - loss: 0.1276 - accuracy: 0.9493\n",
      "Epoch 321/1000\n",
      "350/350 - 1s - loss: 0.1250 - accuracy: 0.9499\n",
      "Epoch 322/1000\n",
      "350/350 - 1s - loss: 0.1231 - accuracy: 0.9490\n",
      "Epoch 323/1000\n",
      "350/350 - 1s - loss: 0.1212 - accuracy: 0.9515\n",
      "Epoch 324/1000\n",
      "350/350 - 1s - loss: 0.1181 - accuracy: 0.9528\n",
      "Epoch 325/1000\n",
      "350/350 - 1s - loss: 0.1193 - accuracy: 0.9511\n",
      "Epoch 326/1000\n",
      "350/350 - 1s - loss: 0.1236 - accuracy: 0.9517\n",
      "Epoch 327/1000\n",
      "350/350 - 1s - loss: 0.1210 - accuracy: 0.9523\n",
      "Epoch 328/1000\n",
      "350/350 - 1s - loss: 0.1172 - accuracy: 0.9523\n",
      "Epoch 329/1000\n",
      "350/350 - 1s - loss: 0.1202 - accuracy: 0.9532\n",
      "Epoch 330/1000\n",
      "350/350 - 1s - loss: 0.1200 - accuracy: 0.9510\n",
      "Epoch 331/1000\n",
      "350/350 - 1s - loss: 0.1212 - accuracy: 0.9533\n",
      "Epoch 332/1000\n",
      "350/350 - 0s - loss: 0.1205 - accuracy: 0.9515\n",
      "Epoch 333/1000\n",
      "350/350 - 1s - loss: 0.1186 - accuracy: 0.9527\n",
      "Epoch 334/1000\n",
      "350/350 - 1s - loss: 0.1187 - accuracy: 0.9501\n",
      "Epoch 335/1000\n",
      "350/350 - 1s - loss: 0.1150 - accuracy: 0.9530\n",
      "Epoch 336/1000\n",
      "350/350 - 1s - loss: 0.1176 - accuracy: 0.9532\n",
      "Epoch 337/1000\n",
      "350/350 - 1s - loss: 0.1209 - accuracy: 0.9500\n",
      "Epoch 338/1000\n",
      "350/350 - 1s - loss: 0.1178 - accuracy: 0.9531\n",
      "Epoch 339/1000\n",
      "350/350 - 1s - loss: 0.1136 - accuracy: 0.9536\n",
      "Epoch 340/1000\n",
      "350/350 - 1s - loss: 0.1173 - accuracy: 0.9539\n",
      "Epoch 341/1000\n",
      "350/350 - 1s - loss: 0.1194 - accuracy: 0.9510\n",
      "Epoch 342/1000\n",
      "350/350 - 1s - loss: 0.1166 - accuracy: 0.9533\n",
      "Epoch 343/1000\n",
      "350/350 - 1s - loss: 0.1156 - accuracy: 0.9528\n",
      "Epoch 344/1000\n",
      "350/350 - 1s - loss: 0.1151 - accuracy: 0.9528\n",
      "Epoch 345/1000\n",
      "350/350 - 1s - loss: 0.1178 - accuracy: 0.9526\n",
      "Epoch 346/1000\n",
      "350/350 - 1s - loss: 0.1177 - accuracy: 0.9517\n",
      "Epoch 347/1000\n",
      "350/350 - 1s - loss: 0.1169 - accuracy: 0.9513\n",
      "Epoch 348/1000\n",
      "350/350 - 1s - loss: 0.1135 - accuracy: 0.9534\n",
      "Epoch 349/1000\n",
      "350/350 - 1s - loss: 0.1179 - accuracy: 0.9516\n",
      "Epoch 350/1000\n",
      "350/350 - 1s - loss: 0.1183 - accuracy: 0.9540\n",
      "Epoch 351/1000\n",
      "350/350 - 1s - loss: 0.1140 - accuracy: 0.9543\n",
      "Epoch 352/1000\n",
      "350/350 - 1s - loss: 0.1146 - accuracy: 0.9514\n",
      "Epoch 353/1000\n",
      "350/350 - 1s - loss: 0.1143 - accuracy: 0.9528\n",
      "Epoch 354/1000\n",
      "350/350 - 1s - loss: 0.1129 - accuracy: 0.9546\n",
      "Epoch 355/1000\n",
      "350/350 - 1s - loss: 0.1152 - accuracy: 0.9547\n",
      "Epoch 356/1000\n",
      "350/350 - 1s - loss: 0.1159 - accuracy: 0.9520\n",
      "Epoch 357/1000\n",
      "350/350 - 1s - loss: 0.1185 - accuracy: 0.9522\n",
      "Epoch 358/1000\n",
      "350/350 - 1s - loss: 0.1147 - accuracy: 0.9529\n",
      "Epoch 359/1000\n",
      "350/350 - 1s - loss: 0.1182 - accuracy: 0.9522\n",
      "Epoch 360/1000\n",
      "350/350 - 1s - loss: 0.1146 - accuracy: 0.9539\n",
      "Epoch 361/1000\n",
      "350/350 - 1s - loss: 0.1113 - accuracy: 0.9553\n",
      "Epoch 362/1000\n",
      "350/350 - 1s - loss: 0.1100 - accuracy: 0.9549\n",
      "Epoch 363/1000\n",
      "350/350 - 1s - loss: 0.1153 - accuracy: 0.9526\n",
      "Epoch 364/1000\n",
      "350/350 - 1s - loss: 0.1223 - accuracy: 0.9494\n",
      "Epoch 365/1000\n",
      "350/350 - 1s - loss: 0.1149 - accuracy: 0.9518\n",
      "Epoch 366/1000\n",
      "350/350 - 1s - loss: 0.1092 - accuracy: 0.9551\n",
      "Epoch 367/1000\n",
      "350/350 - 1s - loss: 0.1103 - accuracy: 0.9538\n",
      "Epoch 368/1000\n",
      "350/350 - 1s - loss: 0.1127 - accuracy: 0.9535\n",
      "Epoch 369/1000\n",
      "350/350 - 1s - loss: 0.1091 - accuracy: 0.9540\n",
      "Epoch 370/1000\n",
      "350/350 - 1s - loss: 0.1095 - accuracy: 0.9560\n",
      "Epoch 371/1000\n",
      "350/350 - 1s - loss: 0.1122 - accuracy: 0.9520\n",
      "Epoch 372/1000\n",
      "350/350 - 1s - loss: 0.1136 - accuracy: 0.9537\n",
      "Epoch 373/1000\n",
      "350/350 - 1s - loss: 0.1152 - accuracy: 0.9529\n",
      "Epoch 374/1000\n",
      "350/350 - 1s - loss: 0.1111 - accuracy: 0.9537\n",
      "Epoch 375/1000\n",
      "350/350 - 1s - loss: 0.1082 - accuracy: 0.9558\n",
      "Epoch 376/1000\n",
      "350/350 - 1s - loss: 0.1111 - accuracy: 0.9558\n",
      "Epoch 377/1000\n",
      "350/350 - 1s - loss: 0.1093 - accuracy: 0.9547\n",
      "Epoch 378/1000\n",
      "350/350 - 1s - loss: 0.1123 - accuracy: 0.9535\n",
      "Epoch 379/1000\n",
      "350/350 - 1s - loss: 0.1144 - accuracy: 0.9535\n",
      "Epoch 380/1000\n",
      "350/350 - 1s - loss: 0.1115 - accuracy: 0.9537\n",
      "Epoch 381/1000\n",
      "350/350 - 1s - loss: 0.1088 - accuracy: 0.9562\n",
      "Epoch 382/1000\n",
      "350/350 - 1s - loss: 0.1100 - accuracy: 0.9550\n",
      "Epoch 383/1000\n",
      "350/350 - 1s - loss: 0.1103 - accuracy: 0.9551\n",
      "Epoch 384/1000\n",
      "350/350 - 1s - loss: 0.1114 - accuracy: 0.9550\n",
      "Epoch 385/1000\n",
      "350/350 - 1s - loss: 0.1122 - accuracy: 0.9545\n",
      "Epoch 386/1000\n",
      "350/350 - 1s - loss: 0.1095 - accuracy: 0.9545\n",
      "Epoch 387/1000\n",
      "350/350 - 1s - loss: 0.1054 - accuracy: 0.9562\n",
      "Epoch 388/1000\n",
      "350/350 - 1s - loss: 0.1089 - accuracy: 0.9563\n",
      "Epoch 389/1000\n",
      "350/350 - 1s - loss: 0.1096 - accuracy: 0.9557\n",
      "Epoch 390/1000\n",
      "350/350 - 1s - loss: 0.1095 - accuracy: 0.9537\n",
      "Epoch 391/1000\n",
      "350/350 - 1s - loss: 0.1065 - accuracy: 0.9576\n",
      "Epoch 392/1000\n",
      "350/350 - 1s - loss: 0.1100 - accuracy: 0.9539\n",
      "Epoch 393/1000\n",
      "350/350 - 1s - loss: 0.1081 - accuracy: 0.9555\n",
      "Epoch 394/1000\n",
      "350/350 - 1s - loss: 0.1098 - accuracy: 0.9552\n",
      "Epoch 395/1000\n",
      "350/350 - 1s - loss: 0.1138 - accuracy: 0.9532\n",
      "Epoch 396/1000\n",
      "350/350 - 1s - loss: 0.1111 - accuracy: 0.9545\n",
      "Epoch 397/1000\n",
      "350/350 - 1s - loss: 0.1049 - accuracy: 0.9566\n",
      "Epoch 398/1000\n",
      "350/350 - 1s - loss: 0.1058 - accuracy: 0.9553\n",
      "Epoch 399/1000\n",
      "350/350 - 1s - loss: 0.1057 - accuracy: 0.9554\n",
      "Epoch 400/1000\n",
      "350/350 - 1s - loss: 0.1051 - accuracy: 0.9554\n",
      "Epoch 401/1000\n",
      "350/350 - 1s - loss: 0.1102 - accuracy: 0.9554\n",
      "Epoch 402/1000\n",
      "350/350 - 1s - loss: 0.1076 - accuracy: 0.9555\n",
      "Epoch 403/1000\n",
      "350/350 - 1s - loss: 0.1064 - accuracy: 0.9555\n",
      "Epoch 404/1000\n",
      "350/350 - 1s - loss: 0.1086 - accuracy: 0.9556\n",
      "Epoch 405/1000\n",
      "350/350 - 1s - loss: 0.1095 - accuracy: 0.9551\n",
      "Epoch 406/1000\n",
      "350/350 - 1s - loss: 0.1110 - accuracy: 0.9542\n",
      "Epoch 407/1000\n",
      "350/350 - 1s - loss: 0.1044 - accuracy: 0.9556\n",
      "Epoch 408/1000\n",
      "350/350 - 1s - loss: 0.1050 - accuracy: 0.9556\n",
      "Epoch 409/1000\n",
      "350/350 - 1s - loss: 0.1026 - accuracy: 0.9582\n",
      "Epoch 410/1000\n",
      "350/350 - 1s - loss: 0.1030 - accuracy: 0.9547\n",
      "Epoch 411/1000\n",
      "350/350 - 1s - loss: 0.1096 - accuracy: 0.9549\n",
      "Epoch 412/1000\n",
      "350/350 - 1s - loss: 0.1087 - accuracy: 0.9546\n",
      "Epoch 413/1000\n",
      "350/350 - 1s - loss: 0.1053 - accuracy: 0.9548\n",
      "Epoch 414/1000\n",
      "350/350 - 1s - loss: 0.1057 - accuracy: 0.9557\n",
      "Epoch 415/1000\n",
      "350/350 - 1s - loss: 0.1052 - accuracy: 0.9546\n",
      "Epoch 416/1000\n",
      "350/350 - 1s - loss: 0.1068 - accuracy: 0.9564\n",
      "Epoch 417/1000\n",
      "350/350 - 1s - loss: 0.1065 - accuracy: 0.9556\n",
      "Epoch 418/1000\n",
      "350/350 - 1s - loss: 0.1084 - accuracy: 0.9557\n",
      "Epoch 419/1000\n",
      "350/350 - 1s - loss: 0.1071 - accuracy: 0.9543\n",
      "Epoch 420/1000\n",
      "350/350 - 1s - loss: 0.1036 - accuracy: 0.9565\n",
      "Epoch 421/1000\n",
      "350/350 - 1s - loss: 0.1049 - accuracy: 0.9560\n",
      "Epoch 422/1000\n",
      "350/350 - 1s - loss: 0.1086 - accuracy: 0.9536\n",
      "Epoch 423/1000\n",
      "350/350 - 1s - loss: 0.1039 - accuracy: 0.9558\n",
      "Epoch 424/1000\n",
      "350/350 - 1s - loss: 0.1052 - accuracy: 0.9567\n",
      "Epoch 425/1000\n",
      "350/350 - 1s - loss: 0.1052 - accuracy: 0.9563\n",
      "Epoch 426/1000\n",
      "350/350 - 1s - loss: 0.1050 - accuracy: 0.9555\n",
      "Epoch 427/1000\n",
      "350/350 - 1s - loss: 0.1046 - accuracy: 0.9562\n",
      "Epoch 428/1000\n",
      "350/350 - 1s - loss: 0.1040 - accuracy: 0.9554\n",
      "Epoch 429/1000\n",
      "350/350 - 0s - loss: 0.1029 - accuracy: 0.9571\n",
      "Epoch 430/1000\n",
      "350/350 - 1s - loss: 0.1003 - accuracy: 0.9580\n",
      "Epoch 431/1000\n",
      "350/350 - 1s - loss: 0.1000 - accuracy: 0.9578\n",
      "Epoch 432/1000\n",
      "350/350 - 1s - loss: 0.1108 - accuracy: 0.9545\n",
      "Epoch 433/1000\n",
      "350/350 - 1s - loss: 0.1071 - accuracy: 0.9558\n",
      "Epoch 434/1000\n",
      "350/350 - 1s - loss: 0.1025 - accuracy: 0.9579\n",
      "Epoch 435/1000\n",
      "350/350 - 1s - loss: 0.1019 - accuracy: 0.9576\n",
      "Epoch 436/1000\n",
      "350/350 - 1s - loss: 0.1030 - accuracy: 0.9562\n",
      "Epoch 437/1000\n",
      "350/350 - 1s - loss: 0.1002 - accuracy: 0.9570\n",
      "Epoch 438/1000\n",
      "350/350 - 1s - loss: 0.1002 - accuracy: 0.9568\n",
      "Epoch 439/1000\n",
      "350/350 - 1s - loss: 0.1003 - accuracy: 0.9583\n",
      "Epoch 440/1000\n",
      "350/350 - 1s - loss: 0.1039 - accuracy: 0.9554\n",
      "Epoch 441/1000\n",
      "350/350 - 1s - loss: 0.0979 - accuracy: 0.9586\n",
      "Epoch 442/1000\n",
      "350/350 - 1s - loss: 0.1030 - accuracy: 0.9576\n",
      "Epoch 443/1000\n",
      "350/350 - 1s - loss: 0.1038 - accuracy: 0.9572\n",
      "Epoch 444/1000\n",
      "350/350 - 1s - loss: 0.1000 - accuracy: 0.9560\n",
      "Epoch 445/1000\n",
      "350/350 - 1s - loss: 0.1031 - accuracy: 0.9558\n",
      "Epoch 446/1000\n",
      "350/350 - 1s - loss: 0.1036 - accuracy: 0.9561\n",
      "Epoch 447/1000\n",
      "350/350 - 1s - loss: 0.1054 - accuracy: 0.9536\n",
      "Epoch 448/1000\n",
      "350/350 - 1s - loss: 0.1028 - accuracy: 0.9562\n",
      "Epoch 449/1000\n",
      "350/350 - 1s - loss: 0.1026 - accuracy: 0.9559\n",
      "Epoch 450/1000\n",
      "350/350 - 1s - loss: 0.1030 - accuracy: 0.9555\n",
      "Epoch 451/1000\n",
      "350/350 - 1s - loss: 0.0993 - accuracy: 0.9568\n",
      "Epoch 452/1000\n",
      "350/350 - 0s - loss: 0.1001 - accuracy: 0.9563\n",
      "Epoch 453/1000\n",
      "350/350 - 1s - loss: 0.1083 - accuracy: 0.9539\n",
      "Epoch 454/1000\n",
      "350/350 - 0s - loss: 0.0968 - accuracy: 0.9593\n",
      "Epoch 455/1000\n",
      "350/350 - 1s - loss: 0.0984 - accuracy: 0.9586\n",
      "Epoch 456/1000\n",
      "350/350 - 1s - loss: 0.1030 - accuracy: 0.9558\n",
      "Epoch 457/1000\n",
      "350/350 - 1s - loss: 0.1035 - accuracy: 0.9570\n",
      "Epoch 458/1000\n",
      "350/350 - 1s - loss: 0.1019 - accuracy: 0.9568\n",
      "Epoch 459/1000\n",
      "350/350 - 1s - loss: 0.1020 - accuracy: 0.9571\n",
      "Epoch 460/1000\n",
      "350/350 - 1s - loss: 0.0979 - accuracy: 0.9557\n",
      "Epoch 461/1000\n",
      "350/350 - 1s - loss: 0.0978 - accuracy: 0.9596\n",
      "Epoch 462/1000\n",
      "350/350 - 1s - loss: 0.1000 - accuracy: 0.9579\n",
      "Epoch 463/1000\n",
      "350/350 - 1s - loss: 0.1034 - accuracy: 0.9550\n",
      "Epoch 464/1000\n",
      "350/350 - 1s - loss: 0.1005 - accuracy: 0.9581\n",
      "Epoch 465/1000\n",
      "350/350 - 1s - loss: 0.1020 - accuracy: 0.9565\n",
      "Epoch 466/1000\n",
      "350/350 - 1s - loss: 0.1015 - accuracy: 0.9567\n",
      "Epoch 467/1000\n",
      "350/350 - 1s - loss: 0.1009 - accuracy: 0.9561\n",
      "Epoch 468/1000\n",
      "350/350 - 1s - loss: 0.0991 - accuracy: 0.9582\n",
      "Epoch 469/1000\n",
      "350/350 - 1s - loss: 0.0992 - accuracy: 0.9576\n",
      "Epoch 470/1000\n",
      "350/350 - 1s - loss: 0.0991 - accuracy: 0.9570\n",
      "Epoch 471/1000\n",
      "350/350 - 1s - loss: 0.1029 - accuracy: 0.9545\n",
      "Epoch 472/1000\n",
      "350/350 - 0s - loss: 0.1030 - accuracy: 0.9571\n",
      "Epoch 473/1000\n",
      "350/350 - 1s - loss: 0.0993 - accuracy: 0.9569\n",
      "Epoch 474/1000\n",
      "350/350 - 1s - loss: 0.0976 - accuracy: 0.9568\n",
      "Epoch 475/1000\n",
      "350/350 - 1s - loss: 0.0990 - accuracy: 0.9588\n",
      "Epoch 476/1000\n",
      "350/350 - 0s - loss: 0.1012 - accuracy: 0.9584\n",
      "Epoch 477/1000\n",
      "350/350 - 1s - loss: 0.0974 - accuracy: 0.9595\n",
      "Epoch 478/1000\n",
      "350/350 - 1s - loss: 0.0967 - accuracy: 0.9597\n",
      "Epoch 479/1000\n",
      "350/350 - 1s - loss: 0.0988 - accuracy: 0.9587\n",
      "Epoch 480/1000\n",
      "350/350 - 1s - loss: 0.0973 - accuracy: 0.9580\n",
      "Epoch 481/1000\n",
      "350/350 - 1s - loss: 0.1012 - accuracy: 0.9573\n",
      "Epoch 482/1000\n",
      "350/350 - 1s - loss: 0.0982 - accuracy: 0.9573\n",
      "Epoch 483/1000\n",
      "350/350 - 1s - loss: 0.1020 - accuracy: 0.9562\n",
      "Epoch 484/1000\n",
      "350/350 - 1s - loss: 0.0989 - accuracy: 0.9557\n",
      "Epoch 485/1000\n",
      "350/350 - 1s - loss: 0.0955 - accuracy: 0.9576\n",
      "Epoch 486/1000\n",
      "350/350 - 1s - loss: 0.0950 - accuracy: 0.9588\n",
      "Epoch 487/1000\n",
      "350/350 - 1s - loss: 0.0970 - accuracy: 0.9591\n",
      "Epoch 488/1000\n",
      "350/350 - 1s - loss: 0.1006 - accuracy: 0.9565\n",
      "Epoch 489/1000\n",
      "350/350 - 1s - loss: 0.0978 - accuracy: 0.9562\n",
      "Epoch 490/1000\n",
      "350/350 - 0s - loss: 0.0994 - accuracy: 0.9567\n",
      "Epoch 491/1000\n",
      "350/350 - 1s - loss: 0.1017 - accuracy: 0.9571\n",
      "Epoch 492/1000\n",
      "350/350 - 0s - loss: 0.0950 - accuracy: 0.9585\n",
      "Epoch 493/1000\n",
      "350/350 - 0s - loss: 0.0971 - accuracy: 0.9577\n",
      "Epoch 494/1000\n",
      "350/350 - 0s - loss: 0.0974 - accuracy: 0.9566\n",
      "Epoch 495/1000\n",
      "350/350 - 1s - loss: 0.0958 - accuracy: 0.9570\n",
      "Epoch 496/1000\n",
      "350/350 - 1s - loss: 0.0966 - accuracy: 0.9581\n",
      "Epoch 497/1000\n",
      "350/350 - 1s - loss: 0.0997 - accuracy: 0.9567\n",
      "Epoch 498/1000\n",
      "350/350 - 0s - loss: 0.0988 - accuracy: 0.9582\n",
      "Epoch 499/1000\n",
      "350/350 - 1s - loss: 0.0959 - accuracy: 0.9587\n",
      "Epoch 500/1000\n",
      "350/350 - 1s - loss: 0.0963 - accuracy: 0.9579\n",
      "Epoch 501/1000\n",
      "350/350 - 1s - loss: 0.0986 - accuracy: 0.9561\n",
      "Epoch 502/1000\n",
      "350/350 - 1s - loss: 0.0948 - accuracy: 0.9596\n",
      "Epoch 503/1000\n",
      "350/350 - 1s - loss: 0.0958 - accuracy: 0.9571\n",
      "Epoch 504/1000\n",
      "350/350 - 1s - loss: 0.1001 - accuracy: 0.9574\n",
      "Epoch 505/1000\n",
      "350/350 - 1s - loss: 0.0974 - accuracy: 0.9570\n",
      "Epoch 506/1000\n",
      "350/350 - 1s - loss: 0.0969 - accuracy: 0.9575\n",
      "Epoch 507/1000\n",
      "350/350 - 1s - loss: 0.0945 - accuracy: 0.9588\n",
      "Epoch 508/1000\n",
      "350/350 - 1s - loss: 0.0964 - accuracy: 0.9584\n",
      "Epoch 509/1000\n",
      "350/350 - 1s - loss: 0.1029 - accuracy: 0.9558\n",
      "Epoch 510/1000\n",
      "350/350 - 1s - loss: 0.0980 - accuracy: 0.9578\n",
      "Epoch 511/1000\n",
      "350/350 - 1s - loss: 0.0955 - accuracy: 0.9590\n",
      "Epoch 512/1000\n",
      "350/350 - 1s - loss: 0.0947 - accuracy: 0.9586\n",
      "Epoch 513/1000\n",
      "350/350 - 1s - loss: 0.0953 - accuracy: 0.9583\n",
      "Epoch 514/1000\n",
      "350/350 - 1s - loss: 0.0952 - accuracy: 0.9588\n",
      "Epoch 515/1000\n",
      "350/350 - 1s - loss: 0.1001 - accuracy: 0.9574\n",
      "Epoch 516/1000\n",
      "350/350 - 1s - loss: 0.0963 - accuracy: 0.9579\n",
      "Epoch 517/1000\n",
      "350/350 - 1s - loss: 0.0946 - accuracy: 0.9596\n",
      "Epoch 518/1000\n",
      "350/350 - 1s - loss: 0.0983 - accuracy: 0.9583\n",
      "Epoch 519/1000\n",
      "350/350 - 1s - loss: 0.0971 - accuracy: 0.9579\n",
      "Epoch 520/1000\n",
      "350/350 - 1s - loss: 0.0985 - accuracy: 0.9579\n",
      "Epoch 521/1000\n",
      "350/350 - 1s - loss: 0.0923 - accuracy: 0.9596\n",
      "Epoch 522/1000\n",
      "350/350 - 1s - loss: 0.0939 - accuracy: 0.9588\n",
      "Epoch 523/1000\n",
      "350/350 - 1s - loss: 0.0938 - accuracy: 0.9586\n",
      "Epoch 524/1000\n",
      "350/350 - 1s - loss: 0.0955 - accuracy: 0.9593\n",
      "Epoch 525/1000\n",
      "350/350 - 1s - loss: 0.0946 - accuracy: 0.9588\n",
      "Epoch 526/1000\n",
      "350/350 - 1s - loss: 0.0945 - accuracy: 0.9598\n",
      "Epoch 527/1000\n",
      "350/350 - 1s - loss: 0.0936 - accuracy: 0.9591\n",
      "Epoch 528/1000\n",
      "350/350 - 1s - loss: 0.0933 - accuracy: 0.9594\n",
      "Epoch 529/1000\n",
      "350/350 - 0s - loss: 0.0961 - accuracy: 0.9587\n",
      "Epoch 530/1000\n",
      "350/350 - 1s - loss: 0.0946 - accuracy: 0.9600\n",
      "Epoch 531/1000\n",
      "350/350 - 1s - loss: 0.0963 - accuracy: 0.9595\n",
      "Epoch 532/1000\n",
      "350/350 - 1s - loss: 0.0968 - accuracy: 0.9575\n",
      "Epoch 533/1000\n",
      "350/350 - 1s - loss: 0.0935 - accuracy: 0.9593\n",
      "Epoch 534/1000\n",
      "350/350 - 1s - loss: 0.1000 - accuracy: 0.9567\n",
      "Epoch 535/1000\n",
      "350/350 - 1s - loss: 0.0937 - accuracy: 0.9591\n",
      "Epoch 536/1000\n",
      "350/350 - 1s - loss: 0.0909 - accuracy: 0.9581\n",
      "Epoch 537/1000\n",
      "350/350 - 1s - loss: 0.0981 - accuracy: 0.9579\n",
      "Epoch 538/1000\n",
      "350/350 - 1s - loss: 0.0932 - accuracy: 0.9600\n",
      "Epoch 539/1000\n",
      "350/350 - 0s - loss: 0.0931 - accuracy: 0.9595\n",
      "Epoch 540/1000\n",
      "350/350 - 0s - loss: 0.0923 - accuracy: 0.9588\n",
      "Epoch 541/1000\n",
      "350/350 - 0s - loss: 0.0937 - accuracy: 0.9588\n",
      "Epoch 542/1000\n",
      "350/350 - 1s - loss: 0.0926 - accuracy: 0.9602\n",
      "Epoch 543/1000\n",
      "350/350 - 1s - loss: 0.0967 - accuracy: 0.9589\n",
      "Epoch 544/1000\n",
      "350/350 - 0s - loss: 0.0923 - accuracy: 0.9586\n",
      "Epoch 545/1000\n",
      "350/350 - 1s - loss: 0.0910 - accuracy: 0.9592\n",
      "Epoch 546/1000\n",
      "350/350 - 1s - loss: 0.0917 - accuracy: 0.9594\n",
      "Epoch 547/1000\n",
      "350/350 - 1s - loss: 0.0926 - accuracy: 0.9597\n",
      "Epoch 548/1000\n",
      "350/350 - 0s - loss: 0.0934 - accuracy: 0.9596\n",
      "Epoch 549/1000\n",
      "350/350 - 0s - loss: 0.0916 - accuracy: 0.9600\n",
      "Epoch 550/1000\n",
      "350/350 - 0s - loss: 0.0944 - accuracy: 0.9593\n",
      "Epoch 551/1000\n",
      "350/350 - 1s - loss: 0.0961 - accuracy: 0.9595\n",
      "Epoch 552/1000\n",
      "350/350 - 1s - loss: 0.0932 - accuracy: 0.9608\n",
      "Epoch 553/1000\n",
      "350/350 - 1s - loss: 0.0930 - accuracy: 0.9588\n",
      "Epoch 554/1000\n",
      "350/350 - 1s - loss: 0.0897 - accuracy: 0.9603\n",
      "Epoch 555/1000\n",
      "350/350 - 1s - loss: 0.0936 - accuracy: 0.9578\n",
      "Epoch 556/1000\n",
      "350/350 - 1s - loss: 0.0910 - accuracy: 0.9598\n",
      "Epoch 557/1000\n",
      "350/350 - 0s - loss: 0.0928 - accuracy: 0.9589\n",
      "Epoch 558/1000\n",
      "350/350 - 1s - loss: 0.0886 - accuracy: 0.9594\n",
      "Epoch 559/1000\n",
      "350/350 - 1s - loss: 0.0911 - accuracy: 0.9605\n",
      "Epoch 560/1000\n",
      "350/350 - 1s - loss: 0.0956 - accuracy: 0.9591\n",
      "Epoch 561/1000\n",
      "350/350 - 1s - loss: 0.0948 - accuracy: 0.9579\n",
      "Epoch 562/1000\n",
      "350/350 - 1s - loss: 0.0907 - accuracy: 0.9591\n",
      "Epoch 563/1000\n",
      "350/350 - 1s - loss: 0.0943 - accuracy: 0.9578\n",
      "Epoch 564/1000\n",
      "350/350 - 1s - loss: 0.0955 - accuracy: 0.9577\n",
      "Epoch 565/1000\n",
      "350/350 - 1s - loss: 0.0962 - accuracy: 0.9589\n",
      "Epoch 566/1000\n",
      "350/350 - 1s - loss: 0.0898 - accuracy: 0.9609\n",
      "Epoch 567/1000\n",
      "350/350 - 1s - loss: 0.0896 - accuracy: 0.9604\n",
      "Epoch 568/1000\n",
      "350/350 - 1s - loss: 0.0898 - accuracy: 0.9607\n",
      "Epoch 569/1000\n",
      "350/350 - 1s - loss: 0.0913 - accuracy: 0.9597\n",
      "Epoch 570/1000\n",
      "350/350 - 1s - loss: 0.0922 - accuracy: 0.9598\n",
      "Epoch 571/1000\n",
      "350/350 - 1s - loss: 0.0937 - accuracy: 0.9595\n",
      "Epoch 572/1000\n",
      "350/350 - 1s - loss: 0.0947 - accuracy: 0.9587\n",
      "Epoch 573/1000\n",
      "350/350 - 1s - loss: 0.0908 - accuracy: 0.9614\n",
      "Epoch 574/1000\n",
      "350/350 - 1s - loss: 0.0902 - accuracy: 0.9601\n",
      "Epoch 575/1000\n",
      "350/350 - 1s - loss: 0.0918 - accuracy: 0.9592\n",
      "Epoch 576/1000\n",
      "350/350 - 1s - loss: 0.0889 - accuracy: 0.9602\n",
      "Epoch 577/1000\n",
      "350/350 - 1s - loss: 0.0937 - accuracy: 0.9584\n",
      "Epoch 578/1000\n",
      "350/350 - 1s - loss: 0.0908 - accuracy: 0.9596\n",
      "Epoch 579/1000\n",
      "350/350 - 1s - loss: 0.0897 - accuracy: 0.9608\n",
      "Epoch 580/1000\n",
      "350/350 - 1s - loss: 0.0958 - accuracy: 0.9582\n",
      "Epoch 581/1000\n",
      "350/350 - 1s - loss: 0.0943 - accuracy: 0.9584\n",
      "Epoch 582/1000\n",
      "350/350 - 0s - loss: 0.0907 - accuracy: 0.9612\n",
      "Epoch 583/1000\n",
      "350/350 - 1s - loss: 0.0914 - accuracy: 0.9596\n",
      "Epoch 584/1000\n",
      "350/350 - 1s - loss: 0.0930 - accuracy: 0.9599\n",
      "Epoch 585/1000\n",
      "350/350 - 1s - loss: 0.0925 - accuracy: 0.9613\n",
      "Epoch 586/1000\n",
      "350/350 - 1s - loss: 0.0903 - accuracy: 0.9587\n",
      "Epoch 587/1000\n",
      "350/350 - 1s - loss: 0.0940 - accuracy: 0.9586\n",
      "Epoch 588/1000\n",
      "350/350 - 1s - loss: 0.0921 - accuracy: 0.9591\n",
      "Epoch 589/1000\n",
      "350/350 - 1s - loss: 0.0896 - accuracy: 0.9601\n",
      "Epoch 590/1000\n",
      "350/350 - 1s - loss: 0.0896 - accuracy: 0.9621\n",
      "Epoch 591/1000\n",
      "350/350 - 1s - loss: 0.0913 - accuracy: 0.9599\n",
      "Epoch 592/1000\n",
      "350/350 - 1s - loss: 0.0922 - accuracy: 0.9594\n",
      "Epoch 593/1000\n",
      "350/350 - 0s - loss: 0.0928 - accuracy: 0.9588\n",
      "Epoch 594/1000\n",
      "350/350 - 0s - loss: 0.0922 - accuracy: 0.9594\n",
      "Epoch 595/1000\n",
      "350/350 - 1s - loss: 0.0914 - accuracy: 0.9605\n",
      "Epoch 596/1000\n",
      "350/350 - 1s - loss: 0.0881 - accuracy: 0.9606\n",
      "Epoch 597/1000\n",
      "350/350 - 1s - loss: 0.0897 - accuracy: 0.9604\n",
      "Epoch 598/1000\n",
      "350/350 - 1s - loss: 0.0900 - accuracy: 0.9605\n",
      "Epoch 599/1000\n",
      "350/350 - 1s - loss: 0.0896 - accuracy: 0.9613\n",
      "Epoch 600/1000\n",
      "350/350 - 1s - loss: 0.0877 - accuracy: 0.9595\n",
      "Epoch 601/1000\n",
      "350/350 - 1s - loss: 0.0899 - accuracy: 0.9603\n",
      "Epoch 602/1000\n",
      "350/350 - 1s - loss: 0.0895 - accuracy: 0.9612\n",
      "Epoch 603/1000\n",
      "350/350 - 1s - loss: 0.0955 - accuracy: 0.9596\n",
      "Epoch 604/1000\n",
      "350/350 - 1s - loss: 0.0888 - accuracy: 0.9613\n",
      "Epoch 605/1000\n",
      "350/350 - 1s - loss: 0.0946 - accuracy: 0.9584\n",
      "Epoch 606/1000\n",
      "350/350 - 1s - loss: 0.0910 - accuracy: 0.9595\n",
      "Epoch 607/1000\n",
      "350/350 - 1s - loss: 0.0873 - accuracy: 0.9615\n",
      "Epoch 608/1000\n",
      "350/350 - 1s - loss: 0.0894 - accuracy: 0.9592\n",
      "Epoch 609/1000\n",
      "350/350 - 1s - loss: 0.0895 - accuracy: 0.9588\n",
      "Epoch 610/1000\n",
      "350/350 - 1s - loss: 0.0893 - accuracy: 0.9590\n",
      "Epoch 611/1000\n",
      "350/350 - 1s - loss: 0.0884 - accuracy: 0.9597\n",
      "Epoch 612/1000\n",
      "350/350 - 1s - loss: 0.0860 - accuracy: 0.9613\n",
      "Epoch 613/1000\n",
      "350/350 - 1s - loss: 0.0874 - accuracy: 0.9614\n",
      "Epoch 614/1000\n",
      "350/350 - 1s - loss: 0.0876 - accuracy: 0.9605\n",
      "Epoch 615/1000\n",
      "350/350 - 1s - loss: 0.0954 - accuracy: 0.9600\n",
      "Epoch 616/1000\n",
      "350/350 - 1s - loss: 0.0944 - accuracy: 0.9590\n",
      "Epoch 617/1000\n",
      "350/350 - 1s - loss: 0.0880 - accuracy: 0.9608\n",
      "Epoch 618/1000\n",
      "350/350 - 1s - loss: 0.0872 - accuracy: 0.9617\n",
      "Epoch 619/1000\n",
      "350/350 - 1s - loss: 0.0929 - accuracy: 0.9603\n",
      "Epoch 620/1000\n",
      "350/350 - 1s - loss: 0.0883 - accuracy: 0.9600\n",
      "Epoch 621/1000\n",
      "350/350 - 1s - loss: 0.0920 - accuracy: 0.9604\n",
      "Epoch 622/1000\n",
      "350/350 - 1s - loss: 0.0877 - accuracy: 0.9616\n",
      "Epoch 623/1000\n",
      "350/350 - 1s - loss: 0.0901 - accuracy: 0.9597\n",
      "Epoch 624/1000\n",
      "350/350 - 1s - loss: 0.0885 - accuracy: 0.9608\n",
      "Epoch 625/1000\n",
      "350/350 - 1s - loss: 0.0875 - accuracy: 0.9613\n",
      "Epoch 626/1000\n",
      "350/350 - 1s - loss: 0.0871 - accuracy: 0.9609\n",
      "Epoch 627/1000\n",
      "350/350 - 1s - loss: 0.0883 - accuracy: 0.9613\n",
      "Epoch 628/1000\n",
      "350/350 - 1s - loss: 0.0880 - accuracy: 0.9630\n",
      "Epoch 629/1000\n",
      "350/350 - 1s - loss: 0.0912 - accuracy: 0.9584\n",
      "Epoch 630/1000\n",
      "350/350 - 1s - loss: 0.0864 - accuracy: 0.9615\n",
      "Epoch 631/1000\n",
      "350/350 - 1s - loss: 0.0896 - accuracy: 0.9605\n",
      "Epoch 632/1000\n",
      "350/350 - 1s - loss: 0.0871 - accuracy: 0.9620\n",
      "Epoch 633/1000\n",
      "350/350 - 1s - loss: 0.0917 - accuracy: 0.9592\n",
      "Epoch 634/1000\n",
      "350/350 - 1s - loss: 0.0880 - accuracy: 0.9614\n",
      "Epoch 635/1000\n",
      "350/350 - 1s - loss: 0.0932 - accuracy: 0.9598\n",
      "Epoch 636/1000\n",
      "350/350 - 1s - loss: 0.0854 - accuracy: 0.9615\n",
      "Epoch 637/1000\n",
      "350/350 - 1s - loss: 0.0860 - accuracy: 0.9605\n",
      "Epoch 638/1000\n",
      "350/350 - 1s - loss: 0.0957 - accuracy: 0.9583\n",
      "Epoch 639/1000\n",
      "350/350 - 1s - loss: 0.0887 - accuracy: 0.9605\n",
      "Epoch 640/1000\n",
      "350/350 - 1s - loss: 0.0880 - accuracy: 0.9628\n",
      "Epoch 641/1000\n",
      "350/350 - 1s - loss: 0.0891 - accuracy: 0.9609\n",
      "Epoch 642/1000\n",
      "350/350 - 1s - loss: 0.0834 - accuracy: 0.9613\n",
      "Epoch 643/1000\n",
      "350/350 - 1s - loss: 0.0869 - accuracy: 0.9621\n",
      "Epoch 644/1000\n",
      "350/350 - 1s - loss: 0.0872 - accuracy: 0.9599\n",
      "Epoch 645/1000\n",
      "350/350 - 1s - loss: 0.0893 - accuracy: 0.9610\n",
      "Epoch 646/1000\n",
      "350/350 - 1s - loss: 0.0880 - accuracy: 0.9613\n",
      "Epoch 647/1000\n",
      "350/350 - 1s - loss: 0.0873 - accuracy: 0.9616\n",
      "Epoch 648/1000\n",
      "350/350 - 1s - loss: 0.0879 - accuracy: 0.9602\n",
      "Epoch 649/1000\n",
      "350/350 - 1s - loss: 0.0866 - accuracy: 0.9613\n",
      "Epoch 650/1000\n",
      "350/350 - 1s - loss: 0.0884 - accuracy: 0.9624\n",
      "Epoch 651/1000\n",
      "350/350 - 1s - loss: 0.0844 - accuracy: 0.9619\n",
      "Epoch 652/1000\n",
      "350/350 - 1s - loss: 0.0885 - accuracy: 0.9603\n",
      "Epoch 653/1000\n",
      "350/350 - 1s - loss: 0.0912 - accuracy: 0.9583\n",
      "Epoch 654/1000\n",
      "350/350 - 1s - loss: 0.0907 - accuracy: 0.9601\n",
      "Epoch 655/1000\n",
      "350/350 - 1s - loss: 0.0873 - accuracy: 0.9610\n",
      "Epoch 656/1000\n",
      "350/350 - 1s - loss: 0.0852 - accuracy: 0.9623\n",
      "Epoch 657/1000\n",
      "350/350 - 0s - loss: 0.0932 - accuracy: 0.9611\n",
      "Epoch 658/1000\n",
      "350/350 - 0s - loss: 0.0849 - accuracy: 0.9615\n",
      "Epoch 659/1000\n",
      "350/350 - 0s - loss: 0.0894 - accuracy: 0.9601\n",
      "Epoch 660/1000\n",
      "350/350 - 1s - loss: 0.0881 - accuracy: 0.9606\n",
      "Epoch 661/1000\n",
      "350/350 - 0s - loss: 0.0832 - accuracy: 0.9622\n",
      "Epoch 662/1000\n",
      "350/350 - 0s - loss: 0.0866 - accuracy: 0.9612\n",
      "Epoch 663/1000\n",
      "350/350 - 0s - loss: 0.0854 - accuracy: 0.9616\n",
      "Epoch 664/1000\n",
      "350/350 - 1s - loss: 0.0893 - accuracy: 0.9617\n",
      "Epoch 665/1000\n",
      "350/350 - 1s - loss: 0.0885 - accuracy: 0.9597\n",
      "Epoch 666/1000\n",
      "350/350 - 1s - loss: 0.0893 - accuracy: 0.9609\n",
      "Epoch 667/1000\n",
      "350/350 - 1s - loss: 0.0878 - accuracy: 0.9609\n",
      "Epoch 668/1000\n",
      "350/350 - 0s - loss: 0.0888 - accuracy: 0.9594\n",
      "Epoch 669/1000\n",
      "350/350 - 0s - loss: 0.0861 - accuracy: 0.9617\n",
      "Epoch 670/1000\n",
      "350/350 - 0s - loss: 0.0906 - accuracy: 0.9619\n",
      "Epoch 671/1000\n",
      "350/350 - 1s - loss: 0.0894 - accuracy: 0.9622\n",
      "Epoch 672/1000\n",
      "350/350 - 1s - loss: 0.0916 - accuracy: 0.9588\n",
      "Epoch 673/1000\n",
      "350/350 - 0s - loss: 0.0824 - accuracy: 0.9622\n",
      "Epoch 674/1000\n",
      "350/350 - 0s - loss: 0.0854 - accuracy: 0.9605\n",
      "Epoch 675/1000\n",
      "350/350 - 0s - loss: 0.0858 - accuracy: 0.9609\n",
      "Epoch 676/1000\n",
      "350/350 - 0s - loss: 0.0863 - accuracy: 0.9613\n",
      "Epoch 677/1000\n",
      "350/350 - 1s - loss: 0.0866 - accuracy: 0.9612\n",
      "Epoch 678/1000\n",
      "350/350 - 0s - loss: 0.0882 - accuracy: 0.9610\n",
      "Epoch 679/1000\n",
      "350/350 - 1s - loss: 0.0873 - accuracy: 0.9609\n",
      "Epoch 680/1000\n",
      "350/350 - 0s - loss: 0.0873 - accuracy: 0.9607\n",
      "Epoch 681/1000\n",
      "350/350 - 1s - loss: 0.0842 - accuracy: 0.9616\n",
      "Epoch 682/1000\n",
      "350/350 - 0s - loss: 0.0853 - accuracy: 0.9607\n",
      "Epoch 683/1000\n",
      "350/350 - 0s - loss: 0.0914 - accuracy: 0.9578\n",
      "Epoch 684/1000\n",
      "350/350 - 0s - loss: 0.0865 - accuracy: 0.9622\n",
      "Epoch 685/1000\n",
      "350/350 - 1s - loss: 0.0859 - accuracy: 0.9606\n",
      "Epoch 686/1000\n",
      "350/350 - 0s - loss: 0.0867 - accuracy: 0.9609\n",
      "Epoch 687/1000\n",
      "350/350 - 1s - loss: 0.0860 - accuracy: 0.9598\n",
      "Epoch 688/1000\n",
      "350/350 - 1s - loss: 0.0836 - accuracy: 0.9602\n",
      "Epoch 689/1000\n",
      "350/350 - 0s - loss: 0.0896 - accuracy: 0.9601\n",
      "Epoch 690/1000\n",
      "350/350 - 0s - loss: 0.0864 - accuracy: 0.9599\n",
      "Epoch 691/1000\n",
      "350/350 - 1s - loss: 0.0869 - accuracy: 0.9608\n",
      "Epoch 692/1000\n",
      "350/350 - 0s - loss: 0.0855 - accuracy: 0.9604\n",
      "Epoch 693/1000\n",
      "350/350 - 0s - loss: 0.0873 - accuracy: 0.9604\n",
      "Epoch 694/1000\n",
      "350/350 - 0s - loss: 0.0879 - accuracy: 0.9613\n",
      "Epoch 695/1000\n",
      "350/350 - 1s - loss: 0.0816 - accuracy: 0.9635\n",
      "Epoch 696/1000\n",
      "350/350 - 1s - loss: 0.0839 - accuracy: 0.9623\n",
      "Epoch 697/1000\n",
      "350/350 - 1s - loss: 0.0862 - accuracy: 0.9618\n",
      "Epoch 698/1000\n",
      "350/350 - 0s - loss: 0.0894 - accuracy: 0.9613\n",
      "Epoch 699/1000\n",
      "350/350 - 1s - loss: 0.0870 - accuracy: 0.9616\n",
      "Epoch 700/1000\n",
      "350/350 - 1s - loss: 0.0855 - accuracy: 0.9601\n",
      "Epoch 701/1000\n",
      "350/350 - 1s - loss: 0.0846 - accuracy: 0.9615\n",
      "Epoch 702/1000\n",
      "350/350 - 1s - loss: 0.0901 - accuracy: 0.9600\n",
      "Epoch 703/1000\n",
      "350/350 - 1s - loss: 0.0885 - accuracy: 0.9616\n",
      "Epoch 704/1000\n",
      "350/350 - 1s - loss: 0.0852 - accuracy: 0.9616\n",
      "Epoch 705/1000\n",
      "350/350 - 1s - loss: 0.0861 - accuracy: 0.9622\n",
      "Epoch 706/1000\n",
      "350/350 - 1s - loss: 0.0843 - accuracy: 0.9610\n",
      "Epoch 707/1000\n",
      "350/350 - 0s - loss: 0.0834 - accuracy: 0.9636\n",
      "Epoch 708/1000\n",
      "350/350 - 0s - loss: 0.0852 - accuracy: 0.9597\n",
      "Epoch 709/1000\n",
      "350/350 - 0s - loss: 0.0853 - accuracy: 0.9605\n",
      "Epoch 710/1000\n",
      "350/350 - 0s - loss: 0.0866 - accuracy: 0.9607\n",
      "Epoch 711/1000\n",
      "350/350 - 0s - loss: 0.0838 - accuracy: 0.9617\n",
      "Epoch 712/1000\n",
      "350/350 - 0s - loss: 0.0874 - accuracy: 0.9616\n",
      "Epoch 713/1000\n",
      "350/350 - 1s - loss: 0.0877 - accuracy: 0.9620\n",
      "Epoch 714/1000\n",
      "350/350 - 1s - loss: 0.0859 - accuracy: 0.9606\n",
      "Epoch 715/1000\n",
      "350/350 - 0s - loss: 0.0844 - accuracy: 0.9617\n",
      "Epoch 716/1000\n",
      "350/350 - 1s - loss: 0.0832 - accuracy: 0.9620\n",
      "Epoch 717/1000\n",
      "350/350 - 1s - loss: 0.0855 - accuracy: 0.9614\n",
      "Epoch 718/1000\n",
      "350/350 - 1s - loss: 0.0838 - accuracy: 0.9614\n",
      "Epoch 719/1000\n",
      "350/350 - 0s - loss: 0.0879 - accuracy: 0.9602\n",
      "Epoch 720/1000\n",
      "350/350 - 1s - loss: 0.0882 - accuracy: 0.9582\n",
      "Epoch 721/1000\n",
      "350/350 - 1s - loss: 0.0824 - accuracy: 0.9635\n",
      "Epoch 722/1000\n",
      "350/350 - 1s - loss: 0.0847 - accuracy: 0.9625\n",
      "Epoch 723/1000\n",
      "350/350 - 1s - loss: 0.0878 - accuracy: 0.9610\n",
      "Epoch 724/1000\n",
      "350/350 - 0s - loss: 0.0841 - accuracy: 0.9619\n",
      "Epoch 725/1000\n",
      "350/350 - 0s - loss: 0.0846 - accuracy: 0.9612\n",
      "Epoch 726/1000\n",
      "350/350 - 0s - loss: 0.0871 - accuracy: 0.9620\n",
      "Epoch 727/1000\n",
      "350/350 - 0s - loss: 0.0859 - accuracy: 0.9610\n",
      "Epoch 728/1000\n",
      "350/350 - 0s - loss: 0.0853 - accuracy: 0.9622\n",
      "Epoch 729/1000\n",
      "350/350 - 0s - loss: 0.0834 - accuracy: 0.9614\n",
      "Epoch 730/1000\n",
      "350/350 - 0s - loss: 0.0894 - accuracy: 0.9613\n",
      "Epoch 731/1000\n",
      "350/350 - 0s - loss: 0.0817 - accuracy: 0.9619\n",
      "Epoch 732/1000\n",
      "350/350 - 0s - loss: 0.0874 - accuracy: 0.9609\n",
      "Epoch 733/1000\n",
      "350/350 - 1s - loss: 0.0851 - accuracy: 0.9629\n",
      "Epoch 734/1000\n",
      "350/350 - 1s - loss: 0.0890 - accuracy: 0.9619\n",
      "Epoch 735/1000\n",
      "350/350 - 1s - loss: 0.0850 - accuracy: 0.9616\n",
      "Epoch 736/1000\n",
      "350/350 - 0s - loss: 0.0879 - accuracy: 0.9605\n",
      "Epoch 737/1000\n",
      "350/350 - 0s - loss: 0.0903 - accuracy: 0.9599\n",
      "Epoch 738/1000\n",
      "350/350 - 0s - loss: 0.0827 - accuracy: 0.9625\n",
      "Epoch 739/1000\n",
      "350/350 - 0s - loss: 0.0861 - accuracy: 0.9615\n",
      "Epoch 740/1000\n",
      "350/350 - 0s - loss: 0.0861 - accuracy: 0.9620\n",
      "Epoch 741/1000\n",
      "350/350 - 0s - loss: 0.0858 - accuracy: 0.9611\n",
      "Epoch 742/1000\n",
      "350/350 - 0s - loss: 0.0816 - accuracy: 0.9629\n",
      "Epoch 743/1000\n",
      "350/350 - 0s - loss: 0.0816 - accuracy: 0.9622\n",
      "Epoch 744/1000\n",
      "350/350 - 0s - loss: 0.0866 - accuracy: 0.9614\n",
      "Epoch 745/1000\n",
      "350/350 - 0s - loss: 0.0859 - accuracy: 0.9612\n",
      "Epoch 746/1000\n",
      "350/350 - 0s - loss: 0.0841 - accuracy: 0.9613\n",
      "Epoch 747/1000\n",
      "350/350 - 1s - loss: 0.0883 - accuracy: 0.9611\n",
      "Epoch 748/1000\n",
      "350/350 - 1s - loss: 0.0864 - accuracy: 0.9613\n",
      "Epoch 749/1000\n",
      "350/350 - 1s - loss: 0.0859 - accuracy: 0.9603\n",
      "Epoch 750/1000\n",
      "350/350 - 0s - loss: 0.0847 - accuracy: 0.9620\n",
      "Epoch 751/1000\n",
      "350/350 - 1s - loss: 0.0843 - accuracy: 0.9626\n",
      "Epoch 752/1000\n",
      "350/350 - 0s - loss: 0.0855 - accuracy: 0.9627\n",
      "Epoch 753/1000\n",
      "350/350 - 0s - loss: 0.0820 - accuracy: 0.9620\n",
      "Epoch 754/1000\n",
      "350/350 - 1s - loss: 0.0867 - accuracy: 0.9619\n",
      "Epoch 755/1000\n",
      "350/350 - 0s - loss: 0.0845 - accuracy: 0.9622\n",
      "Epoch 756/1000\n",
      "350/350 - 0s - loss: 0.0841 - accuracy: 0.9616\n",
      "Epoch 757/1000\n",
      "350/350 - 1s - loss: 0.0845 - accuracy: 0.9613\n",
      "Epoch 758/1000\n",
      "350/350 - 0s - loss: 0.0846 - accuracy: 0.9621\n",
      "Epoch 759/1000\n",
      "350/350 - 0s - loss: 0.0835 - accuracy: 0.9629\n",
      "Epoch 760/1000\n",
      "350/350 - 0s - loss: 0.0834 - accuracy: 0.9620\n",
      "Epoch 761/1000\n",
      "350/350 - 0s - loss: 0.0829 - accuracy: 0.9625\n",
      "Epoch 762/1000\n",
      "350/350 - 0s - loss: 0.0846 - accuracy: 0.9606\n",
      "Epoch 763/1000\n",
      "350/350 - 0s - loss: 0.0829 - accuracy: 0.9619\n",
      "Epoch 764/1000\n",
      "350/350 - 0s - loss: 0.0869 - accuracy: 0.9598\n",
      "Epoch 765/1000\n",
      "350/350 - 0s - loss: 0.0839 - accuracy: 0.9605\n",
      "Epoch 766/1000\n",
      "350/350 - 0s - loss: 0.0805 - accuracy: 0.9627\n",
      "Epoch 767/1000\n",
      "350/350 - 0s - loss: 0.0843 - accuracy: 0.9615\n",
      "Epoch 768/1000\n",
      "350/350 - 0s - loss: 0.0838 - accuracy: 0.9630\n",
      "Epoch 769/1000\n",
      "350/350 - 0s - loss: 0.0841 - accuracy: 0.9616\n",
      "Epoch 770/1000\n",
      "350/350 - 0s - loss: 0.0826 - accuracy: 0.9622\n",
      "Epoch 771/1000\n",
      "350/350 - 1s - loss: 0.0841 - accuracy: 0.9613\n",
      "Epoch 772/1000\n",
      "350/350 - 0s - loss: 0.0788 - accuracy: 0.9623\n",
      "Epoch 773/1000\n",
      "350/350 - 0s - loss: 0.0827 - accuracy: 0.9613\n",
      "Epoch 774/1000\n",
      "350/350 - 0s - loss: 0.0815 - accuracy: 0.9633\n",
      "Epoch 775/1000\n",
      "350/350 - 0s - loss: 0.0830 - accuracy: 0.9618\n",
      "Epoch 776/1000\n",
      "350/350 - 0s - loss: 0.0863 - accuracy: 0.9621\n",
      "Epoch 777/1000\n",
      "350/350 - 0s - loss: 0.0823 - accuracy: 0.9625\n",
      "Epoch 778/1000\n",
      "350/350 - 0s - loss: 0.0836 - accuracy: 0.9619\n",
      "Epoch 779/1000\n",
      "350/350 - 0s - loss: 0.0863 - accuracy: 0.9610\n",
      "Epoch 780/1000\n",
      "350/350 - 0s - loss: 0.0839 - accuracy: 0.9622\n",
      "Epoch 781/1000\n",
      "350/350 - 0s - loss: 0.0840 - accuracy: 0.9611\n",
      "Epoch 782/1000\n",
      "350/350 - 0s - loss: 0.0830 - accuracy: 0.9605\n",
      "Epoch 783/1000\n",
      "350/350 - 0s - loss: 0.0845 - accuracy: 0.9624\n",
      "Epoch 784/1000\n",
      "350/350 - 1s - loss: 0.0807 - accuracy: 0.9628\n",
      "Epoch 785/1000\n",
      "350/350 - 0s - loss: 0.0850 - accuracy: 0.9622\n",
      "Epoch 786/1000\n",
      "350/350 - 0s - loss: 0.0877 - accuracy: 0.9623\n",
      "Epoch 787/1000\n",
      "350/350 - 0s - loss: 0.0825 - accuracy: 0.9632\n",
      "Epoch 788/1000\n",
      "350/350 - 1s - loss: 0.0852 - accuracy: 0.9622\n",
      "Epoch 789/1000\n",
      "350/350 - 0s - loss: 0.0844 - accuracy: 0.9619\n",
      "Epoch 790/1000\n",
      "350/350 - 0s - loss: 0.0861 - accuracy: 0.9628\n",
      "Epoch 791/1000\n",
      "350/350 - 1s - loss: 0.0816 - accuracy: 0.9625\n",
      "Epoch 792/1000\n",
      "350/350 - 0s - loss: 0.0820 - accuracy: 0.9617\n",
      "Epoch 793/1000\n",
      "350/350 - 0s - loss: 0.0817 - accuracy: 0.9629\n",
      "Epoch 794/1000\n",
      "350/350 - 0s - loss: 0.0834 - accuracy: 0.9610\n",
      "Epoch 795/1000\n",
      "350/350 - 0s - loss: 0.0823 - accuracy: 0.9624\n",
      "Epoch 796/1000\n",
      "350/350 - 1s - loss: 0.0821 - accuracy: 0.9631\n",
      "Epoch 797/1000\n",
      "350/350 - 0s - loss: 0.0827 - accuracy: 0.9624\n",
      "Epoch 798/1000\n",
      "350/350 - 0s - loss: 0.0873 - accuracy: 0.9598\n",
      "Epoch 799/1000\n",
      "350/350 - 0s - loss: 0.0849 - accuracy: 0.9610\n",
      "Epoch 800/1000\n",
      "350/350 - 1s - loss: 0.0825 - accuracy: 0.9630\n",
      "Epoch 801/1000\n",
      "350/350 - 0s - loss: 0.0824 - accuracy: 0.9624\n",
      "Epoch 802/1000\n",
      "350/350 - 0s - loss: 0.0819 - accuracy: 0.9619\n",
      "Epoch 803/1000\n",
      "350/350 - 0s - loss: 0.0888 - accuracy: 0.9605\n",
      "Epoch 804/1000\n",
      "350/350 - 0s - loss: 0.0831 - accuracy: 0.9614\n",
      "Epoch 805/1000\n",
      "350/350 - 0s - loss: 0.0854 - accuracy: 0.9613\n",
      "Epoch 806/1000\n",
      "350/350 - 0s - loss: 0.0806 - accuracy: 0.9626\n",
      "Epoch 807/1000\n",
      "350/350 - 1s - loss: 0.0824 - accuracy: 0.9601\n",
      "Epoch 808/1000\n",
      "350/350 - 1s - loss: 0.0787 - accuracy: 0.9641\n",
      "Epoch 809/1000\n",
      "350/350 - 0s - loss: 0.0816 - accuracy: 0.9630\n",
      "Epoch 810/1000\n",
      "350/350 - 0s - loss: 0.0839 - accuracy: 0.9634\n",
      "Epoch 811/1000\n",
      "350/350 - 0s - loss: 0.0836 - accuracy: 0.9610\n",
      "Epoch 812/1000\n",
      "350/350 - 0s - loss: 0.0838 - accuracy: 0.9622\n",
      "Epoch 813/1000\n",
      "350/350 - 0s - loss: 0.0839 - accuracy: 0.9613\n",
      "Epoch 814/1000\n",
      "350/350 - 0s - loss: 0.0835 - accuracy: 0.9616\n",
      "Epoch 815/1000\n",
      "350/350 - 0s - loss: 0.0862 - accuracy: 0.9614\n",
      "Epoch 816/1000\n",
      "350/350 - 0s - loss: 0.0796 - accuracy: 0.9629\n",
      "Epoch 817/1000\n",
      "350/350 - 0s - loss: 0.0793 - accuracy: 0.9633\n",
      "Epoch 818/1000\n",
      "350/350 - 0s - loss: 0.0837 - accuracy: 0.9611\n",
      "Epoch 819/1000\n",
      "350/350 - 0s - loss: 0.0847 - accuracy: 0.9616\n",
      "Epoch 820/1000\n",
      "350/350 - 0s - loss: 0.0838 - accuracy: 0.9614\n",
      "Epoch 821/1000\n",
      "350/350 - 0s - loss: 0.0878 - accuracy: 0.9600\n",
      "Epoch 822/1000\n",
      "350/350 - 0s - loss: 0.0809 - accuracy: 0.9620\n",
      "Epoch 823/1000\n",
      "350/350 - 0s - loss: 0.0849 - accuracy: 0.9623\n",
      "Epoch 824/1000\n",
      "350/350 - 0s - loss: 0.0829 - accuracy: 0.9599\n",
      "Epoch 825/1000\n",
      "350/350 - 0s - loss: 0.0850 - accuracy: 0.9623\n",
      "Epoch 826/1000\n",
      "350/350 - 0s - loss: 0.0818 - accuracy: 0.9633\n",
      "Epoch 827/1000\n",
      "350/350 - 0s - loss: 0.0880 - accuracy: 0.9622\n",
      "Epoch 828/1000\n",
      "350/350 - 0s - loss: 0.0833 - accuracy: 0.9617\n",
      "Epoch 829/1000\n",
      "350/350 - 0s - loss: 0.0863 - accuracy: 0.9617\n",
      "Epoch 830/1000\n",
      "350/350 - 1s - loss: 0.0819 - accuracy: 0.9630\n",
      "Epoch 831/1000\n",
      "350/350 - 0s - loss: 0.0825 - accuracy: 0.9619\n",
      "Epoch 832/1000\n",
      "350/350 - 1s - loss: 0.0811 - accuracy: 0.9625\n",
      "Epoch 833/1000\n",
      "350/350 - 1s - loss: 0.0800 - accuracy: 0.9634\n",
      "Epoch 834/1000\n",
      "350/350 - 0s - loss: 0.0796 - accuracy: 0.9626\n",
      "Epoch 835/1000\n",
      "350/350 - 1s - loss: 0.0803 - accuracy: 0.9624\n",
      "Epoch 836/1000\n",
      "350/350 - 0s - loss: 0.0835 - accuracy: 0.9625\n",
      "Epoch 837/1000\n",
      "350/350 - 0s - loss: 0.0846 - accuracy: 0.9617\n",
      "Epoch 838/1000\n",
      "350/350 - 0s - loss: 0.0861 - accuracy: 0.9611\n",
      "Epoch 839/1000\n",
      "350/350 - 1s - loss: 0.0817 - accuracy: 0.9634\n",
      "Epoch 840/1000\n",
      "350/350 - 0s - loss: 0.0828 - accuracy: 0.9612\n",
      "Epoch 841/1000\n",
      "350/350 - 0s - loss: 0.0817 - accuracy: 0.9623\n",
      "Epoch 842/1000\n",
      "350/350 - 0s - loss: 0.0803 - accuracy: 0.9622\n",
      "Epoch 843/1000\n",
      "350/350 - 0s - loss: 0.0800 - accuracy: 0.9637\n",
      "Epoch 844/1000\n",
      "350/350 - 0s - loss: 0.0810 - accuracy: 0.9627\n",
      "Epoch 845/1000\n",
      "350/350 - 0s - loss: 0.0812 - accuracy: 0.9629\n",
      "Epoch 846/1000\n",
      "350/350 - 0s - loss: 0.0819 - accuracy: 0.9627\n",
      "Epoch 847/1000\n",
      "350/350 - 0s - loss: 0.0860 - accuracy: 0.9617\n",
      "Epoch 848/1000\n",
      "350/350 - 1s - loss: 0.0813 - accuracy: 0.9626\n",
      "Epoch 849/1000\n",
      "350/350 - 1s - loss: 0.0850 - accuracy: 0.9629\n",
      "Epoch 850/1000\n",
      "350/350 - 0s - loss: 0.0856 - accuracy: 0.9609\n",
      "Epoch 851/1000\n",
      "350/350 - 0s - loss: 0.0815 - accuracy: 0.9617\n",
      "Epoch 852/1000\n",
      "350/350 - 0s - loss: 0.0834 - accuracy: 0.9624\n",
      "Epoch 853/1000\n",
      "350/350 - 0s - loss: 0.0832 - accuracy: 0.9616\n",
      "Epoch 854/1000\n",
      "350/350 - 0s - loss: 0.0803 - accuracy: 0.9631\n",
      "Epoch 855/1000\n",
      "350/350 - 0s - loss: 0.0790 - accuracy: 0.9623\n",
      "Epoch 856/1000\n",
      "350/350 - 1s - loss: 0.0815 - accuracy: 0.9624\n",
      "Epoch 857/1000\n",
      "350/350 - 0s - loss: 0.0819 - accuracy: 0.9632\n",
      "Epoch 858/1000\n",
      "350/350 - 1s - loss: 0.0804 - accuracy: 0.9620\n",
      "Epoch 859/1000\n",
      "350/350 - 0s - loss: 0.0849 - accuracy: 0.9624\n",
      "Epoch 860/1000\n",
      "350/350 - 0s - loss: 0.0820 - accuracy: 0.9614\n",
      "Epoch 861/1000\n",
      "350/350 - 0s - loss: 0.0865 - accuracy: 0.9622\n",
      "Epoch 862/1000\n",
      "350/350 - 0s - loss: 0.0858 - accuracy: 0.9616\n",
      "Epoch 863/1000\n",
      "350/350 - 0s - loss: 0.0804 - accuracy: 0.9625\n",
      "Epoch 864/1000\n",
      "350/350 - 0s - loss: 0.0841 - accuracy: 0.9634\n",
      "Epoch 865/1000\n",
      "350/350 - 1s - loss: 0.0798 - accuracy: 0.9644\n",
      "Epoch 866/1000\n",
      "350/350 - 0s - loss: 0.0801 - accuracy: 0.9630\n",
      "Epoch 867/1000\n",
      "350/350 - 1s - loss: 0.0786 - accuracy: 0.9634\n",
      "Epoch 868/1000\n",
      "350/350 - 1s - loss: 0.0811 - accuracy: 0.9610\n",
      "Epoch 869/1000\n",
      "350/350 - 1s - loss: 0.0830 - accuracy: 0.9625\n",
      "Epoch 870/1000\n",
      "350/350 - 1s - loss: 0.0785 - accuracy: 0.9630\n",
      "Epoch 871/1000\n",
      "350/350 - 0s - loss: 0.0842 - accuracy: 0.9614\n",
      "Epoch 872/1000\n",
      "350/350 - 0s - loss: 0.0884 - accuracy: 0.9602\n",
      "Epoch 873/1000\n",
      "350/350 - 0s - loss: 0.0843 - accuracy: 0.9616\n",
      "Epoch 874/1000\n",
      "350/350 - 0s - loss: 0.0840 - accuracy: 0.9615\n",
      "Epoch 875/1000\n",
      "350/350 - 0s - loss: 0.0813 - accuracy: 0.9631\n",
      "Epoch 876/1000\n",
      "350/350 - 0s - loss: 0.0820 - accuracy: 0.9627\n",
      "Epoch 877/1000\n",
      "350/350 - 0s - loss: 0.0847 - accuracy: 0.9622\n",
      "Epoch 878/1000\n",
      "350/350 - 0s - loss: 0.0813 - accuracy: 0.9628\n",
      "Epoch 879/1000\n",
      "350/350 - 0s - loss: 0.0816 - accuracy: 0.9628\n",
      "Epoch 880/1000\n",
      "350/350 - 0s - loss: 0.0795 - accuracy: 0.9638\n",
      "Epoch 881/1000\n",
      "350/350 - 0s - loss: 0.0798 - accuracy: 0.9635\n",
      "Epoch 882/1000\n",
      "350/350 - 0s - loss: 0.0842 - accuracy: 0.9633\n",
      "Epoch 883/1000\n",
      "350/350 - 0s - loss: 0.0842 - accuracy: 0.9624\n",
      "Epoch 884/1000\n",
      "350/350 - 0s - loss: 0.0828 - accuracy: 0.9628\n",
      "Epoch 885/1000\n",
      "350/350 - 1s - loss: 0.0794 - accuracy: 0.9640\n",
      "Epoch 886/1000\n",
      "350/350 - 0s - loss: 0.0782 - accuracy: 0.9640\n",
      "Epoch 887/1000\n",
      "350/350 - 0s - loss: 0.0798 - accuracy: 0.9638\n",
      "Epoch 888/1000\n",
      "350/350 - 0s - loss: 0.0840 - accuracy: 0.9617\n",
      "Epoch 889/1000\n",
      "350/350 - 0s - loss: 0.0823 - accuracy: 0.9631\n",
      "Epoch 890/1000\n",
      "350/350 - 0s - loss: 0.0796 - accuracy: 0.9627\n",
      "Epoch 891/1000\n",
      "350/350 - 0s - loss: 0.0782 - accuracy: 0.9646\n",
      "Epoch 892/1000\n",
      "350/350 - 0s - loss: 0.0840 - accuracy: 0.9625\n",
      "Epoch 893/1000\n",
      "350/350 - 0s - loss: 0.0826 - accuracy: 0.9615\n",
      "Epoch 894/1000\n",
      "350/350 - 0s - loss: 0.0805 - accuracy: 0.9632\n",
      "Epoch 895/1000\n",
      "350/350 - 1s - loss: 0.0820 - accuracy: 0.9630\n",
      "Epoch 896/1000\n",
      "350/350 - 0s - loss: 0.0818 - accuracy: 0.9622\n",
      "Epoch 897/1000\n",
      "350/350 - 0s - loss: 0.0784 - accuracy: 0.9632\n",
      "Epoch 898/1000\n",
      "350/350 - 0s - loss: 0.0840 - accuracy: 0.9621\n",
      "Epoch 899/1000\n",
      "350/350 - 0s - loss: 0.0799 - accuracy: 0.9635\n",
      "Epoch 900/1000\n",
      "350/350 - 0s - loss: 0.0788 - accuracy: 0.9625\n",
      "Epoch 901/1000\n",
      "350/350 - 0s - loss: 0.0796 - accuracy: 0.9623\n",
      "Epoch 902/1000\n",
      "350/350 - 0s - loss: 0.0789 - accuracy: 0.9638\n",
      "Epoch 903/1000\n",
      "350/350 - 0s - loss: 0.0822 - accuracy: 0.9630\n",
      "Epoch 904/1000\n",
      "350/350 - 0s - loss: 0.0825 - accuracy: 0.9640\n",
      "Epoch 905/1000\n",
      "350/350 - 0s - loss: 0.0882 - accuracy: 0.9616\n",
      "Epoch 906/1000\n",
      "350/350 - 0s - loss: 0.0817 - accuracy: 0.9618\n",
      "Epoch 907/1000\n",
      "350/350 - 0s - loss: 0.0772 - accuracy: 0.9634\n",
      "Epoch 908/1000\n",
      "350/350 - 0s - loss: 0.0824 - accuracy: 0.9637\n",
      "Epoch 909/1000\n",
      "350/350 - 0s - loss: 0.0795 - accuracy: 0.9626\n",
      "Epoch 910/1000\n",
      "350/350 - 0s - loss: 0.0851 - accuracy: 0.9625\n",
      "Epoch 911/1000\n",
      "350/350 - 0s - loss: 0.0789 - accuracy: 0.9631\n",
      "Epoch 912/1000\n",
      "350/350 - 0s - loss: 0.0759 - accuracy: 0.9637\n",
      "Epoch 913/1000\n",
      "350/350 - 0s - loss: 0.0813 - accuracy: 0.9628\n",
      "Epoch 914/1000\n",
      "350/350 - 0s - loss: 0.0813 - accuracy: 0.9629\n",
      "Epoch 915/1000\n",
      "350/350 - 0s - loss: 0.0834 - accuracy: 0.9618\n",
      "Epoch 916/1000\n",
      "350/350 - 0s - loss: 0.0768 - accuracy: 0.9634\n",
      "Epoch 917/1000\n",
      "350/350 - 0s - loss: 0.0832 - accuracy: 0.9616\n",
      "Epoch 918/1000\n",
      "350/350 - 0s - loss: 0.0786 - accuracy: 0.9647\n",
      "Epoch 919/1000\n",
      "350/350 - 0s - loss: 0.0785 - accuracy: 0.9635\n",
      "Epoch 920/1000\n",
      "350/350 - 0s - loss: 0.0784 - accuracy: 0.9652\n",
      "Epoch 921/1000\n",
      "350/350 - 0s - loss: 0.0860 - accuracy: 0.9603\n",
      "Epoch 922/1000\n",
      "350/350 - 0s - loss: 0.0837 - accuracy: 0.9629\n",
      "Epoch 923/1000\n",
      "350/350 - 0s - loss: 0.0797 - accuracy: 0.9626\n",
      "Epoch 924/1000\n",
      "350/350 - 0s - loss: 0.0804 - accuracy: 0.9643\n",
      "Epoch 925/1000\n",
      "350/350 - 0s - loss: 0.0818 - accuracy: 0.9634\n",
      "Epoch 926/1000\n",
      "350/350 - 0s - loss: 0.0810 - accuracy: 0.9639\n",
      "Epoch 927/1000\n",
      "350/350 - 0s - loss: 0.0807 - accuracy: 0.9627\n",
      "Epoch 928/1000\n",
      "350/350 - 0s - loss: 0.0802 - accuracy: 0.9618\n",
      "Epoch 929/1000\n",
      "350/350 - 0s - loss: 0.0806 - accuracy: 0.9629\n",
      "Epoch 930/1000\n",
      "350/350 - 0s - loss: 0.0795 - accuracy: 0.9639\n",
      "Epoch 931/1000\n",
      "350/350 - 0s - loss: 0.0835 - accuracy: 0.9611\n",
      "Epoch 932/1000\n",
      "350/350 - 0s - loss: 0.0788 - accuracy: 0.9623\n",
      "Epoch 933/1000\n",
      "350/350 - 0s - loss: 0.0792 - accuracy: 0.9626\n",
      "Epoch 934/1000\n",
      "350/350 - 0s - loss: 0.0818 - accuracy: 0.9616\n",
      "Epoch 935/1000\n",
      "350/350 - 0s - loss: 0.0807 - accuracy: 0.9634\n",
      "Epoch 936/1000\n",
      "350/350 - 0s - loss: 0.0781 - accuracy: 0.9633\n",
      "Epoch 937/1000\n",
      "350/350 - 0s - loss: 0.0814 - accuracy: 0.9622\n",
      "Epoch 938/1000\n",
      "350/350 - 0s - loss: 0.0836 - accuracy: 0.9616\n",
      "Epoch 939/1000\n",
      "350/350 - 0s - loss: 0.0808 - accuracy: 0.9621\n",
      "Epoch 940/1000\n",
      "350/350 - 0s - loss: 0.0809 - accuracy: 0.9641\n",
      "Epoch 941/1000\n",
      "350/350 - 0s - loss: 0.0775 - accuracy: 0.9639\n",
      "Epoch 942/1000\n",
      "350/350 - 0s - loss: 0.0791 - accuracy: 0.9634\n",
      "Epoch 943/1000\n",
      "350/350 - 0s - loss: 0.0804 - accuracy: 0.9621\n",
      "Epoch 944/1000\n",
      "350/350 - 0s - loss: 0.0775 - accuracy: 0.9646\n",
      "Epoch 945/1000\n",
      "350/350 - 0s - loss: 0.0798 - accuracy: 0.9630\n",
      "Epoch 946/1000\n",
      "350/350 - 0s - loss: 0.0770 - accuracy: 0.9631\n",
      "Epoch 947/1000\n",
      "350/350 - 0s - loss: 0.0785 - accuracy: 0.9632\n",
      "Epoch 948/1000\n",
      "350/350 - 0s - loss: 0.0792 - accuracy: 0.9625\n",
      "Epoch 949/1000\n",
      "350/350 - 0s - loss: 0.0791 - accuracy: 0.9636\n",
      "Epoch 950/1000\n",
      "350/350 - 0s - loss: 0.0870 - accuracy: 0.9616\n",
      "Epoch 951/1000\n",
      "350/350 - 0s - loss: 0.0889 - accuracy: 0.9611\n",
      "Epoch 952/1000\n",
      "350/350 - 0s - loss: 0.0801 - accuracy: 0.9635\n",
      "Epoch 953/1000\n",
      "350/350 - 1s - loss: 0.0776 - accuracy: 0.9643\n",
      "Epoch 954/1000\n",
      "350/350 - 1s - loss: 0.0781 - accuracy: 0.9637\n",
      "Epoch 955/1000\n",
      "350/350 - 0s - loss: 0.0817 - accuracy: 0.9623\n",
      "Epoch 956/1000\n",
      "350/350 - 0s - loss: 0.0797 - accuracy: 0.9617\n",
      "Epoch 957/1000\n",
      "350/350 - 0s - loss: 0.0812 - accuracy: 0.9630\n",
      "Epoch 958/1000\n",
      "350/350 - 0s - loss: 0.0824 - accuracy: 0.9621\n",
      "Epoch 959/1000\n",
      "350/350 - 0s - loss: 0.0869 - accuracy: 0.9620\n",
      "Epoch 960/1000\n",
      "350/350 - 0s - loss: 0.0813 - accuracy: 0.9620\n",
      "Epoch 961/1000\n",
      "350/350 - 0s - loss: 0.0788 - accuracy: 0.9624\n",
      "Epoch 962/1000\n",
      "350/350 - 0s - loss: 0.0802 - accuracy: 0.9622\n",
      "Epoch 963/1000\n",
      "350/350 - 0s - loss: 0.0818 - accuracy: 0.9619\n",
      "Epoch 964/1000\n",
      "350/350 - 0s - loss: 0.0794 - accuracy: 0.9631\n",
      "Epoch 965/1000\n",
      "350/350 - 0s - loss: 0.0787 - accuracy: 0.9639\n",
      "Epoch 966/1000\n",
      "350/350 - 0s - loss: 0.0765 - accuracy: 0.9645\n",
      "Epoch 967/1000\n",
      "350/350 - 0s - loss: 0.0794 - accuracy: 0.9616\n",
      "Epoch 968/1000\n",
      "350/350 - 0s - loss: 0.0801 - accuracy: 0.9635\n",
      "Epoch 969/1000\n",
      "350/350 - 0s - loss: 0.0782 - accuracy: 0.9629\n",
      "Epoch 970/1000\n",
      "350/350 - 0s - loss: 0.0773 - accuracy: 0.9641\n",
      "Epoch 971/1000\n",
      "350/350 - 0s - loss: 0.0804 - accuracy: 0.9625\n",
      "Epoch 972/1000\n",
      "350/350 - 0s - loss: 0.0824 - accuracy: 0.9630\n",
      "Epoch 973/1000\n",
      "350/350 - 1s - loss: 0.0778 - accuracy: 0.9634\n",
      "Epoch 974/1000\n",
      "350/350 - 0s - loss: 0.0782 - accuracy: 0.9630\n",
      "Epoch 975/1000\n",
      "350/350 - 1s - loss: 0.0798 - accuracy: 0.9622\n",
      "Epoch 976/1000\n",
      "350/350 - 0s - loss: 0.0806 - accuracy: 0.9636\n",
      "Epoch 977/1000\n",
      "350/350 - 0s - loss: 0.0812 - accuracy: 0.9625\n",
      "Epoch 978/1000\n",
      "350/350 - 0s - loss: 0.0773 - accuracy: 0.9629\n",
      "Epoch 979/1000\n",
      "350/350 - 0s - loss: 0.0789 - accuracy: 0.9647\n",
      "Epoch 980/1000\n",
      "350/350 - 0s - loss: 0.0797 - accuracy: 0.9638\n",
      "Epoch 981/1000\n",
      "350/350 - 0s - loss: 0.0811 - accuracy: 0.9622\n",
      "Epoch 982/1000\n",
      "350/350 - 0s - loss: 0.0804 - accuracy: 0.9642\n",
      "Epoch 983/1000\n",
      "350/350 - 0s - loss: 0.0757 - accuracy: 0.9645\n",
      "Epoch 984/1000\n",
      "350/350 - 0s - loss: 0.0799 - accuracy: 0.9625\n",
      "Epoch 985/1000\n",
      "350/350 - 0s - loss: 0.0811 - accuracy: 0.9634\n",
      "Epoch 986/1000\n",
      "350/350 - 0s - loss: 0.0781 - accuracy: 0.9634\n",
      "Epoch 987/1000\n",
      "350/350 - 0s - loss: 0.0796 - accuracy: 0.9633\n",
      "Epoch 988/1000\n",
      "350/350 - 0s - loss: 0.0800 - accuracy: 0.9629\n",
      "Epoch 989/1000\n",
      "350/350 - 0s - loss: 0.0825 - accuracy: 0.9633\n",
      "Epoch 990/1000\n",
      "350/350 - 0s - loss: 0.0847 - accuracy: 0.9630\n",
      "Epoch 991/1000\n",
      "350/350 - 0s - loss: 0.0806 - accuracy: 0.9620\n",
      "Epoch 992/1000\n",
      "350/350 - 0s - loss: 0.0781 - accuracy: 0.9640\n",
      "Epoch 993/1000\n",
      "350/350 - 0s - loss: 0.0787 - accuracy: 0.9645\n",
      "Epoch 994/1000\n",
      "350/350 - 0s - loss: 0.0820 - accuracy: 0.9631\n",
      "Epoch 995/1000\n",
      "350/350 - 1s - loss: 0.0789 - accuracy: 0.9619\n",
      "Epoch 996/1000\n",
      "350/350 - 0s - loss: 0.0784 - accuracy: 0.9628\n",
      "Epoch 997/1000\n",
      "350/350 - 0s - loss: 0.0788 - accuracy: 0.9632\n",
      "Epoch 998/1000\n",
      "350/350 - 0s - loss: 0.0759 - accuracy: 0.9641\n",
      "Epoch 999/1000\n",
      "350/350 - 0s - loss: 0.0779 - accuracy: 0.9638\n",
      "Epoch 1000/1000\n",
      "350/350 - 0s - loss: 0.0771 - accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "## Compile and train the deep learning model\n",
    "fire_model_v1.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "modelHistory_v1 = fire_model_v1.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=NoOfRuns,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT MODEL ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,4))\n",
    "\n",
    "ax[0].plot(modelHistory_v1.history['loss'])\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "\n",
    "ax[1].plot(modelHistory_v1.history['accuracy'])\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 - 0s - loss: 0.9433 - accuracy: 0.8830\n",
      "Loss: 0.9433024525642395, Accuracy: 0.882984459400177\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = fire_model_v1.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [[2.1296092e-03 4.7793051e-06 9.9786562e-01]\n",
      " [9.9997187e-01 2.4188426e-05 3.9311954e-06]\n",
      " [9.9995565e-01 4.3312302e-05 1.1133171e-06]\n",
      " ...\n",
      " [9.9999976e-01 1.0316450e-07 1.2553748e-07]\n",
      " [9.9999595e-01 3.7204486e-06 4.1407048e-07]\n",
      " [9.9998426e-01 1.8959776e-06 1.3861172e-05]]\n",
      "Predicted class: 5001\n"
     ]
    }
   ],
   "source": [
    "### Making Predictions with new data\n",
    "# new_data = X_scaler.transform(np.array([[-1.2, 0.3, 0.4]]))\n",
    "new_data = X_test_scaled\n",
    "\n",
    "print(f\"Model output: {fire_model_v1.predict(new_data)}\")\n",
    "print(f\"Predicted class: {np.argmax(fire_model_v1.predict(new_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions_v1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>P(0) model1</th>\n",
       "      <th>P(100) model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00213</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99997</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99996</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20685</td>\n",
       "      <td>0.00065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99998</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3726 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predictions_v1  Actual  P(0) model1  P(100) model1\n",
       "0                  2       0      0.00213        0.00000\n",
       "1                  0       0      0.99997        0.00002\n",
       "2                  0       0      0.99996        0.00004\n",
       "3                  2       0      0.20685        0.00065\n",
       "4                  0       0      1.00000        0.00000\n",
       "...              ...     ...          ...            ...\n",
       "3721               0       0      1.00000        0.00000\n",
       "3722               0       1      0.99998        0.00001\n",
       "3723               0       0      1.00000        0.00000\n",
       "3724               0       0      1.00000        0.00000\n",
       "3725               0       0      0.99998        0.00000\n",
       "\n",
       "[3726 rows x 4 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### View prediction probabilities\n",
    "predictions_v1 = np.argmax(fire_model_v1.predict(X_test_scaled), axis=1)\n",
    "probs_v1 = fire_model_v1.predict(X_test_scaled)\n",
    "\n",
    "# Change the shape of y\n",
    "old_y_test = y_test\n",
    "new_y_test = np.array(old_y_test)\n",
    "y_test = new_y_test.reshape(-1, 1) \n",
    "y_test\n",
    "y_test_df = y_test.ravel()\n",
    "y_test_df\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Predictions_v1\": predictions_v1,\n",
    "    \"Actual\": y_test_df, \n",
    "    \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "    \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "    })\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING MODEL\n",
    "# !pip install dill\n",
    "# import dill\n",
    "\n",
    "# with open('NN_fireClassModel.pkl', 'wb') as f:\n",
    "#     dill.dump(fire_model_v1, f)\n",
    "\n",
    "final_model_path = os.path.join(\"..\", \"static\", \"model\", \"fires_class_model_v1.h5\")\n",
    "temp_model_path = os.path.join(\"fires_class_model_v1.h5\")\n",
    "\n",
    "fire_model_v1.save(temp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SAVING MODEL\n",
    "# # save your model by updating \"your_name\" with your name\n",
    "# # and \"your_model\" with your model variable\n",
    "# # be sure to turn this in to BCS\n",
    "# # if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "# import joblib\n",
    "# filename = 'NN_fireClassModel.sav'\n",
    "# joblib.dump(fire_model_v1, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELOAD AND RUN TEST RUN ON NEW MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions_v1</th>\n",
       "      <th>Actual</th>\n",
       "      <th>P(0) model1</th>\n",
       "      <th>P(100) model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.45622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02062</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.99966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.18729</td>\n",
       "      <td>0.16114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>541</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.99984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.99993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38010</td>\n",
       "      <td>0.55314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>618</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36079</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>928</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38316</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>962</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38383</td>\n",
       "      <td>0.61610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00389</td>\n",
       "      <td>0.95551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1107</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05665</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1164</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.33943</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1227</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.99572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.29649</td>\n",
       "      <td>0.70338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1374</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00098</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1471</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predictions_v1  Actual  P(0) model1  P(100) model1\n",
       "267                2       2      0.00046        0.45622\n",
       "282                2       1      0.02062        0.00000\n",
       "355                1       2      0.00031        0.99966\n",
       "393                2       2      0.18729        0.16114\n",
       "541                1       1      0.00002        0.99984\n",
       "605                1       2      0.00000        0.99993\n",
       "609                1       1      0.38010        0.55314\n",
       "618                2       1      0.36079        0.00003\n",
       "928                2       1      0.00001        0.00000\n",
       "950                2       2      0.38316        0.00000\n",
       "962                2       1      0.00001        0.00005\n",
       "1024               1       1      0.38383        0.61610\n",
       "1089               1       2      0.00389        0.95551\n",
       "1092               2       2      0.00000        0.00000\n",
       "1107               2       2      0.05665        0.00000\n",
       "1164               2       2      0.33943        0.00001\n",
       "1227               1       1      0.00413        0.99572\n",
       "1359               1       2      0.29649        0.70338\n",
       "1374               2       1      0.00098        0.00000\n",
       "1471               2       2      0.00006        0.00000"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VIEW PREDICTION AND PROBABILITIES\n",
    "predictions_v1 = np.argmax(fire_model_v1.predict(X_test_scaled), axis=1)\n",
    "probs_v1 = fire_model_v1.predict(X_test_scaled)\n",
    "\n",
    "# Change the shape of y\n",
    "old_y_test = y_test\n",
    "new_y_test = np.array(old_y_test)\n",
    "y_test = new_y_test.reshape(-1, 1) \n",
    "y_test\n",
    "y_test_df = y_test.ravel()\n",
    "y_test_df\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Predictions_v1\": predictions_v1,\n",
    "    \"Actual\": y_test_df, \n",
    "    \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "    \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "    })\n",
    "\n",
    "pred_df\n",
    "\n",
    "# FILTER FOR CLASS G (6) FIRES\n",
    "highFire_df=pred_df.loc[(pred_df[\"Predictions_v1\"] >= 1) & (pred_df[\"Actual\"] >= 1)]\n",
    "highFire_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.    0.    0.    0.    0.    0.    0.    0.    1.    0.   81.5  85.1\n",
      " 78.26 68.72  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      "[ 8.    0.    0.    0.    0.    0.    0.    0.    0.    0.   69.62 69.98\n",
      " 73.4  78.8   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      "[  8.   100.    94.72   0.     0.     0.     0.     0.     0.     0.\n",
      "  71.06  69.26  70.7   66.92   0.     0.     0.     0.     1.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      "[ 8.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         68.18       71.96\n",
      " 72.58600683 64.76        0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "[  9.   100.   100.   100.    59.03   0.     0.     0.     0.     0.\n",
      "  62.96  64.94  64.94  69.08   0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   1.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.  ]\n",
      "[  8.   100.   100.     0.     0.     0.     0.     0.     0.     0.\n",
      "  82.94  84.02  84.74  76.46   0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     1.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.  ]\n"
     ]
    }
   ],
   "source": [
    "# RUN RESULTS TO LOOK AT THE INPUTS FOR THE EXTREME VALUES\n",
    "real_6s = [120,121,325,326,384,385, 401,402,459,460,712,713,737,738,841,844,845,854,855,963,964,1045,1046 ]\n",
    "model_6s = [30,31,120,121,334,335,546,547,677,678,683,684,850,851,909,910,952,953,963,964,998,999,1045,1046]\n",
    "both_6s = [120,963,1045,2231,3130,3389]\n",
    "ExTrain = [9,34,40,42,52,53,55,70,87,88]\n",
    "\n",
    "for i in both_6s:\n",
    "    print(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL\n",
    "import keras.models\n",
    "\n",
    "New_model = keras.models.load_model('fires_class_model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 - 0s - loss: 0.9433 - accuracy: 0.8830\n",
      "Loss: 0.9433024525642395, Accuracy: 0.882984459400177\n"
     ]
    }
   ],
   "source": [
    "# TEST/RUN NEW MODEL\n",
    "model_loss, model_accuracy = New_model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [[2.1296092e-03 4.7793051e-06 9.9786562e-01]\n",
      " [9.9997187e-01 2.4188426e-05 3.9311954e-06]\n",
      " [9.9995565e-01 4.3312302e-05 1.1133171e-06]\n",
      " ...\n",
      " [9.9999976e-01 1.0316450e-07 1.2553748e-07]\n",
      " [9.9999595e-01 3.7204486e-06 4.1407048e-07]\n",
      " [9.9998426e-01 1.8959776e-06 1.3861172e-05]]\n",
      "Predicted class: 5001\n"
     ]
    }
   ],
   "source": [
    "### Making Predictions with new data\n",
    "new_data = X_test_scaled\n",
    "\n",
    "print(f\"Model output: {New_model.predict(new_data)}\")\n",
    "print(f\"Predicted class: {np.argmax(New_model.predict(new_data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions_v1</th>\n",
       "      <th>P(0) model1</th>\n",
       "      <th>P(100) model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00073</td>\n",
       "      <td>0.01168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36362</td>\n",
       "      <td>0.53599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.00949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99993</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99901</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99901</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99901</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51440</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99993</td>\n",
       "      <td>0.00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99565</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99901</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91594</td>\n",
       "      <td>0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.91594</td>\n",
       "      <td>0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.88698</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36377</td>\n",
       "      <td>0.53482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38885</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34941</td>\n",
       "      <td>0.32505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38953</td>\n",
       "      <td>0.00212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84973</td>\n",
       "      <td>0.05479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36370</td>\n",
       "      <td>0.53556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38886</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99997</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38885</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38886</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38922</td>\n",
       "      <td>0.00209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38884</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39198</td>\n",
       "      <td>0.00239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38943</td>\n",
       "      <td>0.00211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36376</td>\n",
       "      <td>0.53494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99975</td>\n",
       "      <td>0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80903</td>\n",
       "      <td>0.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36370</td>\n",
       "      <td>0.53556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38886</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0.38886</td>\n",
       "      <td>0.00206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.39916</td>\n",
       "      <td>0.14213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36369</td>\n",
       "      <td>0.53561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36369</td>\n",
       "      <td>0.53562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99598</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99903</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predictions_v1  P(0) model1  P(100) model1\n",
       "0                2      0.00072        0.01136\n",
       "1                2      0.00073        0.01168\n",
       "2                2      0.00072        0.01129\n",
       "3                2      0.00072        0.01136\n",
       "4                1      0.36362        0.53599\n",
       "5                2      0.00072        0.01138\n",
       "6                2      0.00072        0.01136\n",
       "7                2      0.00054        0.00949\n",
       "8                0      0.99993        0.00006\n",
       "9                0      0.99901        0.00046\n",
       "10               0      0.99901        0.00046\n",
       "11               0      0.99901        0.00046\n",
       "12               0      0.51440        0.00002\n",
       "13               0      0.99993        0.00006\n",
       "14               0      0.99565        0.00001\n",
       "15               0      0.99901        0.00046\n",
       "16               0      0.91594        0.00037\n",
       "17               0      0.91594        0.00037\n",
       "18               0      0.88698        0.00005\n",
       "19               1      0.36377        0.53482\n",
       "20               2      0.38885        0.00206\n",
       "21               0      0.34941        0.32505\n",
       "22               2      0.38953        0.00212\n",
       "23               0      0.84973        0.05479\n",
       "24               1      0.36370        0.53556\n",
       "25               2      0.38886        0.00206\n",
       "26               0      0.99997        0.00001\n",
       "27               2      0.38885        0.00206\n",
       "28               2      0.38886        0.00206\n",
       "29               2      0.38922        0.00209\n",
       "30               2      0.38884        0.00206\n",
       "31               2      0.39198        0.00239\n",
       "32               0      1.00000        0.00000\n",
       "33               2      0.38943        0.00211\n",
       "34               1      0.36376        0.53494\n",
       "35               2      0.00072        0.01136\n",
       "36               0      0.99975        0.00003\n",
       "37               0      0.80903        0.00014\n",
       "38               1      0.36370        0.53556\n",
       "39               2      0.38886        0.00206\n",
       "40               2      0.00072        0.01136\n",
       "41               2      0.38886        0.00206\n",
       "42               2      0.39916        0.14213\n",
       "43               2      0.00072        0.01136\n",
       "44               1      0.36369        0.53561\n",
       "45               1      0.36369        0.53562\n",
       "46               2      0.00072        0.01136\n",
       "47               2      0.00072        0.01136\n",
       "48               0      0.99598        0.00001\n",
       "49               0      0.99903        0.00002"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST MODEL WITH NEW DATA\n",
    "# --------------------------------------------------------------- #\n",
    "\n",
    "# IMPORT CSV FOR DF\n",
    "X_input_dfFormat = os.path.join(\"..\", \"Data\", \"X_input_dfFormat.csv\")\n",
    "\n",
    "# Open the CSV Files, Convert to a Dataframe, and Save as a Variable\n",
    "X_input_dfFormat_df = pd.read_csv(X_input_dfFormat)\n",
    "\n",
    "# X_input_dfFormat_df['NAME_Lincoln']\n",
    "\n",
    "# PREP X VALUES FOR MODEL\n",
    "# --------------------------------------------------------------- #\n",
    "# # Reshape X from df to array v1\n",
    "newInput = X_input_dfFormat_df.values.reshape(-1, 58)\n",
    "\n",
    "# # # View output\n",
    "# print(f\"Shape of X Input is {X.shape}\")\n",
    "# print(f\"Type of X input is {type(X)}\")\n",
    "\n",
    "# RUN TEST\n",
    "# --------------------------------------------------------------- #\n",
    "# print(f\"Model output: {np.argmax(fire_model_v1.predict(newInput), axis=1)}\")\n",
    "# np.argmax(New_model.predict(new_data))\n",
    "\n",
    "# CREATE TO VIEW PREDICTIONS\n",
    "# --------------------------------------------------------------- #\n",
    "predictions_newInput = np.argmax(fire_model_v1.predict(newInput), axis=1)\n",
    "probs_v1 = fire_model_v1.predict(newInput)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Predictions_v1\": predictions_newInput,\n",
    "    \"P(0) model1\": np.round(probs_v1[:, 0], 5),\n",
    "    \"P(100) model1\": np.round(probs_v1[:, 1], 5),\n",
    "    })\n",
    "\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
