{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ---------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# ---------------------------------------------------------\n",
    "from splinter import Browser\n",
    "# ---------------------------------------------------------\n",
    "from bs4 import BeautifulSoup as BS\n",
    "# ---------------------------------------------------------\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "# ---------------------------------------------------------\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "# ---------------------------------------------------------\n",
    "from itertools import dropwhile\n",
    "# ---------------------------------------------------------\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta, date\n",
    "\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# import pymongo\n",
    "# import requests\n",
    "# import datefinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs for the Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USGS_WaterWatch_url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 00 - Scrape the Tables from USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Using Pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This did not work b/c the table is created with JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Websites\n",
    "# River_Stream_7Day_Flow_Conditions_Tables = pd.read_html(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(River_Stream_7Day_Flow_Conditions_Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# River_Stream_7Day_Flow_Conditions_Tables[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Scraping the Website with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' WaterWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # identify location of chromedriver and store it as a variable\n",
    "# chromedriver = !which chromedriver\n",
    "# print(type(chromedriver))\n",
    "# chromedriver[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve page with the requests module\n",
    "# executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# # OR\n",
    "# # executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# # I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# # executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "# browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URL of page to be scraped\n",
    "# url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# browser.visit(url)\n",
    "# # window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = browser.html\n",
    "# soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the html code of the NASA's Mars website\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Click FULL IMAGE to see a large thumbnail of the featured image \n",
    "# browser.click_link_by_id('st')\n",
    "# # browser.fill('st', \"Idaho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "# for option in soup.find_all('option'):\n",
    "#     print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from selenium import webdriver\n",
    "# # from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get(USGS_WaterWatch_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "# select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# # Select by visible text\n",
    "# select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill in Input Fills\n",
    "# #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# # Clear the Input Field\n",
    "# #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "# element = driver.find_element_by_name(\"bdt\")\n",
    "# element.clear()\n",
    "# element.send_keys(\"1990-01-01\")\n",
    "\n",
    "# element = driver.find_element_by_name(\"edt\")\n",
    "# element.clear()\n",
    "# element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Press/Click a Button Without an ID\n",
    "# #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "# button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "# button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# # test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# # test\n",
    "\n",
    "# # https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "# soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Grab All Page Source on the Page\n",
    "# soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# # Find All the Tables on the Page\n",
    "# tables = soup_lxml.find_all(\"table\")\n",
    "# tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the Tables with Pandas\n",
    "# dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the Table\n",
    "# print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "# print(\"*********************************************************************************************************\")\n",
    "# print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "# print(\"*********************************************************************************************************\")\n",
    "# print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "# dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, json\n",
    "# text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "# data = json.loads(text)\n",
    "# print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tr in soup.find_all('tr')[2:]:\n",
    "#     tds = tr.find_all('td')\n",
    "#     print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "# #           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scrape a Table of All the Streamflow Stations In Idaho by County, Save a CSV File with Daily Streamflow Data for Each Station, and Scrape a Table with Extended Streamflow Statistics for Each Streamflow Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create the Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Current Streamflow')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('group_table_by'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('county_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "sbmt_bttn = '//input[@type=\"submit\" and @value=\"go\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find All the Station Numbers Scrap the table with all the stations and use that table to loop \n",
    "# through and click each station's link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crrnt_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tables on the current page: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationNumber</th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)3/8</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)3/8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13206000</td>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13206305</td>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13206400</td>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>13011500</td>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>13011900</td>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>13013650</td>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>13015000</td>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>13018750</td>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StationNumber                                    Station name  \\\n",
       "0        Ada County                                      Ada County   \n",
       "1          13206000      BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2          13206305           BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3          13206400                        EAGLE DRAIN AT EAGLE, ID   \n",
       "4    Bannock County                                  Bannock County   \n",
       "..              ...                                             ...   \n",
       "271        13011500                      PACIFIC CREEK AT MORAN, WY   \n",
       "272        13011900          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273        13013650                        SNAKE RIVER AT MOOSE, WY   \n",
       "274        13015000                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275        13018750  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)3/8 Dailymeanstream- flow (ft3/s)3/8  \n",
       "0                    Ada County                       Ada County  \n",
       "1                           NaN                              288  \n",
       "2                           NaN                              248  \n",
       "3                           NaN                             6.62  \n",
       "4                Bannock County                   Bannock County  \n",
       "..                          ...                              ...  \n",
       "271                         NaN                               --  \n",
       "272                         NaN                               --  \n",
       "273                         NaN                             1010  \n",
       "274                         NaN                               --  \n",
       "275                         NaN                             1410  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "statn_table = pd.read_html(crrnt_url)\n",
    "print(f\"Number of Tables on the current page: {len(statn_table)}\")\n",
    "statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(statn_table[1].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df = statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)3/8</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)3/8</th>\n",
       "      <th>numbers</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td></td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "      <td>13206000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248</td>\n",
       "      <td>13206305</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.62</td>\n",
       "      <td>13206400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td></td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011500</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011900</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010</td>\n",
       "      <td>13013650</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13015000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1410</td>\n",
       "      <td>13018750</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Station name  \\\n",
       "0                                        Ada County   \n",
       "1        BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2             BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3                          EAGLE DRAIN AT EAGLE, ID   \n",
       "4                                    Bannock County   \n",
       "..                                              ...   \n",
       "271                      PACIFIC CREEK AT MORAN, WY   \n",
       "272          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273                        SNAKE RIVER AT MOOSE, WY   \n",
       "274                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)3/8 Dailymeanstream- flow (ft3/s)3/8   numbers  \\\n",
       "0                    Ada County                       Ada County             \n",
       "1                           NaN                              288  13206000   \n",
       "2                           NaN                              248  13206305   \n",
       "3                           NaN                             6.62  13206400   \n",
       "4                Bannock County                   Bannock County             \n",
       "..                          ...                              ...       ...   \n",
       "271                         NaN                               --  13011500   \n",
       "272                         NaN                               --  13011900   \n",
       "273                         NaN                             1010  13013650   \n",
       "274                         NaN                               --  13015000   \n",
       "275                         NaN                             1410  13018750   \n",
       "\n",
       "               text  \n",
       "0        Ada County  \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4    Bannock County  \n",
       "..              ...  \n",
       "271                  \n",
       "272                  \n",
       "273                  \n",
       "274                  \n",
       "275                  \n",
       "\n",
       "[276 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the text from the digits in the \"StationNumber\" column.\n",
    "# https://stackoverflow.com/questions/56851679/how-to-separate-pandas-column-that-contains-values-stored-as-text-and-numbers-in\n",
    "\n",
    "statn_table_df_splt_StatnNmbr = statn_table_df.join(statn_table_df.pop('StationNumber').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n",
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW CELL\n",
    "\n",
    "# if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "#     print(\"No County\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the \"numbers\" column from the \"statn_table_df_splt\" Dataframe\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn = pd.DataFrame(statn_table_df_splt_StatnNmbr[\"numbers\"])\n",
    "\n",
    "# Replace the Empty Rows with \"NaN\"\n",
    "# https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "\n",
    "nan_value = float(\"NaN\")\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.replace(\"\", nan_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the Number of Null Values in the Dataframe\n",
    "# # https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Values: numbers    0\n",
      "dtype: int64\n",
      "*********************************************************************************************************\n",
      "numbers    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove the \"NaN\" Null Values\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls = statn_table_df_splt_StatnNmbr_nmbrs_clmn.dropna()\n",
    "print(f\"Number of Null Values: {statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.isna().sum()}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Convert the \"numbers\" column to an Interger Data Type\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"] = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"].astype(int)\n",
    "\n",
    "# print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgn_date = \"1990-01-01\"\n",
    "end_date = \"1990-01-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        select = Select(driver.find_element_by_id(\"select_data_1\"))\n",
    "        select.select_by_visible_text(\"Time-series:   Current/Historical Observations\")\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_exists_by_xpath(\"https://waterdata.usgs.gov/id/nwis/uv/?site_no=13296000&agency_cd=USGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13206000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 1\n",
      "********************************************************************************\n",
      "Station Number: 13206305\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 2\n",
      "********************************************************************************\n",
      "Station Number: 13206400\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 3\n",
      "********************************************************************************\n",
      "Station Number: 13073000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 5\n",
      "********************************************************************************\n",
      "Station Number: 13075000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 6\n",
      "********************************************************************************\n",
      "Station Number: 13075500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 7\n",
      "********************************************************************************\n",
      "Station Number: 13075910\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 8\n",
      "********************************************************************************\n",
      "Station Number: 10039500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 10\n",
      "********************************************************************************\n",
      "Station Number: 10068500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 11\n",
      "********************************************************************************\n",
      "Station Number: 12414900\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 13\n",
      "********************************************************************************\n",
      "Station Number: 12415070\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12415135\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 15\n",
      "********************************************************************************\n",
      "Station Number: 13060000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 17\n",
      "********************************************************************************\n",
      "Station Number: 13062500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 18\n",
      "********************************************************************************\n",
      "Station Number: 13065500\n",
      "Number of Tables on the current page: 5\n",
      "********************************************************************************\n",
      "Station Number: 13066000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 20\n",
      "********************************************************************************\n",
      "Station Number: 13068300\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 21\n",
      "********************************************************************************\n",
      "Station Number: 13068495\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 22\n",
      "********************************************************************************\n",
      "Station Number: 13068500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 23\n",
      "********************************************************************************\n",
      "Station Number: 13069500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 24\n",
      "********************************************************************************\n",
      "Station Number: 13075983\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 25\n",
      "********************************************************************************\n",
      "Station Number: 13135500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 27\n",
      "********************************************************************************\n",
      "Station Number: 13135520\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 28\n",
      "********************************************************************************\n",
      "Station Number: 13136550\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 29\n",
      "********************************************************************************\n",
      "Station Number: 13137000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 30\n",
      "********************************************************************************\n",
      "Station Number: 13137500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 31\n",
      "********************************************************************************\n",
      "Station Number: 13138000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 32\n",
      "********************************************************************************\n",
      "Station Number: 13139510\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 33\n",
      "********************************************************************************\n",
      "Station Number: 13140335\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 34\n",
      "********************************************************************************\n",
      "Station Number: 13140800\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 35\n",
      "********************************************************************************\n",
      "Station Number: 13142500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 36\n",
      "********************************************************************************\n",
      "Station Number: 13147900\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 37\n",
      "********************************************************************************\n",
      "Station Number: 13148500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 38\n",
      "********************************************************************************\n",
      "Station Number: 13150430\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 39\n",
      "********************************************************************************\n",
      "Station Number: 13185000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 41\n",
      "********************************************************************************\n",
      "Station Number: 13200000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 42\n",
      "********************************************************************************\n",
      "Station Number: 13235000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 43\n",
      "********************************************************************************\n",
      "Station Number: 13237920\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 44\n",
      "********************************************************************************\n",
      "Station Number: 13246000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 45\n",
      "********************************************************************************\n",
      "Station Number: 13247500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 46\n",
      "********************************************************************************\n",
      "Station Number: 12391950\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 48\n",
      "********************************************************************************\n",
      "Station Number: 12392155\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 49\n",
      "********************************************************************************\n",
      "Station Number: 12392300\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 50\n",
      "********************************************************************************\n",
      "Station Number: 12393501\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 51\n",
      "********************************************************************************\n",
      "Station Number: 12395000\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13032500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 54\n",
      "********************************************************************************\n",
      "Station Number: 13037500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 55\n",
      "********************************************************************************\n",
      "Station Number: 13057132\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13057155\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 57\n",
      "********************************************************************************\n",
      "Station Number: 13057500\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13057940\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 59\n",
      "********************************************************************************\n",
      "Station Number: 13058000\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13058510\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13058520\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13058529\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13058530\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 12306500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 66\n",
      "********************************************************************************\n",
      "Station Number: 12308000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 67\n",
      "********************************************************************************\n",
      "Station Number: 12308500\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12309500\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12310100\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 70\n",
      "********************************************************************************\n",
      "Station Number: 12318500\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12321500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 72\n",
      "********************************************************************************\n",
      "Station Number: 12322000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 73\n",
      "********************************************************************************\n",
      "Station Number: 12322001\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 74\n",
      "********************************************************************************\n",
      "Station Number: 13118700\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 76\n",
      "********************************************************************************\n",
      "Station Number: 13118975\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 77\n",
      "********************************************************************************\n",
      "Station Number: 13119000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 78\n",
      "********************************************************************************\n",
      "Station Number: 13132100\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 79\n",
      "********************************************************************************\n",
      "Station Number: 13132373\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 80\n",
      "********************************************************************************\n",
      "Station Number: 13132500\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13132513\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 82\n",
      "********************************************************************************\n",
      "Station Number: 13132520\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 83\n",
      "********************************************************************************\n",
      "Station Number: 13132535\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 84\n",
      "********************************************************************************\n",
      "Station Number: 13132565\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 85\n",
      "********************************************************************************\n",
      "Station Number: 13141500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 87\n",
      "********************************************************************************\n",
      "Station Number: 13210810\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 89\n",
      "********************************************************************************\n",
      "Station Number: 13210824\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 90\n",
      "********************************************************************************\n",
      "Station Number: 13210831\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 91\n",
      "********************************************************************************\n",
      "Station Number: 13210980\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 92\n",
      "********************************************************************************\n",
      "Station Number: 13210986\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 93\n",
      "********************************************************************************\n",
      "Station Number: 132109867\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 94\n",
      "********************************************************************************\n",
      "Station Number: 13211205\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 95\n",
      "********************************************************************************\n",
      "Station Number: 13212549\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 96\n",
      "********************************************************************************\n",
      "Station Number: 13213000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 97\n",
      "********************************************************************************\n",
      "Station Number: 13213100\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 98\n",
      "********************************************************************************\n",
      "Station Number: 13057300\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 100\n",
      "********************************************************************************\n",
      "Station Number: 13063000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 101\n",
      "********************************************************************************\n",
      "Station Number: 13078000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 103\n",
      "********************************************************************************\n",
      "Station Number: 13079300\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13082500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 105\n",
      "********************************************************************************\n",
      "Station Number: 13083000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 106\n",
      "********************************************************************************\n",
      "Station Number: 13116500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 108\n",
      "********************************************************************************\n",
      "Station Number: 13340000\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13340600\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13120000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 113\n",
      "********************************************************************************\n",
      "Station Number: 13120500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 114\n",
      "********************************************************************************\n",
      "Station Number: 13122000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 115\n",
      "********************************************************************************\n",
      "Station Number: 13124265\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 116\n",
      "********************************************************************************\n",
      "Station Number: 13127000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 117\n",
      "********************************************************************************\n",
      "Station Number: 13128900\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 118\n",
      "********************************************************************************\n",
      "Station Number: 13295000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 119\n",
      "********************************************************************************\n",
      "Station Number: 13296000\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n",
      "Station Number: 13296500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 121\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13297330\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 122\n",
      "********************************************************************************\n",
      "Station Number: 13297355\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 123\n",
      "********************************************************************************\n",
      "Station Number: 13154500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 125\n",
      "********************************************************************************\n",
      "Station Number: 13159800\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 126\n",
      "********************************************************************************\n",
      "Station Number: 13186000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 127\n",
      "********************************************************************************\n",
      "Station Number: 13190500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 128\n",
      "********************************************************************************\n",
      "Station Number: 10092700\n",
      "Number of Tables on the current page: 6\n",
      "********************************************************************************\n",
      "Station Number: 13039500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 132\n",
      "********************************************************************************\n",
      "Station Number: 13042500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 133\n",
      "********************************************************************************\n",
      "Station Number: 13046000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 134\n",
      "********************************************************************************\n",
      "Station Number: 13046995\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 135\n",
      "********************************************************************************\n",
      "Station Number: 13047500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 136\n",
      "********************************************************************************\n",
      "Station Number: 13047600\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 137\n",
      "********************************************************************************\n",
      "Station Number: 13049500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 138\n",
      "********************************************************************************\n",
      "Station Number: 13050500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 139\n",
      "********************************************************************************\n",
      "Station Number: 13055000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 140\n",
      "********************************************************************************\n",
      "Station Number: 13249500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 142\n",
      "********************************************************************************\n",
      "Station Number: 13250000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 143\n",
      "********************************************************************************\n",
      "Station Number: 13095175\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 145\n",
      "********************************************************************************\n",
      "Station Number: 13095500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 146\n",
      "********************************************************************************\n",
      "Station Number: 13152500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 147\n",
      "********************************************************************************\n",
      "Station Number: 13316500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 149\n",
      "********************************************************************************\n",
      "Station Number: 13317000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 150\n",
      "********************************************************************************\n",
      "Station Number: 13336500\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13337000\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13337500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 153\n",
      "********************************************************************************\n",
      "Station Number: 13338500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 154\n",
      "********************************************************************************\n",
      "Station Number: 13038000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 156\n",
      "********************************************************************************\n",
      "Station Number: 13038500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 157\n",
      "********************************************************************************\n",
      "Station Number: 13112000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 158\n",
      "********************************************************************************\n",
      "Station Number: 13089500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 160\n",
      "********************************************************************************\n",
      "Station Number: 12413500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 162\n",
      "********************************************************************************\n",
      "Station Number: 12413860\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 163\n",
      "********************************************************************************\n",
      "Station Number: 12417650\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 164\n",
      "********************************************************************************\n",
      "Station Number: 12419000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 165\n",
      "********************************************************************************\n",
      "Station Number: 13345000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 167\n",
      "********************************************************************************\n",
      "Station Number: 13346800\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 168\n",
      "********************************************************************************\n",
      "Station Number: 13302005\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 170\n",
      "********************************************************************************\n",
      "Station Number: 13302500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 171\n",
      "********************************************************************************\n",
      "Station Number: 13305000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 172\n",
      "********************************************************************************\n",
      "Station Number: 13305310\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 173\n",
      "********************************************************************************\n",
      "Station Number: 13306370\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 174\n",
      "********************************************************************************\n",
      "Station Number: 13306385\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 175\n",
      "********************************************************************************\n",
      "Station Number: 13307000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 176\n",
      "********************************************************************************\n",
      "Station Number: 13310199\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 177\n",
      "********************************************************************************\n",
      "Station Number: 13338950\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 179\n",
      "********************************************************************************\n",
      "Station Number: 13055250\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 181\n",
      "********************************************************************************\n",
      "Station Number: 13055340\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 182\n",
      "********************************************************************************\n",
      "Station Number: 13056500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 183\n",
      "********************************************************************************\n",
      "Station Number: 13057000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 184\n",
      "********************************************************************************\n",
      "Station Number: 13081500\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13317660\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 188\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13341050\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n",
      "Station Number: 13341140\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 190\n",
      "********************************************************************************\n",
      "Station Number: 13341570\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 191\n",
      "********************************************************************************\n",
      "Station Number: 13342450\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 192\n",
      "********************************************************************************\n",
      "Station Number: 13342500\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13168500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 195\n",
      "********************************************************************************\n",
      "Station Number: 13176400\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n",
      "Station Number: 13251000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 198\n",
      "********************************************************************************\n",
      "Station Number: 13077000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 200\n",
      "********************************************************************************\n",
      "Station Number: 12411000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 202\n",
      "********************************************************************************\n",
      "Station Number: 12413000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 203\n",
      "********************************************************************************\n",
      "Station Number: 12413125\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 204\n",
      "********************************************************************************\n",
      "Station Number: 12413130\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 205\n",
      "********************************************************************************\n",
      "Station Number: 12413131\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 206\n",
      "********************************************************************************\n",
      "Station Number: 12413210\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 207\n",
      "********************************************************************************\n",
      "Station Number: 12413355\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 208\n",
      "********************************************************************************\n",
      "Station Number: 12413875\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 209\n",
      "********************************************************************************\n",
      "Station Number: 12414500\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13052200\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 212\n",
      "********************************************************************************\n",
      "Station Number: 13087505\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13087995\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 216\n",
      "********************************************************************************\n",
      "Station Number: 13090500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 217\n",
      "********************************************************************************\n",
      "Station Number: 13092747\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 218\n",
      "********************************************************************************\n",
      "Station Number: 13094000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 219\n",
      "********************************************************************************\n",
      "Station Number: 13108150\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 220\n",
      "********************************************************************************\n",
      "Station Number: 13236500\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13239000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 223\n",
      "********************************************************************************\n",
      "Station Number: 13240000\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13309220\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 225\n",
      "********************************************************************************\n",
      "Station Number: 13310700\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 226\n",
      "********************************************************************************\n",
      "Station Number: 13310800\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13310850\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13311000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 229\n",
      "********************************************************************************\n",
      "Station Number: 13311250\n",
      "Number of Tables on the current page: 4\n",
      "********************************************************************************\n",
      "Station Number: 13311450\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 231\n",
      "********************************************************************************\n",
      "Station Number: 13313000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 232\n",
      "********************************************************************************\n",
      "Station Number: 13258500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 234\n",
      "********************************************************************************\n",
      "Station Number: 13265500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 235\n",
      "********************************************************************************\n",
      "Station Number: 13266000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 236\n",
      "********************************************************************************\n",
      "Station Number: 13269000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 237\n",
      "********************************************************************************\n",
      "Station Number: 12355347\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12301250\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 241\n",
      "********************************************************************************\n",
      "Station Number: 12301933\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 242\n",
      "********************************************************************************\n",
      "Station Number: 12302055\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 243\n",
      "********************************************************************************\n",
      "Station Number: 12304500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 244\n",
      "********************************************************************************\n",
      "Station Number: 12305000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 245\n",
      "********************************************************************************\n",
      "Station Number: 480608115242901\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12389500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 248\n",
      "********************************************************************************\n",
      "Station Number: 12390700\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 249\n",
      "********************************************************************************\n",
      "Station Number: 13105000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 251\n",
      "********************************************************************************\n",
      "Station Number: 13161500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 252\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13162225\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 253\n",
      "********************************************************************************\n",
      "Station Number: 10396000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 255\n",
      "********************************************************************************\n",
      "Station Number: 13181000\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n",
      "Station Number: 13183000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 258\n",
      "********************************************************************************\n",
      "Station Number: 13233300\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 259\n",
      "********************************************************************************\n",
      "Station Number: 13333000\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n",
      "Station Number: 13334300\n",
      "Number of Tables on the current page: 6\n",
      "********************************************************************************\n",
      "Station Number: 13022500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 265\n",
      "********************************************************************************\n",
      "Station Number: 13023000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 266\n",
      "********************************************************************************\n",
      "Station Number: 13027500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 267\n",
      "********************************************************************************\n",
      "Station Number: 13010065\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 269\n",
      "********************************************************************************\n",
      "Station Number: 13011000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 270\n",
      "********************************************************************************\n",
      "Station Number: 13011500\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13011900\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13013650\n",
      "Number of Tables on the current page: 3\n",
      "********************************************************************************\n",
      "Station Number: 13015000\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 13018750\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 275\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.index:\n",
    "    \n",
    "    # Find the Hyper Link for One Station\n",
    "    statn_nmbr = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"][row]\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\n",
    "    # driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\n",
    "    driver.find_element_by_xpath(\"//*[contains(text(),'\" +statn_nmbr+\"')]\").click()\n",
    "\n",
    "\n",
    "    # Under Output Format Select the \"Tab-separated\" Output format\n",
    "    lst_all_statns = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "    lst_all_statns_button = driver.find_element_by_xpath(lst_all_statns)\n",
    "    lst_all_statns_button.click()\n",
    "#     time.sleep(5)\n",
    "\n",
    "    # Enter Values for the Begin Date and End Date\n",
    "    # Fill in Input Fills\n",
    "    #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "    # Clear the Input Field\n",
    "    #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "    element = driver.find_element_by_name(\"begin_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(bgn_date)\n",
    "\n",
    "    element = driver.find_element_by_name(\"end_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(end_date)\n",
    "    \n",
    "\n",
    "    # Press/Click a Button Without an ID\n",
    "    #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "    #     - https://stackoverflow.com/questions/21322116/using-selenium-in-python-to-click-select-a-radio-button/21322160\n",
    "\n",
    "    sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
    "\n",
    "    sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "    sbmt_bttn_button.click()\n",
    "#     time.sleep(5)\n",
    "\n",
    "\n",
    "#     from selenium.webdriver import ActionChains\n",
    "\n",
    "    actionChains = ActionChains(driver)\n",
    "\n",
    "\n",
    "    # Save the data file to This Computer\n",
    "\n",
    "    # How to Open and Write to a File on This Computer\n",
    "    #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "    # How to Change the Location of the File\n",
    "    #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "#     import urllib.request, urllib.error, urllib.parse\n",
    "#     import os\n",
    "\n",
    "\n",
    "    response = urllib.request.urlopen(driver.current_url)\n",
    "    webContent = response.read()\n",
    "\n",
    "    fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "    f = open(fle_nm, 'wb')\n",
    "    f.write(webContent)\n",
    "    f.close\n",
    "\n",
    "# Go back to the original URL for the station\n",
    "    driver.back()\n",
    "    time.sleep(2)\n",
    "# ================================================================================================   \n",
    "# This isn't Working Because Some of the Stations do not have a \"Time-series: Current/Historical \n",
    "# Observations\" In the \"Available Data for this Site\" Dropdown List Box\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# # Select the \"Time-series: Current/Historical Observations\" from the dropdown list, this will \n",
    "# # create page which includes a table with extended streamflow statistics.\n",
    "\n",
    "    crrnt_url = driver.current_url\n",
    "\n",
    "    if check_exists_by_xpath(crrnt_url):\n",
    "        crrnt_hstrcl_obsrvtns = '//input[@value=\"uv\"]'\n",
    "\n",
    "        select = Select(driver.find_element_by_id(\"select_data_1\"))\n",
    "        select.select_by_visible_text(\"Time-series:   Current/Historical Observations\")\n",
    "# ================================================================================================\n",
    "\n",
    "# ================================================================================================\n",
    "# Instead of Using the \"Time-series: Current/Historical Observations\", I decided to Use the \n",
    "# \"Time-series:   Daily data\" for the Extended Mean. I do not Need to Select anything in the\n",
    "# \"Available Data for this Site\" Dropdown List Box.\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# Under Output Format Select the \"Tab-separated\" Output format\n",
    "    else:\n",
    "        statn_grph_stats = '//input[@type=\"radio\" and @value=\"gif_stats\"]'\n",
    "\n",
    "        statn_grph_stats_button = driver.find_element_by_xpath(statn_grph_stats)\n",
    "        statn_grph_stats_button.click()\n",
    "\n",
    "        sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
    "\n",
    "        sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "        sbmt_bttn_button.click()\n",
    "\n",
    "# ================================================================================================    \n",
    "    \n",
    "# Get the extended year streamflow min, max, median, mean, 25th percentile, and 75th percentile\n",
    "    # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "    \n",
    "    crrnt_hstrcl_obsrvtns_url = driver.current_url\n",
    "    crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
    "    print(f'Station Number: {statn_nmbr}')\n",
    "    print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
    "#     print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
    "    \n",
    "    if len(crrnt_hstrcl_obsrvtns_html) == 2:\n",
    "        \n",
    "#         print(crrnt_hstrcl_obsrvtns_html[1])\n",
    "\n",
    "        extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
    "\n",
    "\n",
    "        # Reference: \n",
    "    #     - Find column whose name contains a specific string:\n",
    "    #         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
    "\n",
    "    # print(extndd_yrs_sttstcs.columns)\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
    "        min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'Min Flow: {min_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
    "        max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'Max Flow: {max_strmflw}')\n",
    "\n",
    "#         extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
    "#         _25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "# #         print(f'25th_prcntle: {_25th_prcntle_strmflw}')\n",
    "\n",
    "#         extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
    "#         _75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "# #         print(f'75th_prcntle: {_75th_prcntle_strmflw}')\n",
    "\n",
    "\n",
    "\n",
    "            # References:\n",
    "        #     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
    "        #         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
    "        #     - Pandas update a cell:\n",
    "        #         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
    "\n",
    "\n",
    "        # Find the Index for the Station  \n",
    "        indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
    "        print(f'Index No: {indx_lbl[0]}')\n",
    "\n",
    "        # Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
    "        # Dataframe\n",
    "    # #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
    "\n",
    "#     #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "#         statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
    "\n",
    "#     #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "#         statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]\n",
    "    \n",
    "    elif len(crrnt_hstrcl_obsrvtns_html) < 2:\n",
    "        print(\"No Extened Water Statistics\")\n",
    "    \n",
    "    print(\"********************************************************************************\")\n",
    "    \n",
    "# Go back to the URL with the list of Stations and Counties\n",
    "    driver.back()\n",
    "    driver.back()\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extndd_yrs_sttstcs_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_test.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentadams/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4527: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idaho_counties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bear Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benewah County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bingham County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blaine County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boise County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bonner County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bonneville County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Boundary County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Butte County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Camas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Canyon County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Caribou County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cassia County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Clark County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clearwater County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Custer County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Elmore County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Franklin County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Fremont County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Gem County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Gooding County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Idaho County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Jefferson County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Jerome County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kootenai County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Latah County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lemhi County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lewis County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Madison County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Minidoka County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nez Perce County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Owyhee County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Payette County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Power County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shoshone County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Teton County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Twin Falls County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Valley County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Washington County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Flathead County, Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Lincoln County, Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Sanders County, Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Elko County, Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Harney County, Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Malheur County, Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Wallowa County, Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Asotin County, Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Lincoln County, Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Teton County, Wyoming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               idaho_counties\n",
       "0                  Ada County\n",
       "1              Bannock County\n",
       "2            Bear Lake County\n",
       "3              Benewah County\n",
       "4              Bingham County\n",
       "5               Blaine County\n",
       "6                Boise County\n",
       "7               Bonner County\n",
       "8           Bonneville County\n",
       "9             Boundary County\n",
       "10               Butte County\n",
       "11               Camas County\n",
       "12              Canyon County\n",
       "13             Caribou County\n",
       "14              Cassia County\n",
       "15               Clark County\n",
       "16          Clearwater County\n",
       "17              Custer County\n",
       "18              Elmore County\n",
       "19            Franklin County\n",
       "20             Fremont County\n",
       "21                 Gem County\n",
       "22             Gooding County\n",
       "23               Idaho County\n",
       "24           Jefferson County\n",
       "25              Jerome County\n",
       "26            Kootenai County\n",
       "27               Latah County\n",
       "28               Lemhi County\n",
       "29               Lewis County\n",
       "30             Madison County\n",
       "31            Minidoka County\n",
       "32           Nez Perce County\n",
       "33              Owyhee County\n",
       "34             Payette County\n",
       "35               Power County\n",
       "36            Shoshone County\n",
       "37               Teton County\n",
       "38          Twin Falls County\n",
       "39              Valley County\n",
       "40          Washington County\n",
       "41   Flathead County, Montana\n",
       "42    Lincoln County, Montana\n",
       "43    Sanders County, Montana\n",
       "44        Elko County, Nevada\n",
       "45      Harney County, Oregon\n",
       "46     Malheur County, Oregon\n",
       "47     Wallowa County, Oregon\n",
       "48  Asotin County, Washington\n",
       "49    Lincoln County, Wyoming\n",
       "50      Teton County, Wyoming"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe for the county and each day\n",
    "\n",
    "# Reference:\n",
    "#     - How to Drop Empty Rows from a Dataframe\n",
    "#         - https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "\n",
    "cnty_date_df = statn_table_df_splt_StatnNmbr_test[[\"text\"]]\n",
    "print(type(cnty_date_df))\n",
    "cnty_date_df.replace(\"\", nan_value, inplace = True)\n",
    "cnty_date_df = cnty_date_df.dropna(how = \"any\")\n",
    "cnty_date_df = cnty_date_df.reset_index(drop = True)\n",
    "cnty_date_df = cnty_date_df.rename(columns = {\"text\": \"idaho_counties\"})\n",
    "cnty_date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver import ActionChains\n",
    "\n",
    "# actionChains = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the data file to This Computer\n",
    "\n",
    "# # How to Open and Write to a File on This Computer\n",
    "# #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "# # How to Change the Location of the File\n",
    "# #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "# import urllib.request, urllib.error, urllib.parse\n",
    "# import os\n",
    "\n",
    "# # url='https://waterdata.usgs.gov/id/nwis/dv?cb_00060=on&format=rdb&site_no=13206000&referred_module=sw&period=&begin_date=1990-01-01&end_date=1990-12-31'\n",
    "\n",
    "# response = urllib.request.urlopen(driver.current_url)\n",
    "# webContent = response.read()\n",
    "\n",
    "# output_fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "# f = open(output_fle_nm, 'wb')\n",
    "# f.write(webContent)\n",
    "# f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.back()\n",
    "# driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crrnt_hstrcl_obsrvtns_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
    "# print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
    "# print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
    "\n",
    "# extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
    "# extndd_yrs_sttstcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reference: \n",
    "# #     - Find column whose name contains a specific string:\n",
    "# #         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
    "\n",
    "# print(extndd_yrs_sttstcs.columns)\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
    "# min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
    "# max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
    "# _25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "# extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
    "# _75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the Median because I was the most drastic/losest streamflow\n",
    "# extndd_yrs_sttstcs[\"Median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # References:\n",
    "# #     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
    "# #         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
    "# #     - Pandas update a cell:\n",
    "# #         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
    "\n",
    "# statn_nmbr = \"13206305\"\n",
    "\n",
    "# # Find the Index for the Station  \n",
    "# indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
    "# print(indx_lbl[0])\n",
    "\n",
    "# # Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
    "# # Dataframe\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
    "\n",
    "# # statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "# statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_test.head(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Create a Dataframe for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++\n",
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to Skip All of the Commented Lines in the File\n",
    "#     https://cmdlinetips.com/2018/01/3-ways-to-read-a-file-and-skip-initial-comments-in-python/\n",
    "\n",
    "def is_comment(s):\n",
    "    \"\"\" function to check if a line\n",
    "         starts with some character.\n",
    "         Here # for comment\n",
    "    \"\"\"\n",
    "    # return true if a line starts with #\n",
    "    return s.startswith('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names for the Dataframe\n",
    "clmn_nms = [\"agency\", \n",
    "            \"site_nmbr\", \n",
    "            \"date\", \n",
    "            \"streamflow_rate\", \n",
    "            \"approved/pending\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path for the Streamflow Data\n",
    "input_fle_path = os.path.join(\"Data\", \"Idaho_Streamflow_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Data Types to Change in the Dataframe\n",
    "convert_dict = {\n",
    "                \"streamflow_rate\": float\n",
    "               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['13013650.txt', '13311000.txt', '13306385.txt', '12301933.txt', '12392155.txt', '13235000.txt', '12395000.txt', '13239000.txt', '13120500.txt', '12413000.txt', '13140800.txt', '13132500.txt', '13032500.txt', '13058530.txt', '13055000.txt', '12355347.txt', '13233300.txt', '12305000.txt', '13135520.txt', '13063000.txt', '13112000.txt', '13116500.txt', '10039500.txt', '13075500.txt', '13057000.txt', '13011900.txt', '13141500.txt', '12415070.txt', '13038000.txt', '13138000.txt', '.DS_Store', '13022500.txt', '12411000.txt', '13073000.txt', '13058520.txt', '10396000.txt', '13069500.txt', '13305310.txt', '13150430.txt', '13065500.txt', '13211205.txt', '13317660.txt', '13057940.txt', '13132100.txt', '13118700.txt', '13341140.txt', '12413210.txt', '13047600.txt', '13213000.txt', '13313000.txt', '12393501.txt', '13246000.txt', '13342500.txt', '13132513.txt', '13079300.txt', '13337000.txt', '12414900.txt', '13161500.txt', '13077000.txt', '13340600.txt', '13038500.txt', '13295000.txt', '12302055.txt', '13122000.txt', '13010065.txt', '13132373.txt', '12419000.txt', '13057500.txt', '13049500.txt', '13250000.txt', '13337500.txt', '13333000.txt', '12391950.txt', '13258500.txt', '12389500.txt', '13341050.txt', '13140335.txt', '13317000.txt', '13310800.txt', '13266000.txt', '13305000.txt', '13090500.txt', '13094000.txt', '13190500.txt', '13213100.txt', '13237920.txt', '13210810.txt', '13162225.txt', '13240000.txt', '13340000.txt', '13186000.txt', '13082500.txt', '13068495.txt', '13307000.txt', '13057300.txt', '13124265.txt', '12309500.txt', '13075000.txt', '13132565.txt', '10068500.txt', '12413500.txt', '13075983.txt', '13120000.txt', '13047500.txt', '12321500.txt', '13147900.txt', '13108150.txt', '12392300.txt', '13210980.txt', '12413860.txt', '10092700.txt', '13128900.txt', '12308000.txt', '12310100.txt', '12390700.txt', '13206305.txt', '13142500.txt', '13046000.txt', '13042500.txt', '12413875.txt', '13309220.txt', '13296500.txt', '13058000.txt', '13050500.txt', '13118975.txt', '13137000.txt', '13018750.txt', '13083000.txt', '13183000.txt', '13345000.txt', '13095500.txt', '13068300.txt', '13057132.txt', '13046995.txt', '13311450.txt', '13265500.txt', '13212549.txt', '13210831.txt', '13089500.txt', '13087505.txt', '13181000.txt', '13210986.txt', '13338950.txt', '13297355.txt', '13200000.txt', '13055250.txt', '13316500.txt', '13210824.txt', '13302005.txt', '12322001.txt', '13011000.txt', '13168500.txt', '13068500.txt', '13060000.txt', '12413130.txt', '12413125.txt', '12413131.txt', '13152500.txt', '12414500.txt', '13127000.txt', '132109867.txt', '13311250.txt', '13310199.txt', '12322000.txt', '13055340.txt', '13297330.txt', '13206400.txt', '13236500.txt', '13081500.txt', '13336500.txt', '13185000.txt', '13251000.txt', '12413355.txt', '12301250.txt', '13052200.txt', '13247500.txt', '13342450.txt', '13027500.txt', '13023000.txt', '13039500.txt', '13148500.txt', '13135500.txt', '13132535.txt', '13056500.txt', '13159800.txt', '13306370.txt', '13136550.txt', '12318500.txt', '480608115242901.txt', '13334300.txt', '13058510.txt', '13132520.txt', '12306500.txt', '13119000.txt', '12415135.txt', '13075910.txt', '13015000.txt', '13011500.txt', '13154500.txt', '13037500.txt', '13137500.txt', '13176400.txt', '13057155.txt', '13296000.txt', '13058529.txt', '13310700.txt', '12308500.txt', '13066000.txt', '13139510.txt', '13062500.txt', '12304500.txt', '13078000.txt', '13105000.txt', '13087995.txt', '13095175.txt', '13206000.txt', '13302500.txt', '13269000.txt', '13338500.txt', '13341570.txt', '12417650.txt', '13092747.txt', '13310850.txt', '13249500.txt', '13346800.txt']\n"
     ]
    }
   ],
   "source": [
    "# List of Files in a Directory\n",
    "#     - https://careerkarma.com/blog/python-list-files-in-directory/\n",
    "\n",
    "input_fle_lst = os.listdir(input_fle_path)\n",
    "print(input_fle_lst)\n",
    "# input_fle_nm = input_fle_lst[0]\n",
    "# print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# Create a Dictionary of List from the Files in the Directory\n",
    "input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": []}\n",
    "\n",
    "for input_fle_nm in input_fle_lst:\n",
    "#     Skipping the Files that Start With \".\"\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "\n",
    "# Append to the Station Numbers and File Names and create and append the Dataframe Name to the \n",
    "# Directory\n",
    "        input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "        input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "        input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr.head()\n",
    "\n",
    "# The Last Index Value in the \"text\" Column\n",
    "lst_row_text_clmn = statn_table_df_splt_StatnNmbr[\"text\"].last_valid_index()\n",
    "lst_row_text_clmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count_1 = 0\n",
    "\n",
    "# for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "# #     print(row)\n",
    "    \n",
    "#     if row != \"\":\n",
    "# #         print(row)\n",
    "#         count_1 = count_1 + 1\n",
    "# #         cnty_lst.append(row)\n",
    "        \n",
    "# print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnty_lst = [{}for x in range(51)]\n",
    "# # cnty_lst[2].append(2050)\n",
    "# # cnty_lst[1]\n",
    "# cnty_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list of list\n",
    "# #     - https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "\n",
    "\n",
    "# cnty_lst = [[]for x in range(51)]\n",
    "\n",
    "# count_1 = 0\n",
    "# count_2 = 0\n",
    "# count_3 = 0\n",
    "\n",
    "# statn_lst = []\n",
    "# # cnty_lst = [[] * 154]\n",
    "# new_dict = {}\n",
    "\n",
    "\n",
    "# for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "# #     print(row)\n",
    " \n",
    "# # *********************************************************************************************\n",
    "# #                               Step 1: If the row is Not Empty\n",
    "# # *********************************************************************************************\n",
    "#     if row != \"\":\n",
    "#         print(row)\n",
    "# #         count_1 = count_1\n",
    "#         cnty_lst[count_2].append(row)\n",
    "#         cnty_lst[count_2].append([])\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# #                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# # *********************************************************************************************\n",
    "\n",
    "#     elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "# #         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # # #         count_3 = count_1\n",
    "# # # #         print (count_3)\n",
    "# # #         count_1 = 0\n",
    "\n",
    "\n",
    "#         new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "#                                   \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "#                                   \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "#                                   \"Data\": \"\", \n",
    "#                                   \"Avg_Streamflow\": \"\",\n",
    "#                                   \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "#         cnty_lst[count_2][1].append(dict(new_dict))\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# #                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# # *********************************************************************************************\n",
    "#     elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "# #         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "#         new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "#                                   \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "#                                   \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "#                                   \"Data\": \"\", \n",
    "#                                   \"Avg_Streamflow\": \"\",\n",
    "#                                   \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "#         cnty_lst[count_2][1].append(dict(new_dict))\n",
    "        \n",
    "#         count_2 = count_2 + 1\n",
    "# # *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# # *********************************************************************************************\n",
    "# #                               Step 4: Add 1 to the Count\n",
    "# # *********************************************************************************************    \n",
    "#     count_1 = count_1 + 1\n",
    "# # *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # statn_lst\n",
    "\n",
    "# # cnty_lst[0][0].append(input_fle_dict)\n",
    "# # cnty_lst[0][1].append(\"test\")\n",
    "# # print(cnty_lst)\n",
    "# print(cnty_lst[0])\n",
    "# print(\"********************************************************************\")\n",
    "# print(cnty_lst[0][1])\n",
    "# print(\"********************************************************************\")\n",
    "# print(cnty_lst[0][1][0])\n",
    "# print(\"********************************************************************\")\n",
    "# print(cnty_lst[0][1][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    }
   ],
   "source": [
    "# Create a List of the Counties\n",
    "cnty_lst = []\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "# Create a List of the Stations\n",
    "# statn_lst = []\n",
    "# cnty_lst = [[] * 154]\n",
    "new_dict = {}\n",
    "\n",
    "# The \"text\" Column is the County Name\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    " \n",
    "#     If this count is <= the Last Row in the \"text\" Column\n",
    "    if count_1 + 1 < 276:\n",
    "# *********************************************************************************************\n",
    "#                               Step 1: If the row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        if row != \"\":\n",
    "            # Create a List of the Stations\n",
    "            statn_lst = []  # This will be a list of dictionaries\n",
    "            cnty_nm = row\n",
    "#         print(row)\n",
    "# #         count_1 = count_1\n",
    "#         cnty_lst[count_2].append(row)\n",
    "#         cnty_lst[count_2].append([])\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# *********************************************************************************************\n",
    "\n",
    "        elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # #         count_3 = count_1\n",
    "# # #         print (count_3)\n",
    "# #         count_1 = 0\n",
    "\n",
    "\n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        elif row == \"\": #and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "        \n",
    "#         count_2 = count_2 + 1\n",
    "        \n",
    "            cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "        \n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************  \n",
    "    if count_1 + 1 > 275 and row == \"\":\n",
    "        print (count_1)\n",
    "\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        \n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                    \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                    \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                    \"Data\": \"\", \n",
    "                    \"Avg_Streamflow\": \"\",\n",
    "                    \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "        statn_lst.append(dict(new_dict))\n",
    "\n",
    "        cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "# *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                               Step 4: Add 1 to the Count\n",
    "# *********************************************************************************************    \n",
    "    count_1 = count_1 + 1\n",
    "# *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(cnty_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statn_lst\n",
    "# cnty_lst = {cnty_nm: statn_lst}\n",
    "# cnty_lst[0][0].append(input_fle_dict)\n",
    "# cnty_lst[0][1].append(\"test\")\n",
    "# pprint.pprint(cnty_lst)\n",
    "# print(\"********************************************************************\")\n",
    "# print(new_dict)\n",
    "# print(statn_lst)\n",
    "pprint.pprint(cnty_lst[0])\n",
    "# pprint.pprint(cnty_lst[50])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"][0])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Station_Nmbr\"])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Data\"][\"date\"])\n",
    "# pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
    "\n",
    "print(cnty_lst[0].keys())\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][\"Ada County\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_path_fr_lp = input_fle_path + \"/\" + cnty_lst[0][key_list[0]][0][\"File_Name\"]\n",
    "# # input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# I DON'T THINK I NEED THIS!!!\n",
    "\n",
    "# key_list = list(cnty_lst[0].keys())\n",
    "# val_list = list(cnty_lst[0].values())\n",
    "# key_list[0]\n",
    "# print(cnty_lst[0][key_list[0]][0][\"File_Name\"])\n",
    "\n",
    "# input_fle_path + \"/\" + cnty_lst[0][key_list[0]][0][\"File_Name\"]\n",
    "# # val_list\n",
    "\n",
    "# # position = val_list.index(1)\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # *********************************************************************************************\n",
    "# #     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "# df = pd.DataFrame(columns = clmn_nms)\n",
    "# #     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# #                           Step 2 Create a Dataframe for the Streamflow\n",
    "# # *********************************************************************************************\n",
    "# # Loop Through the .txt File and Store the Data into a Dataframe\n",
    "# with open(input_fle_path_fr_lp,'r') as fh:\n",
    "#     for curline in dropwhile(is_comment, fh):\n",
    "#     #         print(f\"Index Number: {count} {curline}\")\n",
    "#     #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "#     # Split a String\n",
    "#     #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "#     # Pandas Series\n",
    "#     #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "#         to_append = curline[:-1].split(\"\\t\")\n",
    "#         a_series = pd.Series(to_append, index = clmn_nms)\n",
    "\n",
    "#     #             Dataframe\n",
    "#     #             Dataframe Name\n",
    "#         statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "#     #             Append Data to the Dataframe\n",
    "#         df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# #     print(input_fle_nm)\n",
    "# # Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "# df = df.drop(index = [0, 1])\n",
    "# # Reset the Index so that it Starts with 0\n",
    "# df = df.reset_index(drop = True)\n",
    "# # Change the Data Types of Each Column\n",
    "# df = df.astype(convert_dict) \n",
    "# # Change the Date Column to a datetime Data Type\n",
    "# df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "# avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "# print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "# #     print(df[\"streamflow_rate\"])\n",
    "# #     print(\"********************************************************************\")\n",
    "# print (df)\n",
    "    \n",
    "# count = 0\n",
    "# print(len(df))\n",
    "\n",
    "# for i_df in range(len(df)):\n",
    "# #         print (df[\"streamflow_rate\"][2])\n",
    "#     print (df[\"streamflow_rate\"][i_df])\n",
    "# #         print (df_row)\n",
    "#     if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "#         count = count + 1\n",
    "\n",
    "#         print (\"True\")\n",
    "#     elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "#         print (\"False\")\n",
    "#     print(\"********************************************************************\")\n",
    "\n",
    "# pct_blw_avg = (count / len(df) * 100)\n",
    "# print (pct_blw_avg)\n",
    "# # Add a value into an empty dictionay element\n",
    "# #     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "# statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "# statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "# statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "# #     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "# # df_nm = df_nm.drop(index = [0, 1])\n",
    "# # \"_\" + statn_nm + \"_df\" = df\n",
    "# # df_nm\n",
    "# # df\n",
    "# # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def find(name, path):\n",
    "for root, dirs, files in os.walk(input_fle_path):\n",
    "    if \"13073000.txt\" in files:\n",
    "        print (os.path.join(root, \"13073000.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(\"13073000.txt\", input_fle_path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(input_fle_path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # Create a List of the Files in the Directory\n",
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# Create a List to Store/Save the Streamflow Data, Data will be Saved as a List of Dictionaries\n",
    "statn_data_lst_of_dicts = []\n",
    "input_fle_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# Put the Station in a list by County Name\n",
    "# First Find the station in the county  \n",
    "\n",
    "if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "    print(\"No County\")\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "# Skip the Hidden Files in the Directory\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "# # *********************************************************************************************\n",
    "# #         Append to the File Names to the Directory\n",
    "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "# #         print(input_fle_nm)\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "        input_fle_dict = {\"Station_Nmbr\": input_fle_nm[:-4], \n",
    "                          \"File_Name\": input_fle_nm, \n",
    "                          \"df_Name\": \"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                          \"Data\": \"\", \n",
    "                          \"Avg_Streamflow\": \"\",\n",
    "                          \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "# Append to the File Names to the Directory\n",
    "    statn_data_lst_of_dicts.append(dict(input_fle_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "statn_data_lst_of_dicts\n",
    "# del statn_data_lst_of_dicts[0]\n",
    "# statn_data_lst_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[1]['Station_Nmbr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, station in enumerate(dict_nm[key]):\n",
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "    print(statn_data_lst_of_dicts[i]['File_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = list(a_dict.keys())\n",
    "type(county)\n",
    "county[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_series = pd.Series(data = [0,1,2,3,4], index = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"])\n",
    "a_series\n",
    "statn_data_lst_of_dicts\n",
    "a_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Break a Loop:\n",
    "#         - https://www.programiz.com/python-programming/break-continue\n",
    "\n",
    "# for i, station in enumerate(dict_nm[key]):\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 1 Loop Through Each County \n",
    "# *********************************************************************************************\n",
    "\n",
    "statns_wth_no_strmflw_data = []\n",
    "\n",
    "for i, county_dict in enumerate(cnty_lst):\n",
    "    print(f\"Index No: {i}\")\n",
    "# Get dictionary keys as a list\n",
    "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
    "    county_lst = list(county_dict.keys())\n",
    "    county = county_lst[0]\n",
    "    print(f\"County: {county}\")\n",
    "#     print(f\"Stations:\")\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each Station Within a County\n",
    "# *********************************************************************************************\n",
    "# \n",
    "    for station_dict in county_dict[county]:\n",
    "        station_lst_keys = list(station_dict.keys())\n",
    "        station_lst_File_Name = station_lst_keys[1]\n",
    "        station_lst_data = station_lst_keys[3]\n",
    "#         print(station_lst_keys)\n",
    "#         print(station_lst_File_Name)\n",
    "#         print(station_lst)\n",
    "        print(f\"Stations:{station_dict[station_lst_File_Name]}\")\n",
    "#     pprint.pprint(a_dict[county])\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3 - Create the File Path for the Stream Data\n",
    "# *********************************************************************************************\n",
    "\n",
    "# Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
    "        input_fle_path_fr_lp = input_fle_path + \"/\" + station_dict[station_lst_File_Name]\n",
    "#         print(f\"File Path: {input_fle_path_fr_lp}\")\n",
    "#         print(\"----------------------------------------------------\")\n",
    "        \n",
    "# Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "        df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "# *********************************************************************************************\n",
    "#             Step 4 - Loop Through the .txt File and Store the Data into a Dataframe\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "        with open(input_fle_path_fr_lp,'r') as fh:\n",
    "#             print(fh)\n",
    "#             print(\"----------------------------------------------------\")\n",
    "            for curline in dropwhile(is_comment, fh):\n",
    "#                 print(f\"Curline:\")\n",
    "#                 print(type(curline))\n",
    "#                 print(\"----------------------------------------------------\")\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "                to_append = curline[:-1].split(\"\\t\")\n",
    "#                 print(f\"To Append:\")\n",
    "#                 print(to_append)\n",
    "# #                 print(to_append[4])\n",
    "#                 print(\"----------------------------------------------------\")\n",
    "                \n",
    "                if len(to_append) == 5:\n",
    "#                     print(\"True\")\n",
    "            \n",
    "                    a_series = pd.Series(data = to_append, index = clmn_nms)\n",
    "#                     print(clmn_nms)\n",
    "#                     print(\"Series:\")\n",
    "#                     print(a_series)\n",
    "#                     print(\"----------------------------------------------------\")\n",
    "                    \n",
    "                        #             Dataframe\n",
    "    #             Dataframe Name\n",
    "#                     statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "                    df= df.append(a_series, ignore_index=True)\n",
    "\n",
    "                    \n",
    "            \n",
    "                elif len(to_append) < 5:\n",
    "                    statns_wth_no_strmflw_data.append(station_dict[station_lst_File_Name])\n",
    "                    break\n",
    "#                     print(f\"Station {station_dict[station_lst_File_Name]} Does not \")\n",
    "                    \n",
    "#     #             Dataframe\n",
    "#     #             Dataframe Name\n",
    "#                 statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "        if len(df) != 0:\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "            df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "            df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "            df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "            df['date']= pd.to_datetime(df['date'])\n",
    "\n",
    "# Calculate the Averge Streamflow Rate for the Station\n",
    "            avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "#     avg_strmflw = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_mean\"]\n",
    "            print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "    \n",
    "#     #             Append Data to the Dataframe           \n",
    "#             print(df)\n",
    "            station_dict[station_lst_data] = df\n",
    "            print(f\"Data:{station_dict[station_lst_data]}\")\n",
    "            print(\"----------------------------------------------------\")\n",
    "            \n",
    "    print(\"********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statns_wth_no_strmflw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(cnty_lst[0][\"Ada County\"][1][\"Data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Refernces:\n",
    "#     - Get a list of dates between two dates\n",
    "#         - https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-50.php\n",
    "#     - Check if a variable is string\n",
    "#         - https://www.geeksforgeeks.org/python-check-if-a-variable-is-string/\n",
    "\n",
    "\n",
    "bgn_date_datetime = datetime.datetime.strptime(bgn_date, '%Y-%m-%d')\n",
    "end_date_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "# Create Dataframe for the county and each day\n",
    "# cnty_date_df = pd.DataFrame()\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "# print(type(end_dt_datetime ))\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each Date\n",
    "# *********************************************************************************************\n",
    "\n",
    "for dt in daterange(bgn_date_datetime, end_date_datetime):\n",
    "    srch_date = dt.strftime(\"%Y-%m-%d\")\n",
    "#     print(dt.strftime(\"%Y-%m-%d\")) # This is a String\n",
    "    dly_strmflw_ttl = 0\n",
    "\n",
    "# Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "    srch_day_df = pd.DataFrame()\n",
    "#     cnty_date_df[srch_date] = \"\"\n",
    "    cnty_date_df[srch_date + \"_ttl_strmflw\"] = \"\"\n",
    "    cnty_date_df[srch_date + \"_cnty_prcnt_blw_extndd_avg\"] = \"\"\n",
    "    cnty_date_df[srch_date + \"wghtd__prcnt_blw_extndd_avg\"] = \"\" \n",
    "#     date_cnty_df_clmn_headr_nms.append(srch_date)\n",
    "#     date_cnty_df_rows\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each County\n",
    "# *********************************************************************************************\n",
    "    for i, county_dict in enumerate(cnty_lst):\n",
    "#         print(f\"Index No: {i}\")\n",
    "    \n",
    "    # Get dictionary keys as a list\n",
    "# https://www.geeksforgeeks.org/python-get-dictionary-keys-as-a-list/\n",
    "        county_lst = list(county_dict.keys())\n",
    "        county = county_lst[0]\n",
    "        cnty_dly_strmflw_ttl = 0\n",
    "#         print(f\"County List Keys: {county_lst}\")\n",
    "#         print(f\"County: {county}\")\n",
    "#         print(\"----------------------------------------------------\")\n",
    "#         print(\"----------------------------------------------------\")\n",
    "        nmbr_strms_blw_extndd_yrs_median = 0\n",
    "        ttl_nmbr_statns = 0\n",
    "\n",
    "\n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                    Step 2 Loop Through Each Station Within a County\n",
    "# *********************************************************************************************\n",
    "\n",
    "        for x, station_dict in enumerate(county_dict[county]):\n",
    "            station_lst_keys = list(station_dict.keys())\n",
    "            station_lst_statn_Name = station_lst_keys[0]\n",
    "            station_lst_data = station_lst_keys[3]\n",
    "#             print(station_lst_keys)\n",
    "#         print(station_lst_File_Name)\n",
    "#             print(station_lst)\n",
    "            print(f\"Stations:{station_dict[station_lst_statn_Name]}\")\n",
    "            df = station_dict[station_lst_data]\n",
    "#             print(type(df))\n",
    "#             pprint.pprint(cnty_lst[0][\"Ada County\"][0][\"Data\"][\"date\"])\n",
    "            data_df = cnty_lst[i][county][x][\"Data\"]\n",
    "#             print(data_df)\n",
    "#             print(f\"Data:{df}\")\n",
    "\n",
    "            ttl_nmbr_statns = ttl_nmbr_statns + 1\n",
    "\n",
    "# If the DataFrame is a String Data Type, Which Means it's Empty\n",
    "            if isinstance(data_df, str): \n",
    "                continue\n",
    "\n",
    "            elif not isinstance(data_df, str):\n",
    "# Find the Index for the Date \n",
    "                test_indx_lbl = data_df[data_df[\"date\"] == srch_date].index.tolist()\n",
    "                found_date = data_df[\"date\"][test_indx_lbl]\n",
    "                daily_strmflw_avg = data_df[\"streamflow_rate\"].values[test_indx_lbl]\n",
    "                daily_strmflw_avg = daily_strmflw_avg[0]\n",
    "                print(f\"Index: {test_indx_lbl}\")\n",
    "                cnty_dly_strmflw_ttl = cnty_dly_strmflw_ttl + daily_strmflw_avg\n",
    "                print(f\"Date: {found_date}\")\n",
    "                print(f\"Daily Streamflow Average: {daily_strmflw_avg}\")\n",
    "                print(type(daily_strmflw_avg))\n",
    "                print(\"----------------------------------------------------\")\n",
    "# Is the Daily Streamflow Below the Streams Extended Streamflow Average\n",
    "                statn_indx_lbl = statn_table_df_splt_StatnNmbr_test[statn_table_df_splt_StatnNmbr_test[\"numbers\"] == station_dict[station_lst_statn_Name]].index.tolist()\n",
    "                extndd_yrs_median_array = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_median\"].values[statn_indx_lbl]\n",
    "                extndd_yrs_median = extndd_yrs_median_array[0]\n",
    "                print(statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_median\"][statn_indx_lbl])\n",
    "                print(f\"Extended Years Median: {extndd_yrs_median}\")\n",
    "                print(type(extndd_yrs_median))\n",
    "                print(\"----------------------------------------------------\")\n",
    "            \n",
    "                \n",
    "                if daily_strmflw_avg < extndd_yrs_median:\n",
    "                    print(f\"{daily_strmflw_avg} < {extndd_yrs_median}\")\n",
    "                    nmbr_strms_blw_extndd_yrs_median = nmbr_strms_blw_extndd_yrs_median + 1\n",
    "        \n",
    "        print(\"====================================================\")\n",
    "        print(f\"{county} Daily Streamflow Average: {cnty_dly_strmflw_ttl}\")\n",
    "        dly_strmflw_ttl = dly_strmflw_ttl + cnty_dly_strmflw_ttl\n",
    "        print(f\"Total Number of Stations Below Extended Average: {nmbr_strms_blw_extndd_yrs_median}\")\n",
    "        print(\"====================================================\")\n",
    "        \n",
    "# Add the Total Number of Stations and Total Number of Stations Who's Daily Streamflow Average\n",
    "# was Below the Extended Streamflow Average. County Daily Streamflow Create a dataframe with the county and each day\n",
    "#         I need total Streamflow amount and percent of streams below extended average\n",
    "\n",
    "        # Find the Index for the Date \n",
    "        cnty_date_df_indx_lbl = cnty_date_df[cnty_date_df[\"idaho_counties\"] == county].index.tolist()\n",
    "        \n",
    "        cnty_date_df[srch_date + \"_ttl_strmflw\"][cnty_date_df_indx_lbl] = cnty_dly_strmflw_ttl\n",
    "        cnty_strms_prcnt_blw_extndd_avg = ttl_nmbr_statns / ttl_nmbr_statns\n",
    "        cnty_date_df[srch_date + \"_cnty_prcnt_blw_extndd_avg\"][cnty_date_df_indx_lbl] = cnty_strms_prcnt_blw_extndd_avg \n",
    "        \n",
    "        \n",
    "    print(\"====================================================\")\n",
    "    print(f\"{srch_date} Daily Streamflow Average: {dly_strmflw_ttl}\")\n",
    "    print(\"====================================================\")\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# # Create a dataframe with the county, each day, weighted average,\n",
    "# # Weighted Average\n",
    "#     print(\"====================================================\")\n",
    "#     wghtd_avg = cnty_dly_strmflw_ttl / dly_strmflw_ttl\n",
    "#     print(f\"{srch_date} Daily Streamflow Average: {dly_strmflw_ttl}\")\n",
    "#     print(\"====================================================\")\n",
    "#     print(\"********************************************************************\")\n",
    "                \n",
    "# #     pprint.pprint(a_dict[county])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnty_date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst[\"Station_Nmbr\"][0]\n",
    "# input_fle_dict[\"File_Name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for station in input_fle_dict[\"df_Name\"]:\n",
    "#     print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_nm = input_fle_lst[0]\n",
    "input_fle_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40482738/how-to-name-dataframe-with-variables-in-pandas\n",
    "\n",
    "N = 10 # 5 in sample\n",
    "dfs = {'name' + str(i):df for i in range(1,N)}\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"name2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # 5 in sample\n",
    "# for input_fle_nm in input_fle_lst:\n",
    "input_fle_nm =\"\"\n",
    "dfs = {input_fle_nm:df for input_fle_nm in input_fle_dict[\"df_Name\"]}\n",
    "# print (input_fle_nm)\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[2]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "# *********************************************************************************************\n",
    "#                                   Step 1 Create Variables\n",
    "# *********************************************************************************************\n",
    "\n",
    "#     Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
    "    input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']\n",
    "\n",
    "#     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "    df = pd.DataFrame(columns = clmn_nms)\n",
    "#     print(df)\n",
    "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# *********************************************************************************************\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 2 Create a Dataframe for the Streamflow\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "    with open(input_fle_path_fr_lp,'r') as fh:\n",
    "        for curline in dropwhile(is_comment, fh):\n",
    "#             print(curline)\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "            to_append = curline[:-1].split(\"\\t\")\n",
    "            a_series = pd.Series(to_append, index = clmn_nms)\n",
    "            print(a_series)\n",
    "            print(\"********************************************************************\")\n",
    "    #             Dataframe\n",
    "    #             Dataframe Name\n",
    "            statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "            df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(input_fle_nm)\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "    df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "    df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "    df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "    avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "#     avg_strmflw = statn_table_df_splt_StatnNmbr_test[\"extndd_yrs_mean\"]\n",
    "    print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "#     print(df[\"streamflow_rate\"])\n",
    "#     print(\"********************************************************************\")\n",
    "    print (df)\n",
    "    \n",
    "    count = 0\n",
    "    print(len(df))\n",
    "    \n",
    "    for i_df in range(len(df)):\n",
    "#         print (df[\"streamflow_rate\"][2])\n",
    "        print (df[\"streamflow_rate\"][i_df])\n",
    "#         print (df_row)\n",
    "        if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "            count = count + 1\n",
    "            \n",
    "            print (\"True\")\n",
    "        elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "            print (\"False\")\n",
    "        print(\"********************************************************************\")\n",
    "        print(\"********************************************************************\")\n",
    "\n",
    "    pct_blw_avg = (count / len(df) * 100)\n",
    "    print (pct_blw_avg)\n",
    "# Add a value into an empty dictionay element\n",
    "#     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "    statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "    statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "    statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "#     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "    # df_nm = df_nm.drop(index = [0, 1])\n",
    "    # \"_\" + statn_nm + \"_df\" = df\n",
    "    # df_nm\n",
    "    # df\n",
    "    # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next Step, take the total number of streams that are below its 38 year average and create a\n",
    "precent of that per day (calculate a percent by county then a total precent for the state (Use \n",
    "weighted averaging for the county and for the state, so that bigger streams have more weight in the\n",
    "precent)). This will tell us how many streams are below average per day and we can relate that to \n",
    "how many fires were reported that day and how many lightning strikes occured that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts\n",
    "# statn_data_lst_of_dicts[0]\n",
    "# statn_data_lst_of_dicts[0][\"Data\"]\n",
    "\n",
    "# data_df = statn_data_lst_of_dicts[0][\"Data\"]\n",
    "# data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Refernces:\n",
    "#     - Get a list of dates between two dates\n",
    "#         - https://www.w3resource.com/python-exercises/date-time-exercise/python-date-time-exercise-50.php\n",
    "\n",
    "\n",
    "bgn_date_datetime = datetime.datetime.strptime(bgn_date, '%Y-%m-%d')\n",
    "end_date_datetime = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "\n",
    "start_dt = date(2015, 12, 20)\n",
    "end_dt = date(2016, 1, 11)\n",
    "# print(type(end_dt_datetime ))\n",
    "\n",
    "for dt in daterange(bgn_date_datetime, end_date_datetime):\n",
    "    \n",
    "    print(dt.strftime(\"%Y-%m-%d\")) # This is a String\n",
    "#     print(type(dt.strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "        # Find the Index for the Station  \n",
    "#     test_indx_lbl = data_df[data_df[\"date\"] == dt].index.tolist()\n",
    "\n",
    "#     print(f'Index No: {test_indx_lbl[0]}')\n",
    "#     print(f'Streamflow Rate: {data_df[\"streamflow_rate\"][test_indx_lbl[0]]}')\n",
    "#     print(\"********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Index for the Station  \n",
    "test_indx_lbl = data_df[data_df[\"date\"] == \"1990-01-05\"].index.tolist()\n",
    "\n",
    "print(f'Index No: {test_indx_lbl[0]}')\n",
    "print(f'Streamflow Rate: {data_df[\"streamflow_rate\"][test_indx_lbl[0]]}')\n",
    "\n",
    "\n",
    "\n",
    "# To Do:\n",
    "#     - Create a dataframe with the date, county name, total streamflow, average streamflow, weighted \n",
    "#         percent\n",
    "#     - Count how many Stations have a recorded streamflow for that day\n",
    "#         - Make and if statement: If the data exist then count_total else skip that station and go \n",
    "#             to the next station\n",
    "#         - If the data exist then sum the amount of water flowing in the streams for each county\n",
    "#             - Weighted precent for each stream per day\n",
    "#             - Use the count_county and weighted_average_percent to create a streamflow weighted \n",
    "#                 average per county (weighted average is how many county streams are below it's\n",
    "#                 extended average)\n",
    "#             - Add the streamflow rate to the state streamflow\n",
    "#             - Create streamflow weighted average for the state of Idaho using the county streamflow\n",
    "#                 (weighted average is how many county streams are below it's extended average)\n",
    "#             - Append the streamflow weighted average to the new dataframe\n",
    "#                  - The dataframe would include the date, streamflow weighted average, lightning\n",
    "#                      strikes, average prcp, average temp., average humdity, dew point, number of \n",
    "#                      camping permits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"_\" + input_fle_nm + \"_df\")\n",
    "# test = \"_\" + input_fle_nm\n",
    "# test[:-4]\n",
    "# input_fle_dict[\"df_Name\"]\n",
    "# _13073000_df.head()\n",
    "# _13206000_df.drop(index = [0, 1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict['Station_Nmbr'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
    "\n",
    "count = 0 \n",
    "\n",
    "with open(input_fle_path,'r') as fh:\n",
    "    for curline in dropwhile(is_comment, fh):\n",
    "        print(f\"Index Number: {count} {curline}\")\n",
    "        count = count + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe for the Data\n",
    "\n",
    "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]\n",
    "\n",
    "_13206000_df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a String\n",
    "#     - https://www.geeksforgeeks.org/python-string-split/\n",
    "# Pandas Series\n",
    "#     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "\n",
    "print(type(curline))\n",
    "print(curline)\n",
    "print((curline.split(\"\\t\")))\n",
    "print(type(curline.split(\"\\t\")))\n",
    "\n",
    "to_append = curline[:-1].split(\"\\t\")\n",
    "a_series = pd.Series(to_append, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Lighting Data from the National Centers for Enviromental Information (NCEI) National Oceanic and Atmospheric Administration (NOAA) Severe Weather Data Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Create the Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://www.ncdc.noaa.gov/severe-weather/severe-weather-data-inventory\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Map Search')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "year = \"2001\"\n",
    "\n",
    "\n",
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//input[@class='esri-input esri-search__input'])[1]\"))).send_keys(\"Idaho, USA\")\n",
    "# time.sleep(5)\n",
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='esri-search__submit-button esri-widget--button'])[1]\"))).click()\n",
    "# time.sleep(10)\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='custom-select swdi-select']/option[text()=\" + dataset + \"])\"))).click()\n",
    "\n",
    "# # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "# driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()=\" + year + \"]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Get All the Options in the Dropdown List:\n",
    "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "#     - Remove a List of Unwanted Characters from a String:\n",
    "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "\n",
    "\n",
    "yrs_lghtnng_strks = [\"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]\n",
    "dataset = \"Lightning Strikes\"\n",
    "\n",
    "lghtnng_strks_df = pd.DataFrame()\n",
    "bad_chars = ['(', 'events)']\n",
    "\n",
    "for yr in yrs_lghtnng_strks:\n",
    "    WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + yr + \"])\"))).click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
    "    select.select_by_visible_text(dataset)    \n",
    "    \n",
    "    time.sleep(15)\n",
    "    \n",
    "    lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "    options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "    \n",
    "    for element in options:\n",
    "#     print (element.get_attribute(\"text\"))\n",
    "        text = element.get_attribute(\"text\")\n",
    "\n",
    "        count = 1\n",
    "    \n",
    "        for i in bad_chars:\n",
    "            text = text.replace(i, \"\")\n",
    "            \n",
    "            if count == 2:\n",
    "                text = text.replace(i, \"\")\n",
    "#                 print (text.split())\n",
    "#                 print (text.split()[0])\n",
    "#                 print (text.split()[1])\n",
    "#                 print (\"**************************\")\n",
    "                count = 0\n",
    "\n",
    "                lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
    "                                                            \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
    "\n",
    "            count = 1 + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = lghtnng_strks_df\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many seconds of phone calls are recorded in total?\n",
    "# print(test_df['number_of_strikes'].sum())\n",
    "# test_df\n",
    "\n",
    "# test_df.groupby(['month']).groups.keys()\n",
    "\n",
    "# test_df.groupby([test_df[\"date\"].dt.month]).sum().reset_index()\n",
    "\n",
    "\n",
    "# Split the String into Just the Year-Month:\n",
    "#     - https://stackoverflow.com/questions/26646191/pandas-groupby-month-and-year\n",
    "\n",
    "def getYearMonth(s):\n",
    "  return s.split(\"-\")[0]+\"-\"+s.split(\"-\")[1]\n",
    "\n",
    "test_df['YearMonth']= test_df['date'].apply(lambda x: getYearMonth(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.dtypes)\n",
    "\n",
    "# Change the Date Column to a datetime Data Type\n",
    "# test_df['date']= pd.to_datetime(test_df['date'])\n",
    "# or\n",
    "# test_df.astype({'date': 'datetime64'})\n",
    "\n",
    "# Change the \"number_of_strikes\" Column to an Integer (\"int32\") Data Type\n",
    "test_df = test_df.astype({'number_of_strikes': 'int32'})\n",
    "print(\"*******************************************\")\n",
    "print(test_df.dtypes)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_YearMonth_df = test_df.groupby(\"YearMonth\")[\"number_of_strikes\"].sum()\n",
    "test_YearMonth_df = pd.DataFrame(test_YearMonth_df)\n",
    "test_YearMonth_df = test_YearMonth_df.reset_index()\n",
    "test_YearMonth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect'])\"))).click()\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect']/option[text()=\" + dataset + \"])\"))).click()\n",
    "# driver.find_element_by_xpath(\"//select[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
    "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
    "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']\").click()\n",
    "\n",
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
    "\n",
    "select.select_by_visible_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_YearMonth_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     Shading an area between two points in a matplotlib plot:\n",
    "#         - https://stackoverflow.com/questions/3681872/shading-an-area-between-two-points-in-a-matplotlib-plot\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(test_YearMonth_df))\n",
    "\n",
    "plt.figure(figsize = (25,20))\n",
    "plt.bar(x_axis, test_YearMonth_df[\"number_of_strikes\"])\n",
    "plt.xticks(x_axis, test_YearMonth_df[\"YearMonth\"], rotation = \"vertical\")\n",
    "plt.hlines(10,0,92, alpha = 1, color = \"red\")\n",
    "plt.axvspan(0, 3, color='y', alpha=0.4, lw=0) # Highlighting the 1992 Lightning Strikes\n",
    "plt.axvspan(4, 8, color='g', alpha=0.4, lw=0) # Highlighting the 1993 Lightning Strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "\n",
    "# lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "\n",
    "# options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "# print(options)\n",
    "\n",
    "# for element in options:\n",
    "#     print (element.get_attribute(\"text\").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Get All the Options in the Dropdown List:\n",
    "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "#     - Remove a List of Unwanted Characters from a String:\n",
    "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "\n",
    "lghtnng_strks_df = pd.DataFrame()\n",
    "\n",
    "lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "\n",
    "options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "bad_chars = ['(', 'events)']\n",
    "\n",
    "for element in options:\n",
    "#     print (element.get_attribute(\"text\"))\n",
    "    text = element.get_attribute(\"text\")\n",
    "    \n",
    "    count = 1\n",
    "    \n",
    "    for i in bad_chars:\n",
    "        text = text.replace(i, \"\")\n",
    "        \n",
    "        if count == 2:\n",
    "            text = text.replace(i, \"\")\n",
    "            print (text.split())\n",
    "            print (text.split()[0])\n",
    "            print (text.split()[1])\n",
    "            print (\"**************************\")\n",
    "            count = 0\n",
    "            \n",
    "            lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
    "                                                        \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
    "            \n",
    "        count = 1 + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lghtnng_strks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dropdown_value(year):\n",
    "    # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "    driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()='2001']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pythonspot.com/selenium-textbox/\n",
    "\n",
    "text_area = driver.find_element_by_class_name('esri-input esri-search__input')\n",
    "text_area.send_keys(\"This text is send using Python code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Mean Streamflow Rate for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "\n",
    "input_fle_dict[\"Data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)\n",
    "statn_data_lst_of_dicts[0][\"Data\"][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of a dictionary within a list (I modified this codes since my dictionary isn't in a list)\n",
    "#     - https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value\n",
    "\n",
    "def find_avg (lst, key, value):\n",
    "    for i, a_dict_2 in enumerate(lst):\n",
    "        print(a_dict_2[key])\n",
    "    #         print(input_fle_dict[\"Station_Nmbr\"])\n",
    "    #         print(\"********************************************************************\")\n",
    "#         if a_dict_2[key] == value:    \n",
    "#         if station == value:\n",
    "#             print(i)\n",
    "    \n",
    "                \n",
    "    \n",
    "#             avg_strmflw_rte = dict_nm[\"Data\"][i][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             dict_nm[\"Avg_Streamflow\"][i].append(avg_strmflw_rte )\n",
    "\n",
    "#             avg_strmflw = lst[i][\"Data\"][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             lst[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "        \n",
    "#             return i # avg_strmflw_rte\n",
    "    #             print(\"********************************************************************\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"][0].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_avg(statn_data_lst_of_dicts, \"Station_Nmbr\", \"13206000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [{'id':'1234','name':'Jason'}, {'id':'2345','name':'Tom'}, {'id':'3456','name':'Art'}]\n",
    "\n",
    "tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None)\n",
    "tom_index\n",
    "\n",
    "# tom_index = next((index for (index, d) in enumerate(input_fle_dict) if d[\"Station_Nmbr\"] == 13075910), None)\n",
    "# print(tom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types1 = [type(k) for k in input_fle_dict[\"Station_Nmbr\"]]\n",
    "types1\n",
    "# type(13075000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = [{'id':'1234','name':'Jason'},\n",
    "         {'id':'2345','name':'Tom'},\n",
    "         {'id':'3456','name':'Art'}]\n",
    "\n",
    "def find_index(dicts, key, value):\n",
    "    class Null: pass\n",
    "    for i, d in enumerate(dicts):\n",
    "        if d.get(key, Null) == value:\n",
    "            return d\n",
    "    else:\n",
    "        raise ValueError('no dict with the key and value combination found')\n",
    "\n",
    "print (find_index(dicts, 'name', 'Tom'))\n",
    "# 1\n",
    "# find_index(dicts, 'name', 'Ensnare')\n",
    "# ValueError: no dict with the key and value combination found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, key, value):\n",
    "#     i = 0\n",
    "    for i, dic in enumerate(lst):\n",
    "        print(lst)\n",
    "        print(dic)\n",
    "        print(\"********************************************************************\")\n",
    "        if dic[key] == value:\n",
    "            return i\n",
    "            print(\"********************************************************************\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find(lst, \"name\", \"Tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "search_key = \"13075000\"\n",
    "\n",
    "temp = list(input_fle_dict.items())  Station_Nmbr\n",
    "res = list(input_fle_dict.keys()).index(search_key) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
    "    \n",
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "    temp = list(test_dict.items())  \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0] == search_key] \n",
    "    \n",
    "    \n",
    "    input_fle_dict[\"Data\"][0][\"streamflow_rate\"] = input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Data/Idaho_Streamflow_Data/13206000.txt\", \"r\")\n",
    "lines = file.readlines()[26:]\n",
    "\n",
    "print(type(lines))\n",
    "print(lines)\n",
    "\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a Row from the List\n",
    "#     - https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del lines[0:1]\n",
    "lines\n",
    "# print((lines[1].split(\"\\t\")))\n",
    "test = lines[1][:-1].split(\"\\t\")\n",
    "test\n",
    "\n",
    "a_series = pd.Series(test, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Text File and Convert to a Dataframe\n",
    "data = pd.read_csv('Data/Idaho_Streamflow_Data/13206000.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Empty Rows\n",
    "import numpy as np\n",
    "np.where(pd.isnull(statn_table_df_splt_StatnNmbr_nmbrs_clmn))\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"] = statn_table_df[\"StationNumber\"].astype(str)\n",
    "print(statn_table.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if \"County\" in statn_table[\"StationNumber\"][0]:\n",
    "        print(\"true\")\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([0, 4], axis = 0)\n",
    "statn_table_df_drp_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the County Names from the Table\n",
    "# test = statn_table.drop([0, 4], axis = 0)\n",
    "# test.head()\n",
    "\n",
    "# Count the number of Rows in the Dataframe\n",
    "count = 0\n",
    "for statn_table_df_row in statn_table_df.index:\n",
    "\n",
    "    if \"County\" in statn_table_df[\"StationNumber\"][statn_table_df_row]:\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([statn_table_df_row], axis = 0)\n",
    "        count = count + 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_drp_cnty.head(15)\n",
    "# statn_table_df_drp_cnty.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statn_table_df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# Select(driver.find_element_by_id('rdb'))\n",
    "\n",
    "tab_sprtd_rado = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(tab_sprtd_rado)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# url = \"https://www.usgs.gov/\"\n",
    "browser.visit(url)\n",
    "window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Collect the latest News Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
