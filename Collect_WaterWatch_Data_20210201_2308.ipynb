{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ---------------------------------------------------------\n",
    "import pandas as pd\n",
    "# ---------------------------------------------------------\n",
    "from bs4 import BeautifulSoup as BS\n",
    "# ---------------------------------------------------------\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "# ---------------------------------------------------------\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "# ---------------------------------------------------------\n",
    "from itertools import dropwhile\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# import pymongo\n",
    "# import time\n",
    "# import datetime\n",
    "# import requests\n",
    "# import datefinder\n",
    "# from splinter import Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Tried to Scrape the Table Using Pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This did not work b/c the table is created with JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Different Insurance Websites\n",
    "River_Stream_7Day_Flow_Conditions_Tables = pd.read_html(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(River_Stream_7Day_Flow_Conditions_Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "River_Stream_7Day_Flow_Conditions_Tables[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Scraping the Website with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' WaterWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# browser.visit(url)\n",
    "# window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click FULL IMAGE to see a large thumbnail of the featured image \n",
    "browser.click_link_by_id('st')\n",
    "# browser.fill('st', \"Idaho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Current Streamflow')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('group_table_by'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('county_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "sbmt_bttn = '//input[@type=\"submit\" and @value=\"go\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find All the Station Numbers Scrap the table with all the stations and use that table to loop \n",
    "# through and click each station's link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crrnt_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "statn_table = pd.read_html(crrnt_url)\n",
    "print(f\"Number of Tables on the current page: {len(statn_table)}\")\n",
    "statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(statn_table[1].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df = statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the text from the digits in the \"StationNumber\" column.\n",
    "# https://stackoverflow.com/questions/56851679/how-to-separate-pandas-column-that-contains-values-stored-as-text-and-numbers-in\n",
    "\n",
    "statn_table_df_splt_StatnNmbr = statn_table_df.join(statn_table_df.pop('StationNumber').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n",
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the \"numbers\" column from the \"statn_table_df_splt\" Dataframe\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn = pd.DataFrame(statn_table_df_splt_StatnNmbr[\"numbers\"])\n",
    "\n",
    "# Replace the Empty Rows with \"NaN\"\n",
    "# https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "\n",
    "nan_value = float(\"NaN\")\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.replace(\"\", nan_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Number of Null Values in the Dataframe\n",
    "# https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
    "\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"NaN\" Null Values\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls = statn_table_df_splt_StatnNmbr_nmbrs_clmn.dropna()\n",
    "print(f\"Number of Null Values: {statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.isna().sum()}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Convert the \"numbers\" column to an Interger Data Type\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"] = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"].astype(int)\n",
    "\n",
    "# print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgn_date = \"1990-01-01\"\n",
    "end_date = \"1990-01-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.index:\n",
    "   \n",
    "    # Find the Hyper Link for One Station\n",
    "    statn_nmbr = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"][row]\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\n",
    "    # driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\n",
    "    driver.find_element_by_xpath(\"//*[contains(text(),'\" +statn_nmbr+\"')]\").click()\n",
    "\n",
    "\n",
    "    # Select the Tab-separated Output format\n",
    "    lst_all_statns = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "    lst_all_statns_button = driver.find_element_by_xpath(lst_all_statns)\n",
    "    lst_all_statns_button.click()\n",
    "\n",
    "\n",
    "    # Enter Values for the Begin Date and End Date\n",
    "    # Fill in Input Fills\n",
    "    #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "    # Clear the Input Field\n",
    "    #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "    element = driver.find_element_by_name(\"begin_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(bgn_date)\n",
    "\n",
    "    element = driver.find_element_by_name(\"end_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(end_date)\n",
    "\n",
    "    # Press/Click a Button Without an ID\n",
    "    #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "    #     - https://stackoverflow.com/questions/21322116/using-selenium-in-python-to-click-select-a-radio-button/21322160\n",
    "\n",
    "    sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
    "\n",
    "    sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "    sbmt_bttn_button.click()\n",
    "\n",
    "\n",
    "#     from selenium.webdriver import ActionChains\n",
    "\n",
    "    actionChains = ActionChains(driver)\n",
    "\n",
    "\n",
    "    # Save the data file to This Computer\n",
    "\n",
    "    # How to Open and Write to a File on This Computer\n",
    "    #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "    # How to Change the Location of the File\n",
    "    #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "#     import urllib.request, urllib.error, urllib.parse\n",
    "#     import os\n",
    "\n",
    "\n",
    "    response = urllib.request.urlopen(driver.current_url)\n",
    "    webContent = response.read()\n",
    "\n",
    "    fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "    f = open(fle_nm, 'wb')\n",
    "    f.write(webContent)\n",
    "    f.close\n",
    "\n",
    "\n",
    "    driver.back()\n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "actionChains = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data file to This Computer\n",
    "\n",
    "# How to Open and Write to a File on This Computer\n",
    "#     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "# How to Change the Location of the File\n",
    "#     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import os\n",
    "\n",
    "# url='https://waterdata.usgs.gov/id/nwis/dv?cb_00060=on&format=rdb&site_no=13206000&referred_module=sw&period=&begin_date=1990-01-01&end_date=1990-12-31'\n",
    "\n",
    "response = urllib.request.urlopen(driver.current_url)\n",
    "webContent = response.read()\n",
    "\n",
    "output_fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "f = open(output_fle_nm, 'wb')\n",
    "f.write(webContent)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Create a Dataframe for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to Skip All of the Comments in the File\n",
    "#     https://cmdlinetips.com/2018/01/3-ways-to-read-a-file-and-skip-initial-comments-in-python/\n",
    "\n",
    "def is_comment(s):\n",
    "    \"\"\" function to check if a line\n",
    "         starts with some character.\n",
    "         Here # for comment\n",
    "    \"\"\"\n",
    "    # return true if a line starts with #\n",
    "    return s.startswith('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names for the Dataframe\n",
    "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the Files\n",
    "input_fle_path = os.path.join(\"Data\", \"Idaho_Streamflow_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Data Types for the Dataframe\n",
    "convert_dict = {\n",
    "                \"streamflow_rate\": float\n",
    "               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # List of Files in a Directory\n",
    "# #     - https://careerkarma.com/blog/python-list-files-in-directory/\n",
    "\n",
    "# input_fle_lst = os.listdir(\"Data/Idaho_Streamflow_Data\")\n",
    "# print(input_fle_lst)\n",
    "# # input_fle_nm = input_fle_lst[0]\n",
    "# # print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # How to Ignore Hidden Files\n",
    "# #     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# # Create a List of the Files in the Directory\n",
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": []}\n",
    "\n",
    "# for input_fle_nm in os.listdir(input_fle_path):\n",
    "#     if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "\n",
    "# #         Append to the File Names to the Directory\n",
    "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "# #         print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # Create a List of the Files in the Directory\n",
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# Create a List to Store/Save the Streamflow Data, Data will be Saved as a List of Dictionaries\n",
    "statn_data_lst = []\n",
    "input_fle_dict = {}\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "# # *********************************************************************************************\n",
    "# #         Append to the File Names to the Directory\n",
    "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "# #         print(input_fle_nm)\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "        input_fle_dict = {\"Station_Nmbr\": input_fle_nm[:-4], \n",
    "                          \"File_Name\": input_fle_nm, \n",
    "                          \"df_Name\": \"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                          \"Data\": \"\", \n",
    "                          \"Avg_Streamflow\": \"\"}\n",
    "\n",
    "# Append to the File Names to the Directory\n",
    "    statn_data_lst.append(dict(input_fle_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'Station_Nmbr': '13073000',\n",
       "  'File_Name': '13073000.txt',\n",
       "  'df_Name': '_13073000_df',\n",
       "  'Data': '',\n",
       "  'Avg_Streamflow': ''},\n",
       " {'Station_Nmbr': '13075000',\n",
       "  'File_Name': '13075000.txt',\n",
       "  'df_Name': '_13075000_df',\n",
       "  'Data': '',\n",
       "  'Avg_Streamflow': ''},\n",
       " {'Station_Nmbr': '13075910',\n",
       "  'File_Name': '13075910.txt',\n",
       "  'df_Name': '_13075910_df',\n",
       "  'Data': '',\n",
       "  'Avg_Streamflow': ''},\n",
       " {'Station_Nmbr': '13206000',\n",
       "  'File_Name': '13206000.txt',\n",
       "  'df_Name': '_13206000_df',\n",
       "  'Data': '',\n",
       "  'Avg_Streamflow': ''}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statn_data_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"][0]\n",
    "# input_fle_dict[\"File_Name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in input_fle_dict[\"df_Name\"]:\n",
    "    print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_nm = input_fle_lst[0]\n",
    "input_fle_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40482738/how-to-name-dataframe-with-variables-in-pandas\n",
    "\n",
    "N = 10 # 5 in sample\n",
    "dfs = {'name' + str(i):df for i in range(1,N)}\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"name2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # 5 in sample\n",
    "# for input_fle_nm in input_fle_lst:\n",
    "input_fle_nm =\"\"\n",
    "dfs = {input_fle_nm:df for input_fle_nm in input_fle_dict[\"df_Name\"]}\n",
    "# print (input_fle_nm)\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
    "\n",
    "    input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
    "\n",
    "    # count = 0 \n",
    "\n",
    "    # Create Dataframe\n",
    "    df = pd.DataFrame(columns = clmn_nms)\n",
    "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "\n",
    "    with open(input_fle_path,'r') as fh:\n",
    "        for curline in dropwhile(is_comment, fh):\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "            to_append = curline[:-1].split(\"\\t\")\n",
    "            a_series = pd.Series(to_append, index = clmn_nms)\n",
    "\n",
    "    #             Dataframe\n",
    "    #             Dataframe Name\n",
    "            statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "            df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(input_fle_nm)\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "    df = df.drop(index = [0, 1])\n",
    "# Change the Data Types of Each Column\n",
    "    df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "    input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "    # df_nm = df_nm.drop(index = [0, 1])\n",
    "    # \"_\" + statn_nm + \"_df\" = df\n",
    "    # df_nm\n",
    "    # df\n",
    "    # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"_\" + input_fle_nm + \"_df\")\n",
    "# test = \"_\" + input_fle_nm\n",
    "# test[:-4]\n",
    "# input_fle_dict[\"df_Name\"]\n",
    "# _13073000_df.head()\n",
    "# _13206000_df.drop(index = [0, 1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict['Station_Nmbr'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
    "\n",
    "count = 0 \n",
    "\n",
    "with open(input_fle_path,'r') as fh:\n",
    "    for curline in dropwhile(is_comment, fh):\n",
    "        print(f\"Index Number: {count} {curline}\")\n",
    "        count = count + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe for the Data\n",
    "\n",
    "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]\n",
    "\n",
    "_13206000_df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a String\n",
    "#     - https://www.geeksforgeeks.org/python-string-split/\n",
    "# Pandas Series\n",
    "#     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "\n",
    "print(type(curline))\n",
    "print(curline)\n",
    "print((curline.split(\"\\t\")))\n",
    "print(type(curline.split(\"\\t\")))\n",
    "\n",
    "to_append = curline[:-1].split(\"\\t\")\n",
    "a_series = pd.Series(to_append, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Mean Streamflow Rate for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "\n",
    "input_fle_dict[\"Data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of a dictionary within a list (I modified this codes since my dictionary isn't in a list)\n",
    "#     - https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value\n",
    "\n",
    "def find_avg (dict_nm, key, value):\n",
    "    for i, station in enumerate(dict_nm[key]):\n",
    "    #         print(i)\n",
    "    #         print(input_fle_dict[\"Station_Nmbr\"])\n",
    "    #         print(\"********************************************************************\")\n",
    "            if station == value:\n",
    "                print(i)\n",
    "                avg_strmflw_rte = dict_nm[\"Data\"][i][\"streamflow_rate\"].mean(axis = 0)\n",
    "                dict_nm[\"Avg_Streamflow\"][i].append(avg_strmflw_rte )\n",
    "                return avg_strmflw_rte\n",
    "    #             print(\"********************************************************************\")\n",
    "    #     return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"][0].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_avg(input_fle_dict, \"Station_Nmbr\", \"13073000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [{'id':'1234','name':'Jason'}, {'id':'2345','name':'Tom'}, {'id':'3456','name':'Art'}]\n",
    "\n",
    "tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None)\n",
    "tom_index\n",
    "\n",
    "# tom_index = next((index for (index, d) in enumerate(input_fle_dict) if d[\"Station_Nmbr\"] == 13075910), None)\n",
    "# print(tom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types1 = [type(k) for k in input_fle_dict[\"Station_Nmbr\"]]\n",
    "types1\n",
    "# type(13075000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts = [{'id':'1234','name':'Jason'},\n",
    "#          {'id':'2345','name':'Tom'},\n",
    "#          {'id':'3456','name':'Art'}]\n",
    "\n",
    "def find_index(dicts, key, value):\n",
    "    class Null: pass\n",
    "    for i, d in enumerate(dicts):\n",
    "        if d.get(key, Null) == value:\n",
    "            return d\n",
    "    else:\n",
    "        raise ValueError('no dict with the key and value combination found')\n",
    "\n",
    "print (find_index(dicts, 'name', 'Tom'))\n",
    "# 1\n",
    "# find_index(dicts, 'name', 'Ensnare')\n",
    "# ValueError: no dict with the key and value combination found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, key, value):\n",
    "#     i = 0\n",
    "    for i, dic in enumerate(lst):\n",
    "        print(lst)\n",
    "        print(dic)\n",
    "        print(\"********************************************************************\")\n",
    "        if dic[key] == value:\n",
    "            return i\n",
    "            print(\"********************************************************************\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find(lst, \"name\", \"Tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "search_key = \"13075000\"\n",
    "\n",
    "temp = list(input_fle_dict.items())  Station_Nmbr\n",
    "res = list(input_fle_dict.keys()).index(search_key) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
    "    \n",
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "    temp = list(test_dict.items())  \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0] == search_key] \n",
    "    \n",
    "    \n",
    "    input_fle_dict[\"Data\"][0][\"streamflow_rate\"] = input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Data/Idaho_Streamflow_Data/13206000.txt\", \"r\")\n",
    "lines = file.readlines()[26:]\n",
    "\n",
    "print(type(lines))\n",
    "print(lines)\n",
    "\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a Row from the List\n",
    "#     - https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del lines[0:1]\n",
    "lines\n",
    "# print((lines[1].split(\"\\t\")))\n",
    "test = lines[1][:-1].split(\"\\t\")\n",
    "test\n",
    "\n",
    "a_series = pd.Series(test, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Text File and Convert to a Dataframe\n",
    "data = pd.read_csv('Data/Idaho_Streamflow_Data/13206000.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Empty Rows\n",
    "import numpy as np\n",
    "np.where(pd.isnull(statn_table_df_splt_StatnNmbr_nmbrs_clmn))\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"] = statn_table_df[\"StationNumber\"].astype(str)\n",
    "print(statn_table.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if \"County\" in statn_table[\"StationNumber\"][0]:\n",
    "        print(\"true\")\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([0, 4], axis = 0)\n",
    "statn_table_df_drp_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the County Names from the Table\n",
    "# test = statn_table.drop([0, 4], axis = 0)\n",
    "# test.head()\n",
    "\n",
    "# Count the number of Rows in the Dataframe\n",
    "count = 0\n",
    "for statn_table_df_row in statn_table_df.index:\n",
    "\n",
    "    if \"County\" in statn_table_df[\"StationNumber\"][statn_table_df_row]:\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([statn_table_df_row], axis = 0)\n",
    "        count = count + 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_drp_cnty.head(15)\n",
    "# statn_table_df_drp_cnty.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statn_table_df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# Select(driver.find_element_by_id('rdb'))\n",
    "\n",
    "tab_sprtd_rado = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(tab_sprtd_rado)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# url = \"https://www.usgs.gov/\"\n",
    "browser.visit(url)\n",
    "window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Collect the latest News Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
