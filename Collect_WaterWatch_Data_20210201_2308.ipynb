{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ---------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# ---------------------------------------------------------\n",
    "from splinter import Browser\n",
    "# ---------------------------------------------------------\n",
    "from bs4 import BeautifulSoup as BS\n",
    "# ---------------------------------------------------------\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "# ---------------------------------------------------------\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "# ---------------------------------------------------------\n",
    "from itertools import dropwhile\n",
    "# ---------------------------------------------------------\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# import pymongo\n",
    "# import datetime\n",
    "# import requests\n",
    "# import datefinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLs for the Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS_WaterWatch_url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 00 - Scrape the Tables from USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Using Pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This did not work b/c the table is created with JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the USGS' WaterWatch Retrieval Summary of 7-day Flow Conditions Websites\n",
    "River_Stream_7Day_Flow_Conditions_Tables = pd.read_html(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(River_Stream_7Day_Flow_Conditions_Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "River_Stream_7Day_Flow_Conditions_Tables[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Scraping the Website with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' WaterWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "browser.visit(url)\n",
    "# window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click FULL IMAGE to see a large thumbnail of the featured image \n",
    "browser.click_link_by_id('st')\n",
    "# browser.fill('st', \"Idaho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(USGS_WaterWatch_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Current Streamflow')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('group_table_by'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('county_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "sbmt_bttn = '//input[@type=\"submit\" and @value=\"go\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find All the Station Numbers Scrap the table with all the stations and use that table to loop \n",
    "# through and click each station's link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "crrnt_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tables on the current page: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationNumber</th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)2/26</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)2/26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13206000</td>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13206305</td>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13206400</td>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>13011500</td>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>13011900</td>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>13013650</td>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>13015000</td>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>13018750</td>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StationNumber                                    Station name  \\\n",
       "0        Ada County                                      Ada County   \n",
       "1          13206000      BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2          13206305           BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3          13206400                        EAGLE DRAIN AT EAGLE, ID   \n",
       "4    Bannock County                                  Bannock County   \n",
       "..              ...                                             ...   \n",
       "271        13011500                      PACIFIC CREEK AT MORAN, WY   \n",
       "272        13011900          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273        13013650                        SNAKE RIVER AT MOOSE, WY   \n",
       "274        13015000                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275        13018750  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)2/26 Dailymeanstream- flow (ft3/s)2/26  \n",
       "0                     Ada County                        Ada County  \n",
       "1                            NaN                               271  \n",
       "2                            NaN                               235  \n",
       "3                            NaN                              7.38  \n",
       "4                 Bannock County                    Bannock County  \n",
       "..                           ...                               ...  \n",
       "271                          NaN                                --  \n",
       "272                          NaN                                --  \n",
       "273                          NaN                               849  \n",
       "274                          NaN                                --  \n",
       "275                          NaN                              1400  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "statn_table = pd.read_html(crrnt_url)\n",
    "print(f\"Number of Tables on the current page: {len(statn_table)}\")\n",
    "statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(statn_table[1].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df = statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)2/26</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)2/26</th>\n",
       "      <th>numbers</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td></td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271</td>\n",
       "      <td>13206000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235</td>\n",
       "      <td>13206305</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38</td>\n",
       "      <td>13206400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td></td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011500</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011900</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>849</td>\n",
       "      <td>13013650</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13015000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400</td>\n",
       "      <td>13018750</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Station name  \\\n",
       "0                                        Ada County   \n",
       "1        BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2             BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3                          EAGLE DRAIN AT EAGLE, ID   \n",
       "4                                    Bannock County   \n",
       "..                                              ...   \n",
       "271                      PACIFIC CREEK AT MORAN, WY   \n",
       "272          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273                        SNAKE RIVER AT MOOSE, WY   \n",
       "274                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)2/26 Dailymeanstream- flow (ft3/s)2/26   numbers  \\\n",
       "0                     Ada County                        Ada County             \n",
       "1                            NaN                               271  13206000   \n",
       "2                            NaN                               235  13206305   \n",
       "3                            NaN                              7.38  13206400   \n",
       "4                 Bannock County                    Bannock County             \n",
       "..                           ...                               ...       ...   \n",
       "271                          NaN                                --  13011500   \n",
       "272                          NaN                                --  13011900   \n",
       "273                          NaN                               849  13013650   \n",
       "274                          NaN                                --  13015000   \n",
       "275                          NaN                              1400  13018750   \n",
       "\n",
       "               text  \n",
       "0        Ada County  \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4    Bannock County  \n",
       "..              ...  \n",
       "271                  \n",
       "272                  \n",
       "273                  \n",
       "274                  \n",
       "275                  \n",
       "\n",
       "[276 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the text from the digits in the \"StationNumber\" column.\n",
    "# https://stackoverflow.com/questions/56851679/how-to-separate-pandas-column-that-contains-values-stored-as-text-and-numbers-in\n",
    "\n",
    "statn_table_df_splt_StatnNmbr = statn_table_df.join(statn_table_df.pop('StationNumber').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n",
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW CELL\n",
    "\n",
    "# if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "#     print(\"No County\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the \"numbers\" column from the \"statn_table_df_splt\" Dataframe\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn = pd.DataFrame(statn_table_df_splt_StatnNmbr[\"numbers\"])\n",
    "\n",
    "# Replace the Empty Rows with \"NaN\"\n",
    "# https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "\n",
    "nan_value = float(\"NaN\")\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.replace(\"\", nan_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Number of Null Values in the Dataframe\n",
    "# https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
    "\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null Values: numbers    0\n",
      "dtype: int64\n",
      "*********************************************************************************************************\n",
      "numbers    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove the \"NaN\" Null Values\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls = statn_table_df_splt_StatnNmbr_nmbrs_clmn.dropna()\n",
    "print(f\"Number of Null Values: {statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.isna().sum()}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Convert the \"numbers\" column to an Interger Data Type\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"] = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"].astype(int)\n",
    "\n",
    "# print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgn_date = \"1990-01-01\"\n",
    "end_date = \"1990-01-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Number: 13206000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 1\n",
      "********************************************************************************\n",
      "Station Number: 13206305\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 2\n",
      "********************************************************************************\n",
      "Station Number: 13206400\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 3\n",
      "********************************************************************************\n",
      "Station Number: 13073000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 5\n",
      "********************************************************************************\n",
      "Station Number: 13075000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 6\n",
      "********************************************************************************\n",
      "Station Number: 13075500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 7\n",
      "********************************************************************************\n",
      "Station Number: 13075910\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 8\n",
      "********************************************************************************\n",
      "Station Number: 10039500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 10\n",
      "********************************************************************************\n",
      "Station Number: 10068500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 11\n",
      "********************************************************************************\n",
      "Station Number: 12414900\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 13\n",
      "********************************************************************************\n",
      "Station Number: 12415070\n",
      "Number of Tables on the current page: 1\n",
      "No Extened Water Statistics\n",
      "********************************************************************************\n",
      "Station Number: 12415135\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 15\n",
      "********************************************************************************\n",
      "Station Number: 13060000\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 17\n",
      "********************************************************************************\n",
      "Station Number: 13062500\n",
      "Number of Tables on the current page: 2\n",
      "Index No: 18\n",
      "********************************************************************************\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@type=\"radio\" and @value=\"rdb\"]\"}\n  (Session info: chrome=88.0.4324.192)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dbb0979ccf19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlst_all_statns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'//input[@type=\"radio\" and @value=\"rdb\"]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mlst_all_statns_button\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_all_statns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mlst_all_statns_button\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[0;34m(self, xpath)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div/td[1]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@type=\"radio\" and @value=\"rdb\"]\"}\n  (Session info: chrome=88.0.4324.192)\n"
     ]
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.index:\n",
    "    \n",
    "    # Find the Hyper Link for One Station\n",
    "    statn_nmbr = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"][row]\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\n",
    "    # driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\n",
    "    driver.find_element_by_xpath(\"//*[contains(text(),'\" +statn_nmbr+\"')]\").click()\n",
    "\n",
    "\n",
    "    # Select the Tab-separated Output format\n",
    "    lst_all_statns = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "    lst_all_statns_button = driver.find_element_by_xpath(lst_all_statns)\n",
    "    lst_all_statns_button.click()\n",
    "\n",
    "\n",
    "    # Enter Values for the Begin Date and End Date\n",
    "    # Fill in Input Fills\n",
    "    #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "    # Clear the Input Field\n",
    "    #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "    element = driver.find_element_by_name(\"begin_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(bgn_date)\n",
    "\n",
    "    element = driver.find_element_by_name(\"end_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(end_date)\n",
    "\n",
    "    # Press/Click a Button Without an ID\n",
    "    #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "    #     - https://stackoverflow.com/questions/21322116/using-selenium-in-python-to-click-select-a-radio-button/21322160\n",
    "\n",
    "    sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
    "\n",
    "    sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "    sbmt_bttn_button.click()\n",
    "\n",
    "\n",
    "#     from selenium.webdriver import ActionChains\n",
    "\n",
    "    actionChains = ActionChains(driver)\n",
    "\n",
    "\n",
    "    # Save the data file to This Computer\n",
    "\n",
    "    # How to Open and Write to a File on This Computer\n",
    "    #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "    # How to Change the Location of the File\n",
    "    #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "#     import urllib.request, urllib.error, urllib.parse\n",
    "#     import os\n",
    "\n",
    "\n",
    "    response = urllib.request.urlopen(driver.current_url)\n",
    "    webContent = response.read()\n",
    "\n",
    "    fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "    f = open(fle_nm, 'wb')\n",
    "    f.write(webContent)\n",
    "    f.close\n",
    "\n",
    "# Go back to the original URL for the station\n",
    "    driver.back()\n",
    "    \n",
    "# Select the \"Time-series: Current/Historical Observations\" from the dropdown list, this will \n",
    "# create page which includes a table with extended streamflow statistics.\n",
    "\n",
    "    crrnt_hstrcl_obsrvtns = '//input[@value=\"uv\"]'\n",
    "    \n",
    "    select = Select(driver.find_element_by_id(\"select_data_1\"))\n",
    "    select.select_by_visible_text(\"Time-series:   Current/Historical Observations\")\n",
    "    \n",
    "# Get the extended year streamflow min, max, median, mean, 25th percentile, and 75th percentile\n",
    "    # https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "    \n",
    "    crrnt_hstrcl_obsrvtns_url = driver.current_url\n",
    "    crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
    "    print(f'Station Number: {statn_nmbr}')\n",
    "    print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
    "#     print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
    "    \n",
    "    if len(crrnt_hstrcl_obsrvtns_html) == 2:\n",
    "        \n",
    "#         print(crrnt_hstrcl_obsrvtns_html[1])\n",
    "\n",
    "        extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
    "\n",
    "\n",
    "        # Reference: \n",
    "    #     - Find column whose name contains a specific string:\n",
    "    #         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
    "\n",
    "    # print(extndd_yrs_sttstcs.columns)\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
    "        min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'Min Flow: {min_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
    "        max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'Max Flow: {max_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
    "        _25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'25th_prcntle: {_25th_prcntle_strmflw}')\n",
    "\n",
    "        extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
    "        _75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "#         print(f'75th_prcntle: {_75th_prcntle_strmflw}')\n",
    "\n",
    "\n",
    "\n",
    "            # References:\n",
    "        #     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
    "        #         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
    "        #     - Pandas update a cell:\n",
    "        #         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
    "\n",
    "\n",
    "        # Find the Index for the Station  \n",
    "        indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
    "        print(f'Index No: {indx_lbl[0]}')\n",
    "\n",
    "        # Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
    "        # Dataframe\n",
    "    # #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
    "\n",
    "    #     statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "        statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]\n",
    "    \n",
    "    elif len(crrnt_hstrcl_obsrvtns_html) < 2:\n",
    "        print(\"No Extened Water Statistics\")\n",
    "    \n",
    "    print(\"********************************************************************************\")\n",
    "    \n",
    "# Go back to the URL with the list of Stations and Counties\n",
    "    driver.back()\n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "actionChains = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data file to This Computer\n",
    "\n",
    "# How to Open and Write to a File on This Computer\n",
    "#     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "# How to Change the Location of the File\n",
    "#     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import os\n",
    "\n",
    "# url='https://waterdata.usgs.gov/id/nwis/dv?cb_00060=on&format=rdb&site_no=13206000&referred_module=sw&period=&begin_date=1990-01-01&end_date=1990-12-31'\n",
    "\n",
    "response = urllib.request.urlopen(driver.current_url)\n",
    "webContent = response.read()\n",
    "\n",
    "output_fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "f = open(output_fle_nm, 'wb')\n",
    "f.write(webContent)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crrnt_hstrcl_obsrvtns_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "crrnt_hstrcl_obsrvtns_html = pd.read_html(crrnt_hstrcl_obsrvtns_url)\n",
    "print(f\"Number of Tables on the current page: {len(crrnt_hstrcl_obsrvtns_html)}\")\n",
    "print(type(crrnt_hstrcl_obsrvtns_html[1]))\n",
    "\n",
    "extndd_yrs_sttstcs = crrnt_hstrcl_obsrvtns_html[1]\n",
    "extndd_yrs_sttstcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: \n",
    "#     - Find column whose name contains a specific string:\n",
    "#         - https://stackoverflow.com/questions/21285380/find-column-whose-name-contains-a-specific-string\n",
    "\n",
    "print(extndd_yrs_sttstcs.columns)\n",
    "extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Min' in col_nm]\n",
    "min_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if 'Max' in col_nm]\n",
    "max_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '25th' in col_nm]\n",
    "_25th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]\n",
    "\n",
    "extndd_yrs_sttstcs_cols = [col_nm for col_nm in extndd_yrs_sttstcs.columns if '75th' in col_nm]\n",
    "_75th_prcntle_strmflw = extndd_yrs_sttstcs_cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Median because I was the most drastic/losest streamflow\n",
    "extndd_yrs_sttstcs[\"Median\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Return the Index label if some condition is satisfied over a column in Pandas Dataframe:\n",
    "#         - geeksforgeeks.org/return-the-index-label-if-some-condition-is-satisfied-over-a-column-in-pandas-dataframe/\n",
    "#     - Pandas update a cell:\n",
    "#         - https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/\n",
    "\n",
    "statn_nmbr = \"13206305\"\n",
    "\n",
    "# Find the Index for the Station  \n",
    "indx_lbl = statn_table_df_splt_StatnNmbr[statn_table_df_splt_StatnNmbr[\"numbers\"] == statn_nmbr].index.tolist()\n",
    "print(indx_lbl[0])\n",
    "\n",
    "# Append the Extened Water Years Average to the \"statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls\"\n",
    "# Dataframe\n",
    "# statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_min\": indx_lbl}, ignore_index=True)\n",
    "statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_min\"] = extndd_yrs_sttstcs[min_strmflw][0]\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_max\": indx_lbl}, ignore_index=True)\n",
    "statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_max\"] = extndd_yrs_sttstcs[max_strmflw][0]\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_median\": indx_lbl}, ignore_index=True)\n",
    "statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_median\"] = extndd_yrs_sttstcs[\"Median\"][0]\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"extndd_yrs_mean\": indx_lbl}, ignore_index=True)\n",
    "statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"extndd_yrs_mean\"] = extndd_yrs_sttstcs[\"Mean\"][0]\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"25th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"25th_prcntle\"] = extndd_yrs_sttstcs[_25th_prcntle_strmflw][0]\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_test = statn_table_df_splt_StatnNmbr.append({\"75th_prcntle\": indx_lbl}, ignore_index=True)\n",
    "statn_table_df_splt_StatnNmbr_test.at[indx_lbl[0], \"75th_prcntle\"] = extndd_yrs_sttstcs[_75th_prcntle_strmflw][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I need to Do the above without knowing the column names!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)2/26</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)2/26</th>\n",
       "      <th>numbers</th>\n",
       "      <th>text</th>\n",
       "      <th>extndd_yrs_min</th>\n",
       "      <th>extndd_yrs_max</th>\n",
       "      <th>extndd_yrs_median</th>\n",
       "      <th>extndd_yrs_mean</th>\n",
       "      <th>25th_prcntle</th>\n",
       "      <th>75th_prcntle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td></td>\n",
       "      <td>Ada County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271</td>\n",
       "      <td>13206000</td>\n",
       "      <td></td>\n",
       "      <td>110.00</td>\n",
       "      <td>7020.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235</td>\n",
       "      <td>13206305</td>\n",
       "      <td></td>\n",
       "      <td>103.00</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.38</td>\n",
       "      <td>13206400</td>\n",
       "      <td></td>\n",
       "      <td>6.11</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td></td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PORTNEUF RIVER AT TOPAZ ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>13073000</td>\n",
       "      <td></td>\n",
       "      <td>89.00</td>\n",
       "      <td>823.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MARSH CREEK NR MCCAMMON ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.2</td>\n",
       "      <td>13075000</td>\n",
       "      <td></td>\n",
       "      <td>39.00</td>\n",
       "      <td>306.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PORTNEUF RIVER AT POCATELLO ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>13075500</td>\n",
       "      <td></td>\n",
       "      <td>159.00</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PORTNEUF RIVER NR TYHEE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383</td>\n",
       "      <td>13075910</td>\n",
       "      <td></td>\n",
       "      <td>335.00</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bear Lake County</td>\n",
       "      <td>Bear Lake County</td>\n",
       "      <td>Bear Lake County</td>\n",
       "      <td></td>\n",
       "      <td>Bear Lake County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BEAR RIVER AT BORDER, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ice</td>\n",
       "      <td>10039500</td>\n",
       "      <td></td>\n",
       "      <td>70.00</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BEAR RIVER AT PESCADERO ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ice</td>\n",
       "      <td>10068500</td>\n",
       "      <td></td>\n",
       "      <td>28.00</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>546.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Benewah County</td>\n",
       "      <td>Benewah County</td>\n",
       "      <td>Benewah County</td>\n",
       "      <td></td>\n",
       "      <td>Benewah County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ST MARIES RIVER NR SANTA, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420</td>\n",
       "      <td>12414900</td>\n",
       "      <td></td>\n",
       "      <td>70.00</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ST JOE RIVER AT SAINT MARIES, ID</td>\n",
       "      <td>23.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12415070</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ST JOE RIVER AT RAMSDELL NR ST MARIES ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2200</td>\n",
       "      <td>12415135</td>\n",
       "      <td></td>\n",
       "      <td>567.00</td>\n",
       "      <td>4790.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>3160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bingham County</td>\n",
       "      <td>Bingham County</td>\n",
       "      <td>Bingham County</td>\n",
       "      <td></td>\n",
       "      <td>Bingham County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SNAKE RIVER NR SHELLEY ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ice</td>\n",
       "      <td>13060000</td>\n",
       "      <td></td>\n",
       "      <td>1350.00</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>3060.0</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>4720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SNAKE RIVER AT BLACKFOOT ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ice</td>\n",
       "      <td>13062500</td>\n",
       "      <td></td>\n",
       "      <td>1500.00</td>\n",
       "      <td>14700.0</td>\n",
       "      <td>2670.0</td>\n",
       "      <td>3620.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>4330.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Station name Dailymeangage height(ft)2/26  \\\n",
       "0                                   Ada County                   Ada County   \n",
       "1   BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID                          NaN   \n",
       "2        BOISE RIVER SOUTH CHANNEL AT EAGLE ID                          NaN   \n",
       "3                     EAGLE DRAIN AT EAGLE, ID                          NaN   \n",
       "4                               Bannock County               Bannock County   \n",
       "5                   PORTNEUF RIVER AT TOPAZ ID                          NaN   \n",
       "6                   MARSH CREEK NR MCCAMMON ID                          NaN   \n",
       "7               PORTNEUF RIVER AT POCATELLO ID                          NaN   \n",
       "8                   PORTNEUF RIVER NR TYHEE ID                          NaN   \n",
       "9                             Bear Lake County             Bear Lake County   \n",
       "10                    BEAR RIVER AT BORDER, WY                          NaN   \n",
       "11                  BEAR RIVER AT PESCADERO ID                          NaN   \n",
       "12                              Benewah County               Benewah County   \n",
       "13                ST MARIES RIVER NR SANTA, ID                          NaN   \n",
       "14            ST JOE RIVER AT SAINT MARIES, ID                        23.40   \n",
       "15    ST JOE RIVER AT RAMSDELL NR ST MARIES ID                          NaN   \n",
       "16                              Bingham County               Bingham County   \n",
       "17                   SNAKE RIVER NR SHELLEY ID                          NaN   \n",
       "18                 SNAKE RIVER AT BLACKFOOT ID                          NaN   \n",
       "\n",
       "   Dailymeanstream- flow (ft3/s)2/26   numbers              text  \\\n",
       "0                         Ada County                  Ada County   \n",
       "1                                271  13206000                     \n",
       "2                                235  13206305                     \n",
       "3                               7.38  13206400                     \n",
       "4                     Bannock County              Bannock County   \n",
       "5                                118  13073000                     \n",
       "6                               53.2  13075000                     \n",
       "7                                210  13075500                     \n",
       "8                                383  13075910                     \n",
       "9                   Bear Lake County            Bear Lake County   \n",
       "10                               Ice  10039500                     \n",
       "11                               Ice  10068500                     \n",
       "12                    Benewah County              Benewah County   \n",
       "13                               420  12414900                     \n",
       "14                               NaN  12415070                     \n",
       "15                              2200  12415135                     \n",
       "16                    Bingham County              Bingham County   \n",
       "17                               Ice  13060000                     \n",
       "18                               Ice  13062500                     \n",
       "\n",
       "    extndd_yrs_min  extndd_yrs_max  extndd_yrs_median  extndd_yrs_mean  \\\n",
       "0              NaN             NaN                NaN              NaN   \n",
       "1           110.00          7020.0              274.0           1190.0   \n",
       "2           103.00          2570.0              219.0            410.0   \n",
       "3             6.11            23.0                7.7              9.9   \n",
       "4              NaN             NaN                NaN              NaN   \n",
       "5            89.00           823.0              153.0            172.0   \n",
       "6            39.00           306.0               90.0             99.0   \n",
       "7           159.00          1210.0              300.0            333.0   \n",
       "8           335.00          1470.0              501.0            546.0   \n",
       "9              NaN             NaN                NaN              NaN   \n",
       "10           70.00          1280.0              185.0            219.0   \n",
       "11           28.00          1830.0              110.0            333.0   \n",
       "12             NaN             NaN                NaN              NaN   \n",
       "13           70.00          1720.0              341.0            455.0   \n",
       "14             NaN             NaN                NaN              NaN   \n",
       "15          567.00          4790.0             2100.0           2180.0   \n",
       "16             NaN             NaN                NaN              NaN   \n",
       "17         1350.00         15000.0             3060.0           3770.0   \n",
       "18         1500.00         14700.0             2670.0           3620.0   \n",
       "\n",
       "    25th_prcntle  75th_prcntle  \n",
       "0            NaN           NaN  \n",
       "1          216.0        1270.0  \n",
       "2          167.0         273.0  \n",
       "3            6.1          13.0  \n",
       "4            NaN           NaN  \n",
       "5          128.0         191.0  \n",
       "6           67.0         113.0  \n",
       "7          249.0         372.0  \n",
       "8          430.0         559.0  \n",
       "9            NaN           NaN  \n",
       "10         140.0         260.0  \n",
       "11          76.0         546.0  \n",
       "12           NaN           NaN  \n",
       "13         188.0         603.0  \n",
       "14           NaN           NaN  \n",
       "15        1250.0        3160.0  \n",
       "16           NaN           NaN  \n",
       "17        2320.0        4720.0  \n",
       "18        2070.0        4330.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statn_table_df_splt_StatnNmbr_test.head(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Create a Dataframe for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to Skip All of the Comments in the File\n",
    "#     https://cmdlinetips.com/2018/01/3-ways-to-read-a-file-and-skip-initial-comments-in-python/\n",
    "\n",
    "def is_comment(s):\n",
    "    \"\"\" function to check if a line\n",
    "         starts with some character.\n",
    "         Here # for comment\n",
    "    \"\"\"\n",
    "    # return true if a line starts with #\n",
    "    return s.startswith('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names for the Dataframe\n",
    "clmn_nms = [\"agency\", \n",
    "            \"site_nmbr\", \n",
    "            \"date\", \n",
    "            \"streamflow_rate\", \n",
    "            \"approved/pending\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the Files\n",
    "input_fle_path = os.path.join(\"Data\", \"Idaho_Streamflow_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Data Types for the Dataframe\n",
    "convert_dict = {\n",
    "                \"streamflow_rate\": float\n",
    "               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of Files in a Directory\n",
    "#     - https://careerkarma.com/blog/python-list-files-in-directory/\n",
    "\n",
    "input_fle_lst = os.listdir(\"Data/Idaho_Streamflow_Data\")\n",
    "print(input_fle_lst)\n",
    "# input_fle_nm = input_fle_lst[0]\n",
    "# print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# Create a List of the Files in the Directory\n",
    "input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": []}\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "\n",
    "#         Append to the File Names to the Directory\n",
    "        input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "        input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "        input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr[\"text\"].last_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_1 = 0\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    "    \n",
    "    if row != \"\":\n",
    "#         print(row)\n",
    "        count_1 = count_1 + 1\n",
    "#         cnty_lst.append(row)\n",
    "        \n",
    "print(count_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnty_lst = [{}for x in range(51)]\n",
    "# cnty_lst[2].append(2050)\n",
    "# cnty_lst[1]\n",
    "cnty_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of list\n",
    "#     - https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "\n",
    "\n",
    "cnty_lst = [[]for x in range(51)]\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "statn_lst = []\n",
    "# cnty_lst = [[] * 154]\n",
    "new_dict = {}\n",
    "\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    " \n",
    "# *********************************************************************************************\n",
    "#                               Step 1: If the row is Not Empty\n",
    "# *********************************************************************************************\n",
    "    if row != \"\":\n",
    "        print(row)\n",
    "#         count_1 = count_1\n",
    "        cnty_lst[count_2].append(row)\n",
    "        cnty_lst[count_2].append([])\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# *********************************************************************************************\n",
    "\n",
    "    elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "        print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # #         count_3 = count_1\n",
    "# # #         print (count_3)\n",
    "# #         count_1 = 0\n",
    "\n",
    "\n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                                  \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "                                  \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                                  \"Data\": \"\", \n",
    "                                  \"Avg_Streamflow\": \"\",\n",
    "                                  \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "        cnty_lst[count_2][1].append(dict(new_dict))\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "    elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                                  \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                                  \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                                  \"Data\": \"\", \n",
    "                                  \"Avg_Streamflow\": \"\",\n",
    "                                  \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "        cnty_lst[count_2][1].append(dict(new_dict))\n",
    "        \n",
    "        count_2 = count_2 + 1\n",
    "# *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                               Step 4: Add 1 to the Count\n",
    "# *********************************************************************************************    \n",
    "    count_1 = count_1 + 1\n",
    "# *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statn_lst\n",
    "\n",
    "# cnty_lst[0][0].append(input_fle_dict)\n",
    "# cnty_lst[0][1].append(\"test\")\n",
    "# print(cnty_lst)\n",
    "print(cnty_lst[0])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][1])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][1][0])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][1][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnty_lst = []\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "statn_lst = []\n",
    "# cnty_lst = [[] * 154]\n",
    "new_dict = {}\n",
    "\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    " \n",
    "    \n",
    "    if count_1 + 1 < 276:\n",
    "# *********************************************************************************************\n",
    "#                               Step 1: If the row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        if row != \"\":\n",
    "            statn_lst = []  # This will be a list of dictionaries\n",
    "            cnty_nm = row\n",
    "#         print(row)\n",
    "# #         count_1 = count_1\n",
    "#         cnty_lst[count_2].append(row)\n",
    "#         cnty_lst[count_2].append([])\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# *********************************************************************************************\n",
    "\n",
    "        elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # #         count_3 = count_1\n",
    "# # #         print (count_3)\n",
    "# #         count_1 = 0\n",
    "\n",
    "\n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        elif row == \"\": #and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "        \n",
    "#         count_2 = count_2 + 1\n",
    "        \n",
    "            cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "        \n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************  \n",
    "    if count_1 + 1 > 275 and row == \"\":\n",
    "        print (count_1)\n",
    "\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        \n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                    \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                    \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                    \"Data\": \"\", \n",
    "                    \"Avg_Streamflow\": \"\",\n",
    "                    \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "        statn_lst.append(dict(new_dict))\n",
    "\n",
    "        cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "# *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                               Step 4: Add 1 to the Count\n",
    "# *********************************************************************************************    \n",
    "    count_1 = count_1 + 1\n",
    "# *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(cnty_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statn_lst\n",
    "# cnty_lst = {cnty_nm: statn_lst}\n",
    "# cnty_lst[0][0].append(input_fle_dict)\n",
    "# cnty_lst[0][1].append(\"test\")\n",
    "# print(cnty_lst)\n",
    "# print(\"********************************************************************\")\n",
    "# print(new_dict)\n",
    "# print(statn_lst)\n",
    "pprint.pprint(cnty_lst[50])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0])\n",
    "print(\"********************************************************************\")\n",
    "pprint.pprint(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_list = list(cnty_lst[0].keys())\n",
    "val_list = list(cnty_lst[0].values())\n",
    "key_list[0]\n",
    "print(cnty_lst[0][key_list[0]][0][\"File_Name\"])\n",
    "\n",
    "input_fle_path + \"/\" + cnty_lst[0][key_list[0]][0][\"File_Name\"]\n",
    "# val_list\n",
    "\n",
    "# position = val_list.index(1)\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "# *********************************************************************************************\n",
    "#     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "    df = pd.DataFrame(columns = clmn_nms)\n",
    "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# *********************************************************************************************\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 2 Create a Dataframe for the Streamflow\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "    with open(input_fle_path_fr_lp,'r') as fh:\n",
    "        for curline in dropwhile(is_comment, fh):\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "            to_append = curline[:-1].split(\"\\t\")\n",
    "            a_series = pd.Series(to_append, index = clmn_nms)\n",
    "\n",
    "    #             Dataframe\n",
    "    #             Dataframe Name\n",
    "            statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "            df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(input_fle_nm)\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "    df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "    df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "    df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "    avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "    print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "#     print(df[\"streamflow_rate\"])\n",
    "#     print(\"********************************************************************\")\n",
    "    print (df)\n",
    "    \n",
    "    count = 0\n",
    "    print(len(df))\n",
    "    \n",
    "    for i_df in range(len(df)):\n",
    "#         print (df[\"streamflow_rate\"][2])\n",
    "        print (df[\"streamflow_rate\"][i_df])\n",
    "#         print (df_row)\n",
    "        if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "            count = count + 1\n",
    "            \n",
    "            print (\"True\")\n",
    "        elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "            print (\"False\")\n",
    "        print(\"********************************************************************\")\n",
    "\n",
    "    pct_blw_avg = (count / len(df) * 100)\n",
    "    print (pct_blw_avg)\n",
    "# Add a value into an empty dictionay element\n",
    "#     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "    statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "    statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "    statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "#     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "    # df_nm = df_nm.drop(index = [0, 1])\n",
    "    # \"_\" + statn_nm + \"_df\" = df\n",
    "    # df_nm\n",
    "    # df\n",
    "    # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def find(name, path):\n",
    "for root, dirs, files in os.walk(input_fle_path):\n",
    "    if \"13073000.txt\" in files:\n",
    "        print (os.path.join(root, \"13073000.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(\"13073000.txt\", input_fle_path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(input_fle_path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # Create a List of the Files in the Directory\n",
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# Create a List to Store/Save the Streamflow Data, Data will be Saved as a List of Dictionaries\n",
    "statn_data_lst_of_dicts = []\n",
    "input_fle_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# Put the Station in a list by County Name\n",
    "# First Find the station in the county  \n",
    "\n",
    "if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "    print(\"No County\")\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "# Skip the Hidden Files in the Directory\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "# # *********************************************************************************************\n",
    "# #         Append to the File Names to the Directory\n",
    "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "# #         print(input_fle_nm)\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "        input_fle_dict = {\"Station_Nmbr\": input_fle_nm[:-4], \n",
    "                          \"File_Name\": input_fle_nm, \n",
    "                          \"df_Name\": \"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                          \"Data\": \"\", \n",
    "                          \"Avg_Streamflow\": \"\",\n",
    "                          \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "# Append to the File Names to the Directory\n",
    "    statn_data_lst_of_dicts.append(dict(input_fle_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del statn_data_lst_of_dicts[0]\n",
    "statn_data_lst_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[1]['Station_Nmbr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, station in enumerate(dict_nm[key]):\n",
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "    print(statn_data_lst_of_dicts[i]['File_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst[\"Station_Nmbr\"][0]\n",
    "# input_fle_dict[\"File_Name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in input_fle_dict[\"df_Name\"]:\n",
    "    print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_nm = input_fle_lst[0]\n",
    "input_fle_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40482738/how-to-name-dataframe-with-variables-in-pandas\n",
    "\n",
    "N = 10 # 5 in sample\n",
    "dfs = {'name' + str(i):df for i in range(1,N)}\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"name2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # 5 in sample\n",
    "# for input_fle_nm in input_fle_lst:\n",
    "input_fle_nm =\"\"\n",
    "dfs = {input_fle_nm:df for input_fle_nm in input_fle_dict[\"df_Name\"]}\n",
    "# print (input_fle_nm)\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[2]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "# *********************************************************************************************\n",
    "#                                   Step 1 Create Variables\n",
    "# *********************************************************************************************\n",
    "\n",
    "#     Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
    "    input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']\n",
    "\n",
    "#     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "    df = pd.DataFrame(columns = clmn_nms)\n",
    "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# *********************************************************************************************\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 2 Create a Dataframe for the Streamflow\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "    with open(input_fle_path_fr_lp,'r') as fh:\n",
    "        for curline in dropwhile(is_comment, fh):\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "            to_append = curline[:-1].split(\"\\t\")\n",
    "            a_series = pd.Series(to_append, index = clmn_nms)\n",
    "\n",
    "    #             Dataframe\n",
    "    #             Dataframe Name\n",
    "            statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "            df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(input_fle_nm)\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "    df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "    df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "    df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "    avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "    print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "#     print(df[\"streamflow_rate\"])\n",
    "#     print(\"********************************************************************\")\n",
    "    print (df)\n",
    "    \n",
    "    count = 0\n",
    "    print(len(df))\n",
    "    \n",
    "    for i_df in range(len(df)):\n",
    "#         print (df[\"streamflow_rate\"][2])\n",
    "        print (df[\"streamflow_rate\"][i_df])\n",
    "#         print (df_row)\n",
    "        if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "            count = count + 1\n",
    "            \n",
    "            print (\"True\")\n",
    "        elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "            print (\"False\")\n",
    "        print(\"********************************************************************\")\n",
    "\n",
    "    pct_blw_avg = (count / len(df) * 100)\n",
    "    print (pct_blw_avg)\n",
    "# Add a value into an empty dictionay element\n",
    "#     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "    statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "    statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "    statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "#     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "    # df_nm = df_nm.drop(index = [0, 1])\n",
    "    # \"_\" + statn_nm + \"_df\" = df\n",
    "    # df_nm\n",
    "    # df\n",
    "    # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next Step, take the total number of streams that are below its 38 year average and create a\n",
    "precent of that per day (calculate a percent by county then a total precent for the state (Use \n",
    "weighted averaging for the county and for the state, so that bigger streams have more weight in the\n",
    "precent)). This will tell us how many streams are below average per day and we can relate that to \n",
    "how many fires were reported that day and how many lightning strikes occured that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"_\" + input_fle_nm + \"_df\")\n",
    "# test = \"_\" + input_fle_nm\n",
    "# test[:-4]\n",
    "# input_fle_dict[\"df_Name\"]\n",
    "# _13073000_df.head()\n",
    "# _13206000_df.drop(index = [0, 1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict['Station_Nmbr'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
    "\n",
    "count = 0 \n",
    "\n",
    "with open(input_fle_path,'r') as fh:\n",
    "    for curline in dropwhile(is_comment, fh):\n",
    "        print(f\"Index Number: {count} {curline}\")\n",
    "        count = count + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe for the Data\n",
    "\n",
    "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]\n",
    "\n",
    "_13206000_df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a String\n",
    "#     - https://www.geeksforgeeks.org/python-string-split/\n",
    "# Pandas Series\n",
    "#     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "\n",
    "print(type(curline))\n",
    "print(curline)\n",
    "print((curline.split(\"\\t\")))\n",
    "print(type(curline.split(\"\\t\")))\n",
    "\n",
    "to_append = curline[:-1].split(\"\\t\")\n",
    "a_series = pd.Series(to_append, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Lighting Data from the National Centers for Enviromental Information (NCEI) National Oceanic and Atmospheric Administration (NOAA) Severe Weather Data Inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Create the Webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://www.ncdc.noaa.gov/severe-weather/severe-weather-data-inventory\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Map Search')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "year = \"2001\"\n",
    "\n",
    "\n",
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//input[@class='esri-input esri-search__input'])[1]\"))).send_keys(\"Idaho, USA\")\n",
    "# time.sleep(5)\n",
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='esri-search__submit-button esri-widget--button'])[1]\"))).click()\n",
    "# time.sleep(10)\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@class='custom-select swdi-select']/option[text()=\" + dataset + \"])\"))).click()\n",
    "\n",
    "# # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "# driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()=\" + year + \"]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + year + \"])\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Get All the Options in the Dropdown List:\n",
    "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "#     - Remove a List of Unwanted Characters from a String:\n",
    "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "\n",
    "\n",
    "yrs_lghtnng_strks = [\"1992\", \"1993\", \"1994\", \"1995\", \"1996\", \"1997\", \"1998\", \"1999\", \"2000\", \"2001\", \"2002\", \"2003\", \"2004\", \"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\"]\n",
    "dataset = \"Lightning Strikes\"\n",
    "\n",
    "lghtnng_strks_df = pd.DataFrame()\n",
    "bad_chars = ['(', 'events)']\n",
    "\n",
    "for yr in yrs_lghtnng_strks:\n",
    "    WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='yearSelect']/option[text()=\" + yr + \"])\"))).click()\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
    "    select.select_by_visible_text(dataset)    \n",
    "    \n",
    "    time.sleep(15)\n",
    "    \n",
    "    lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "    options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "    \n",
    "    for element in options:\n",
    "#     print (element.get_attribute(\"text\"))\n",
    "        text = element.get_attribute(\"text\")\n",
    "\n",
    "        count = 1\n",
    "    \n",
    "        for i in bad_chars:\n",
    "            text = text.replace(i, \"\")\n",
    "            \n",
    "            if count == 2:\n",
    "                text = text.replace(i, \"\")\n",
    "#                 print (text.split())\n",
    "#                 print (text.split()[0])\n",
    "#                 print (text.split()[1])\n",
    "#                 print (\"**************************\")\n",
    "                count = 0\n",
    "\n",
    "                lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
    "                                                            \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
    "\n",
    "            count = 1 + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = lghtnng_strks_df\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many seconds of phone calls are recorded in total?\n",
    "# print(test_df['number_of_strikes'].sum())\n",
    "# test_df\n",
    "\n",
    "# test_df.groupby(['month']).groups.keys()\n",
    "\n",
    "# test_df.groupby([test_df[\"date\"].dt.month]).sum().reset_index()\n",
    "\n",
    "\n",
    "# Split the String into Just the Year-Month:\n",
    "#     - https://stackoverflow.com/questions/26646191/pandas-groupby-month-and-year\n",
    "\n",
    "def getYearMonth(s):\n",
    "  return s.split(\"-\")[0]+\"-\"+s.split(\"-\")[1]\n",
    "\n",
    "test_df['YearMonth']= test_df['date'].apply(lambda x: getYearMonth(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.dtypes)\n",
    "\n",
    "# Change the Date Column to a datetime Data Type\n",
    "# test_df['date']= pd.to_datetime(test_df['date'])\n",
    "# or\n",
    "# test_df.astype({'date': 'datetime64'})\n",
    "\n",
    "# Change the \"number_of_strikes\" Column to an Integer (\"int32\") Data Type\n",
    "test_df = test_df.astype({'number_of_strikes': 'int32'})\n",
    "print(\"*******************************************\")\n",
    "print(test_df.dtypes)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_YearMonth_df = test_df.groupby(\"YearMonth\")[\"number_of_strikes\"].sum()\n",
    "test_YearMonth_df = pd.DataFrame(test_YearMonth_df)\n",
    "test_YearMonth_df = test_YearMonth_df.reset_index()\n",
    "test_YearMonth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect'])\"))).click()\n",
    "# WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.XPATH, \"(//*[@id='datasetSelect']/option[text()=\" + dataset + \"])\"))).click()\n",
    "# driver.find_element_by_xpath(\"//select[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
    "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']/option[text()=\" + dataset + \"]\").click()\n",
    "# driver.find_element_by_xpath(\"//*[@id='datasetSelect']\").click()\n",
    "\n",
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "select = Select(driver.find_element_by_id(\"datasetSelect\"))\n",
    "\n",
    "select.select_by_visible_text(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_YearMonth_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     Shading an area between two points in a matplotlib plot:\n",
    "#         - https://stackoverflow.com/questions/3681872/shading-an-area-between-two-points-in-a-matplotlib-plot\n",
    "\n",
    "\n",
    "x_axis = np.arange(len(test_YearMonth_df))\n",
    "\n",
    "plt.figure(figsize = (25,20))\n",
    "plt.bar(x_axis, test_YearMonth_df[\"number_of_strikes\"])\n",
    "plt.xticks(x_axis, test_YearMonth_df[\"YearMonth\"], rotation = \"vertical\")\n",
    "plt.hlines(10,0,92, alpha = 1, color = \"red\")\n",
    "plt.axvspan(0, 3, color='y', alpha=0.4, lw=0) # Highlighting the 1992 Lightning Strikes\n",
    "plt.axvspan(4, 8, color='g', alpha=0.4, lw=0) # Highlighting the 1993 Lightning Strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "\n",
    "# lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "\n",
    "# options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "# print(options)\n",
    "\n",
    "# for element in options:\n",
    "#     print (element.get_attribute(\"text\").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "#     - Get All the Options in the Dropdown List:\n",
    "#         - https://www.edureka.co/community/53559/how-get-all-options-dropdown-using-python-selenium-webdriver\n",
    "#     - Remove a List of Unwanted Characters from a String:\n",
    "#         - https://www.geeksforgeeks.org/python-removing-unwanted-characters-from-string/\n",
    "\n",
    "lghtnng_strks_df = pd.DataFrame()\n",
    "\n",
    "lghtnng_strks = driver.find_element_by_id(\"dateSelect\")\n",
    "\n",
    "options = [x for x in lghtnng_strks.find_elements_by_tag_name(\"option\")]\n",
    "\n",
    "bad_chars = ['(', 'events)']\n",
    "\n",
    "for element in options:\n",
    "#     print (element.get_attribute(\"text\"))\n",
    "    text = element.get_attribute(\"text\")\n",
    "    \n",
    "    count = 1\n",
    "    \n",
    "    for i in bad_chars:\n",
    "        text = text.replace(i, \"\")\n",
    "        \n",
    "        if count == 2:\n",
    "            text = text.replace(i, \"\")\n",
    "            print (text.split())\n",
    "            print (text.split()[0])\n",
    "            print (text.split()[1])\n",
    "            print (\"**************************\")\n",
    "            count = 0\n",
    "            \n",
    "            lghtnng_strks_df = lghtnng_strks_df.append({\"date\": text.split()[0], \n",
    "                                                        \"number_of_strikes\": text.split()[1]}, ignore_index = True)\n",
    "            \n",
    "        count = 1 + count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lghtnng_strks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dropdown_value(year):\n",
    "    # https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "    driver.find_element_by_xpath(\"//select[@id='yearSelect']/option[text()='2001']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://pythonspot.com/selenium-textbox/\n",
    "\n",
    "text_area = driver.find_element_by_class_name('esri-input esri-search__input')\n",
    "text_area.send_keys(\"This text is send using Python code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Mean Streamflow Rate for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "\n",
    "input_fle_dict[\"Data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)\n",
    "statn_data_lst_of_dicts[0][\"Data\"][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of a dictionary within a list (I modified this codes since my dictionary isn't in a list)\n",
    "#     - https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value\n",
    "\n",
    "def find_avg (lst, key, value):\n",
    "    for i, a_dict_2 in enumerate(lst):\n",
    "        print(a_dict_2[key])\n",
    "    #         print(input_fle_dict[\"Station_Nmbr\"])\n",
    "    #         print(\"********************************************************************\")\n",
    "#         if a_dict_2[key] == value:    \n",
    "#         if station == value:\n",
    "#             print(i)\n",
    "    \n",
    "                \n",
    "    \n",
    "#             avg_strmflw_rte = dict_nm[\"Data\"][i][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             dict_nm[\"Avg_Streamflow\"][i].append(avg_strmflw_rte )\n",
    "\n",
    "#             avg_strmflw = lst[i][\"Data\"][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             lst[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "        \n",
    "#             return i # avg_strmflw_rte\n",
    "    #             print(\"********************************************************************\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"][0].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_avg(statn_data_lst_of_dicts, \"Station_Nmbr\", \"13206000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [{'id':'1234','name':'Jason'}, {'id':'2345','name':'Tom'}, {'id':'3456','name':'Art'}]\n",
    "\n",
    "tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None)\n",
    "tom_index\n",
    "\n",
    "# tom_index = next((index for (index, d) in enumerate(input_fle_dict) if d[\"Station_Nmbr\"] == 13075910), None)\n",
    "# print(tom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types1 = [type(k) for k in input_fle_dict[\"Station_Nmbr\"]]\n",
    "types1\n",
    "# type(13075000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts = [{'id':'1234','name':'Jason'},\n",
    "#          {'id':'2345','name':'Tom'},\n",
    "#          {'id':'3456','name':'Art'}]\n",
    "\n",
    "def find_index(dicts, key, value):\n",
    "    class Null: pass\n",
    "    for i, d in enumerate(dicts):\n",
    "        if d.get(key, Null) == value:\n",
    "            return d\n",
    "    else:\n",
    "        raise ValueError('no dict with the key and value combination found')\n",
    "\n",
    "print (find_index(dicts, 'name', 'Tom'))\n",
    "# 1\n",
    "# find_index(dicts, 'name', 'Ensnare')\n",
    "# ValueError: no dict with the key and value combination found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, key, value):\n",
    "#     i = 0\n",
    "    for i, dic in enumerate(lst):\n",
    "        print(lst)\n",
    "        print(dic)\n",
    "        print(\"********************************************************************\")\n",
    "        if dic[key] == value:\n",
    "            return i\n",
    "            print(\"********************************************************************\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find(lst, \"name\", \"Tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "search_key = \"13075000\"\n",
    "\n",
    "temp = list(input_fle_dict.items())  Station_Nmbr\n",
    "res = list(input_fle_dict.keys()).index(search_key) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
    "    \n",
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "    temp = list(test_dict.items())  \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0] == search_key] \n",
    "    \n",
    "    \n",
    "    input_fle_dict[\"Data\"][0][\"streamflow_rate\"] = input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Data/Idaho_Streamflow_Data/13206000.txt\", \"r\")\n",
    "lines = file.readlines()[26:]\n",
    "\n",
    "print(type(lines))\n",
    "print(lines)\n",
    "\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a Row from the List\n",
    "#     - https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del lines[0:1]\n",
    "lines\n",
    "# print((lines[1].split(\"\\t\")))\n",
    "test = lines[1][:-1].split(\"\\t\")\n",
    "test\n",
    "\n",
    "a_series = pd.Series(test, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Text File and Convert to a Dataframe\n",
    "data = pd.read_csv('Data/Idaho_Streamflow_Data/13206000.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Empty Rows\n",
    "import numpy as np\n",
    "np.where(pd.isnull(statn_table_df_splt_StatnNmbr_nmbrs_clmn))\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"] = statn_table_df[\"StationNumber\"].astype(str)\n",
    "print(statn_table.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if \"County\" in statn_table[\"StationNumber\"][0]:\n",
    "        print(\"true\")\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([0, 4], axis = 0)\n",
    "statn_table_df_drp_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the County Names from the Table\n",
    "# test = statn_table.drop([0, 4], axis = 0)\n",
    "# test.head()\n",
    "\n",
    "# Count the number of Rows in the Dataframe\n",
    "count = 0\n",
    "for statn_table_df_row in statn_table_df.index:\n",
    "\n",
    "    if \"County\" in statn_table_df[\"StationNumber\"][statn_table_df_row]:\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([statn_table_df_row], axis = 0)\n",
    "        count = count + 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_drp_cnty.head(15)\n",
    "# statn_table_df_drp_cnty.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statn_table_df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# Select(driver.find_element_by_id('rdb'))\n",
    "\n",
    "tab_sprtd_rado = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(tab_sprtd_rado)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# url = \"https://www.usgs.gov/\"\n",
    "browser.visit(url)\n",
    "window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Collect the latest News Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
