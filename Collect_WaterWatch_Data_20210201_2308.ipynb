{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ---------------------------------------------------------\n",
    "import pandas as pd\n",
    "# ---------------------------------------------------------\n",
    "from bs4 import BeautifulSoup as BS\n",
    "# ---------------------------------------------------------\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import Select\n",
    "# ---------------------------------------------------------\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "# ---------------------------------------------------------\n",
    "from itertools import dropwhile\n",
    "\n",
    "\n",
    "# import warnings\n",
    "# import pymongo\n",
    "# import time\n",
    "# import datetime\n",
    "# import requests\n",
    "# import datefinder\n",
    "# from splinter import Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Tried to Scrape the Table Using Pandas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This did not work b/c the table is created with JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Different Insurance Websites\n",
    "River_Stream_7Day_Flow_Conditions_Tables = pd.read_html(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(River_Stream_7Day_Flow_Conditions_Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "River_Stream_7Day_Flow_Conditions_Tables[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Scraping the Website with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' WaterWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# browser.visit(url)\n",
    "# window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click FULL IMAGE to see a large thumbnail of the featured image \n",
    "browser.click_link_by_id('st')\n",
    "# browser.fill('st', \"Idaho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/12323403/how-do-i-find-an-element-that-contains-specific-text-in-selenium-webdriver-pyth\n",
    "# https://selenium-python.readthedocs.io/locating-elements.html\n",
    "\n",
    "driver.find_element_by_xpath(\"//*[contains(text(), 'Current Streamflow')]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52873433/python-selenium-clicking-based-on-alt-attribute\n",
    "\n",
    "driver.find_element_by_css_selector('[alt=\"id\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "lst_all_statns = '//input[@type=\"radio\" and @value=\"statelist\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(lst_all_statns)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('select_display'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('dailystagedischarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('group_table_by'))\n",
    "\n",
    "# Select by visible text\n",
    "# select.select_by_visible_text('Daily Stage and Streamflow')\n",
    "\n",
    "# Select by value text\n",
    "select.select_by_value('county_cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "sbmt_bttn = '//input[@type=\"submit\" and @value=\"go\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find All the Station Numbers Scrap the table with all the stations and use that table to loop \n",
    "# through and click each station's link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crrnt_url = driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tables on the current page: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationNumber</th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)2/9</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)2/9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13206000</td>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13206305</td>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13206400</td>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>13011500</td>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>13011900</td>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>13013650</td>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>13015000</td>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>13018750</td>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      StationNumber                                    Station name  \\\n",
       "0        Ada County                                      Ada County   \n",
       "1          13206000      BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2          13206305           BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3          13206400                        EAGLE DRAIN AT EAGLE, ID   \n",
       "4    Bannock County                                  Bannock County   \n",
       "..              ...                                             ...   \n",
       "271        13011500                      PACIFIC CREEK AT MORAN, WY   \n",
       "272        13011900          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273        13013650                        SNAKE RIVER AT MOOSE, WY   \n",
       "274        13015000                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275        13018750  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)2/9 Dailymeanstream- flow (ft3/s)2/9  \n",
       "0                    Ada County                       Ada County  \n",
       "1                           NaN                              260  \n",
       "2                           NaN                              230  \n",
       "3                           NaN                             6.35  \n",
       "4                Bannock County                   Bannock County  \n",
       "..                          ...                              ...  \n",
       "271                         NaN                               --  \n",
       "272                         NaN                               --  \n",
       "273                         NaN                              844  \n",
       "274                         NaN                               --  \n",
       "275                         NaN                             1300  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "statn_table = pd.read_html(crrnt_url)\n",
    "print(f\"Number of Tables on the current page: {len(statn_table)}\")\n",
    "statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(statn_table[1].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df = statn_table[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station name</th>\n",
       "      <th>Dailymeangage height(ft)2/9</th>\n",
       "      <th>Dailymeanstream- flow (ft3/s)2/9</th>\n",
       "      <th>numbers</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td>Ada County</td>\n",
       "      <td></td>\n",
       "      <td>Ada County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260</td>\n",
       "      <td>13206000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOISE RIVER SOUTH CHANNEL AT EAGLE ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230</td>\n",
       "      <td>13206305</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAGLE DRAIN AT EAGLE, ID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.35</td>\n",
       "      <td>13206400</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td>Bannock County</td>\n",
       "      <td></td>\n",
       "      <td>Bannock County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>PACIFIC CREEK AT MORAN, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011500</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>BUFFALO FORK AB LAVA CREEK NR MORAN WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13011900</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>SNAKE RIVER AT MOOSE, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>844</td>\n",
       "      <td>13013650</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>GROS VENTRE RIVER AT ZENITH, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>13015000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1300</td>\n",
       "      <td>13018750</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Station name  \\\n",
       "0                                        Ada County   \n",
       "1        BOISE RIVER AT GLENWOOD BRIDGE NR BOISE ID   \n",
       "2             BOISE RIVER SOUTH CHANNEL AT EAGLE ID   \n",
       "3                          EAGLE DRAIN AT EAGLE, ID   \n",
       "4                                    Bannock County   \n",
       "..                                              ...   \n",
       "271                      PACIFIC CREEK AT MORAN, WY   \n",
       "272          BUFFALO FORK AB LAVA CREEK NR MORAN WY   \n",
       "273                        SNAKE RIVER AT MOOSE, WY   \n",
       "274                 GROS VENTRE RIVER AT ZENITH, WY   \n",
       "275  SNAKE RIVER BELOW FLAT CREEK, NEAR JACKSON, WY   \n",
       "\n",
       "    Dailymeangage height(ft)2/9 Dailymeanstream- flow (ft3/s)2/9   numbers  \\\n",
       "0                    Ada County                       Ada County             \n",
       "1                           NaN                              260  13206000   \n",
       "2                           NaN                              230  13206305   \n",
       "3                           NaN                             6.35  13206400   \n",
       "4                Bannock County                   Bannock County             \n",
       "..                          ...                              ...       ...   \n",
       "271                         NaN                               --  13011500   \n",
       "272                         NaN                               --  13011900   \n",
       "273                         NaN                              844  13013650   \n",
       "274                         NaN                               --  13015000   \n",
       "275                         NaN                             1300  13018750   \n",
       "\n",
       "               text  \n",
       "0        Ada County  \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4    Bannock County  \n",
       "..              ...  \n",
       "271                  \n",
       "272                  \n",
       "273                  \n",
       "274                  \n",
       "275                  \n",
       "\n",
       "[276 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the text from the digits in the \"StationNumber\" column.\n",
    "# https://stackoverflow.com/questions/56851679/how-to-separate-pandas-column-that-contains-values-stored-as-text-and-numbers-in\n",
    "\n",
    "statn_table_df_splt_StatnNmbr = statn_table_df.join(statn_table_df.pop('StationNumber').str.extract('(?P<numbers>\\d+)?(?P<text>\\D+)?').fillna(''))\n",
    "statn_table_df_splt_StatnNmbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CELL\n",
    "\n",
    "if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "    print(\"No County\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with only the \"numbers\" column from the \"statn_table_df_splt\" Dataframe\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn = pd.DataFrame(statn_table_df_splt_StatnNmbr[\"numbers\"])\n",
    "\n",
    "# Replace the Empty Rows with \"NaN\"\n",
    "# https://www.kite.com/python/answers/how-to-drop-empty-rows-from-a-pandas-dataframe-in-python\n",
    "\n",
    "nan_value = float(\"NaN\")\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.replace(\"\", nan_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Number of Null Values in the Dataframe\n",
    "# https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe\n",
    "\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"NaN\" Null Values\n",
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls = statn_table_df_splt_StatnNmbr_nmbrs_clmn.dropna()\n",
    "print(f\"Number of Null Values: {statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.isna().sum()}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Convert the \"numbers\" column to an Interger Data Type\n",
    "\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"] = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"].astype(int)\n",
    "\n",
    "# print(statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgn_date = \"1990-01-01\"\n",
    "end_date = \"1990-01-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls.index:\n",
    "   \n",
    "    # Find the Hyper Link for One Station\n",
    "    statn_nmbr = statn_table_df_splt_StatnNmbr_nmbrs_clmn_no_nulls[\"numbers\"][row]\n",
    "\n",
    "\n",
    "    # https://stackoverflow.com/questions/32874539/using-a-variable-in-xpath-in-python-selenium\n",
    "    # driver.find_element_by_xpath(\"//*[contains(text(), '13206000')]\").click()\n",
    "    driver.find_element_by_xpath(\"//*[contains(text(),'\" +statn_nmbr+\"')]\").click()\n",
    "\n",
    "\n",
    "    # Select the Tab-separated Output format\n",
    "    lst_all_statns = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "    lst_all_statns_button = driver.find_element_by_xpath(lst_all_statns)\n",
    "    lst_all_statns_button.click()\n",
    "\n",
    "\n",
    "    # Enter Values for the Begin Date and End Date\n",
    "    # Fill in Input Fills\n",
    "    #     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "    # Clear the Input Field\n",
    "    #     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "    element = driver.find_element_by_name(\"begin_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(bgn_date)\n",
    "\n",
    "    element = driver.find_element_by_name(\"end_date\")\n",
    "    element.clear()\n",
    "    element.send_keys(end_date)\n",
    "\n",
    "    # Press/Click a Button Without an ID\n",
    "    #     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "    #     - https://stackoverflow.com/questions/21322116/using-selenium-in-python-to-click-select-a-radio-button/21322160\n",
    "\n",
    "    sbmt_bttn = '//input[@id=\"go_available_button\"]'\n",
    "\n",
    "    sbmt_bttn_button = driver.find_element_by_xpath(sbmt_bttn)\n",
    "    sbmt_bttn_button.click()\n",
    "\n",
    "\n",
    "#     from selenium.webdriver import ActionChains\n",
    "\n",
    "    actionChains = ActionChains(driver)\n",
    "\n",
    "\n",
    "    # Save the data file to This Computer\n",
    "\n",
    "    # How to Open and Write to a File on This Computer\n",
    "    #     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "    # How to Change the Location of the File\n",
    "    #     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "#     import urllib.request, urllib.error, urllib.parse\n",
    "#     import os\n",
    "\n",
    "\n",
    "    response = urllib.request.urlopen(driver.current_url)\n",
    "    webContent = response.read()\n",
    "\n",
    "    fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "    f = open(fle_nm, 'wb')\n",
    "    f.write(webContent)\n",
    "    f.close\n",
    "\n",
    "\n",
    "    driver.back()\n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "actionChains = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data file to This Computer\n",
    "\n",
    "# How to Open and Write to a File on This Computer\n",
    "#     - https://programminghistorian.org/en/lessons/working-with-web-pages\n",
    "# How to Change the Location of the File\n",
    "#     - https://www3.ntu.edu.sg/home/ehchua/programming/webprogramming/Python_FileText.html\n",
    "\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import os\n",
    "\n",
    "# url='https://waterdata.usgs.gov/id/nwis/dv?cb_00060=on&format=rdb&site_no=13206000&referred_module=sw&period=&begin_date=1990-01-01&end_date=1990-12-31'\n",
    "\n",
    "response = urllib.request.urlopen(driver.current_url)\n",
    "webContent = response.read()\n",
    "\n",
    "output_fle_nm = \"Data/Idaho_Streamflow_Data/\" + statn_nmbr + \".txt\"\n",
    "\n",
    "f = open(output_fle_nm, 'wb')\n",
    "f.write(webContent)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()\n",
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Create a Dataframe for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to Skip All of the Comments in the File\n",
    "#     https://cmdlinetips.com/2018/01/3-ways-to-read-a-file-and-skip-initial-comments-in-python/\n",
    "\n",
    "def is_comment(s):\n",
    "    \"\"\" function to check if a line\n",
    "         starts with some character.\n",
    "         Here # for comment\n",
    "    \"\"\"\n",
    "    # return true if a line starts with #\n",
    "    return s.startswith('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Names for the Dataframe\n",
    "clmn_nms = [\"agency\", \n",
    "            \"site_nmbr\", \n",
    "            \"date\", \n",
    "            \"streamflow_rate\", \n",
    "            \"approved/pending\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the Files\n",
    "input_fle_path = os.path.join(\"Data\", \"Idaho_Streamflow_Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of Data Types for the Dataframe\n",
    "convert_dict = {\n",
    "                \"streamflow_rate\": float\n",
    "               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '13073000.txt', '13075000.txt', '13075910.txt', '13206000.txt']\n"
     ]
    }
   ],
   "source": [
    "# List of Files in a Directory\n",
    "#     - https://careerkarma.com/blog/python-list-files-in-directory/\n",
    "\n",
    "input_fle_lst = os.listdir(\"Data/Idaho_Streamflow_Data\")\n",
    "print(input_fle_lst)\n",
    "# input_fle_nm = input_fle_lst[0]\n",
    "# print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# Create a List of the Files in the Directory\n",
    "input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": []}\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "\n",
    "#         Append to the File Names to the Directory\n",
    "        input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "        input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "        input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         print(input_fle_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_splt_StatnNmbr[\"text\"].last_valid_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "count_1 = 0\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    "    \n",
    "    if row != \"\":\n",
    "#         print(row)\n",
    "        count_1 = count_1 + 1\n",
    "#         cnty_lst.append(row)\n",
    "        \n",
    "print(count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnty_lst = [{}for x in range(51)]\n",
    "# cnty_lst[2].append(2050)\n",
    "# cnty_lst[1]\n",
    "cnty_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada County\n",
      "13206000\n",
      "13206305\n",
      "Bannock County\n",
      "13073000\n",
      "13075000\n",
      "13075500\n",
      "Bear Lake County\n",
      "10039500\n",
      "Benewah County\n",
      "12414900\n",
      "12415070\n",
      "Bingham County\n",
      "13060000\n",
      "13062500\n",
      "13065500\n",
      "13066000\n",
      "13068300\n",
      "13068495\n",
      "13068500\n",
      "13069500\n",
      "Blaine County\n",
      "13135500\n",
      "13135520\n",
      "13136550\n",
      "13137000\n",
      "13137500\n",
      "13138000\n",
      "13139510\n",
      "13140335\n",
      "13140800\n",
      "13142500\n",
      "13147900\n",
      "13148500\n",
      "Boise County\n",
      "13185000\n",
      "13200000\n",
      "13235000\n",
      "13237920\n",
      "13246000\n",
      "Bonner County\n",
      "12391950\n",
      "12392155\n",
      "12392300\n",
      "12393501\n",
      "Bonneville County\n",
      "13032500\n",
      "13037500\n",
      "13057132\n",
      "13057155\n",
      "13057500\n",
      "13057940\n",
      "13058000\n",
      "13058510\n",
      "13058520\n",
      "13058529\n",
      "Boundary County\n",
      "12306500\n",
      "12308000\n",
      "12308500\n",
      "12309500\n",
      "12310100\n",
      "12318500\n",
      "12321500\n",
      "12322000\n",
      "Butte County\n",
      "13118700\n",
      "13118975\n",
      "13119000\n",
      "13132100\n",
      "13132373\n",
      "13132500\n",
      "13132513\n",
      "13132520\n",
      "13132535\n",
      "Camas County\n",
      "Canyon County\n",
      "13210810\n",
      "13210824\n",
      "13210831\n",
      "13210980\n",
      "13210986\n",
      "132109867\n",
      "13211205\n",
      "13212549\n",
      "13213000\n",
      "Caribou County\n",
      "13057300\n",
      "Cassia County\n",
      "13078000\n",
      "13082500\n",
      "Clark County\n",
      "Clearwater County\n",
      "13340000\n",
      "Custer County\n",
      "13120000\n",
      "13120500\n",
      "13122000\n",
      "13124265\n",
      "13127000\n",
      "13128900\n",
      "13295000\n",
      "13296000\n",
      "13296500\n",
      "13297330\n",
      "Elmore County\n",
      "13154500\n",
      "13159800\n",
      "13186000\n",
      "Franklin County\n",
      "Fremont County\n",
      "13039500\n",
      "13042500\n",
      "13046000\n",
      "13046995\n",
      "13047500\n",
      "13047600\n",
      "13049500\n",
      "13050500\n",
      "Gem County\n",
      "13249500\n",
      "Gooding County\n",
      "13095175\n",
      "13095500\n",
      "Idaho County\n",
      "13316500\n",
      "13317000\n",
      "13336500\n",
      "13337000\n",
      "13337500\n",
      "Jefferson County\n",
      "13038000\n",
      "13038500\n",
      "Jerome County\n",
      "Kootenai County\n",
      "12413500\n",
      "12413860\n",
      "12417650\n",
      "Latah County\n",
      "13345000\n",
      "Lemhi County\n",
      "13302005\n",
      "13302500\n",
      "13305000\n",
      "13305310\n",
      "13306370\n",
      "13306385\n",
      "13307000\n",
      "Lewis County\n",
      "Madison County\n",
      "13055250\n",
      "13055340\n",
      "13056500\n",
      "Minidoka County\n",
      "Nez Perce County\n",
      "13317660\n",
      "13341050\n",
      "13341140\n",
      "13341570\n",
      "13342450\n",
      "Owyhee County\n",
      "13168500\n",
      "Payette County\n",
      "Power County\n",
      "Shoshone County\n",
      "12411000\n",
      "12413000\n",
      "12413125\n",
      "12413130\n",
      "12413131\n",
      "12413210\n",
      "12413355\n",
      "12413470\n",
      "12413875\n",
      "Teton County\n",
      "Twin Falls County\n",
      "13087505\n",
      "\n",
      "13087995\n",
      "13090500\n",
      "13092747\n",
      "13094000\n",
      "Valley County\n",
      "13236500\n",
      "13239000\n",
      "13240000\n",
      "13309220\n",
      "13310700\n",
      "13310800\n",
      "13310850\n",
      "13311000\n",
      "13311250\n",
      "13311450\n",
      "Washington County\n",
      "13258500\n",
      "13265500\n",
      "13266000\n",
      "Flathead County, Montana\n",
      "Lincoln County, Montana\n",
      "12301250\n",
      "12301933\n",
      "12302055\n",
      "12304500\n",
      "12305000\n",
      "Sanders County, Montana\n",
      "12389500\n",
      "Elko County, Nevada\n",
      "13105000\n",
      "13161500\n",
      "Harney County, Oregon\n",
      "Malheur County, Oregon\n",
      "13181000\n",
      "13183000\n",
      "Wallowa County, Oregon\n",
      "Asotin County, Washington\n",
      "Lincoln County, Wyoming\n",
      "13022500\n",
      "13023000\n",
      "Teton County, Wyoming\n",
      "13010065\n",
      "13011000\n",
      "13011500\n",
      "13011900\n",
      "13013650\n",
      "13015000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "276",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 276 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4512e6ce9ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# *********************************************************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstatn_table_df_splt_StatnNmbr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatn_table_df_splt_StatnNmbr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numbers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 276"
     ]
    }
   ],
   "source": [
    "# Create a list of list\n",
    "#     - https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "\n",
    "\n",
    "cnty_lst = [[]for x in range(51)]\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "statn_lst = []\n",
    "# cnty_lst = [[] * 154]\n",
    "new_dict = {}\n",
    "\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    " \n",
    "# *********************************************************************************************\n",
    "#                               Step 1: If the row is Not Empty\n",
    "# *********************************************************************************************\n",
    "    if row != \"\":\n",
    "        print(row)\n",
    "#         count_1 = count_1\n",
    "        cnty_lst[count_2].append(row)\n",
    "        cnty_lst[count_2].append([])\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# *********************************************************************************************\n",
    "\n",
    "    elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "        print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # #         count_3 = count_1\n",
    "# # #         print (count_3)\n",
    "# #         count_1 = 0\n",
    "\n",
    "\n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                                  \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "                                  \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                                  \"Data\": \"\", \n",
    "                                  \"Avg_Streamflow\": \"\",\n",
    "                                  \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "        cnty_lst[count_2][1].append(dict(new_dict))\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "    elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                                  \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                                  \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                                  \"Data\": \"\", \n",
    "                                  \"Avg_Streamflow\": \"\",\n",
    "                                  \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "        cnty_lst[count_2][1].append(dict(new_dict))\n",
    "        \n",
    "        count_2 = count_2 + 1\n",
    "# *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                               Step 4: Add 1 to the Count\n",
    "# *********************************************************************************************    \n",
    "    count_1 = count_1 + 1\n",
    "# *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ada County', [{'Station_Nmbr': '13206000', 'File_Name': '13206000.txt', 'df_Name': '13206000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13206305', 'File_Name': '13206305.txt', 'df_Name': '13206305_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13206400', 'File_Name': '13206400.txt', 'df_Name': '13206400_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}]]\n",
      "********************************************************************\n",
      "[{'Station_Nmbr': '13206000', 'File_Name': '13206000.txt', 'df_Name': '13206000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13206305', 'File_Name': '13206305.txt', 'df_Name': '13206305_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13206400', 'File_Name': '13206400.txt', 'df_Name': '13206400_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}]\n",
      "********************************************************************\n",
      "{'Station_Nmbr': '13206000', 'File_Name': '13206000.txt', 'df_Name': '13206000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}\n",
      "********************************************************************\n",
      "13206000\n"
     ]
    }
   ],
   "source": [
    "# statn_lst\n",
    "\n",
    "# cnty_lst[0][0].append(input_fle_dict)\n",
    "# cnty_lst[0][1].append(\"test\")\n",
    "# print(cnty_lst)\n",
    "print(cnty_lst[0])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][1])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][1][0])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[0][1][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    }
   ],
   "source": [
    "# Create a list of list\n",
    "#     - https://stackoverflow.com/questions/8713620/appending-items-to-a-list-of-lists-in-python\n",
    "\n",
    "\n",
    "cnty_lst = []\n",
    "\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "\n",
    "statn_lst = []\n",
    "# cnty_lst = [[] * 154]\n",
    "new_dict = {}\n",
    "\n",
    "\n",
    "for row in statn_table_df_splt_StatnNmbr[\"text\"]:\n",
    "#     print(row)\n",
    " \n",
    "    \n",
    "    if count_1 + 1 < 276:\n",
    "# *********************************************************************************************\n",
    "#                               Step 1: If the row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        if row != \"\":\n",
    "            statn_lst = []  # This will be a list of dictionaries\n",
    "            cnty_nm = row\n",
    "#         print(row)\n",
    "# #         count_1 = count_1\n",
    "#         cnty_lst[count_2].append(row)\n",
    "#         cnty_lst[count_2].append([])\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 2: If the row is Empty and the Next Row is Empty\n",
    "# *********************************************************************************************\n",
    "\n",
    "        elif row == \"\" and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] == \"\":\n",
    "#         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1]) \n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "        \n",
    "# # #         print(statn_table_df_splt_StatnNmbr[\"numbers\"][count])\n",
    "# # #         count_3 = count_1\n",
    "# # #         print (count_3)\n",
    "# #         count_1 = 0\n",
    "\n",
    "\n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", #input_fle_nm, \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",#\"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        elif row == \"\": #and statn_table_df_splt_StatnNmbr[\"text\"][count_1 + 1] != \"\":\n",
    "#         cnty_lst[count_2][1].append(statn_table_df_splt_StatnNmbr[\"numbers\"][count_1])\n",
    "        \n",
    "            new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                        \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                        \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                        \"Data\": \"\", \n",
    "                        \"Avg_Streamflow\": \"\",\n",
    "                        \"Prcnt_Below_Avg\": \"\"}\n",
    "    \n",
    "            statn_lst.append(dict(new_dict))\n",
    "        \n",
    "#         count_2 = count_2 + 1\n",
    "        \n",
    "            cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "        \n",
    "# *********************************************************************************************\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************  \n",
    "    if count_1 + 1 > 275 and row == \"\":\n",
    "        print (count_1)\n",
    "\n",
    "\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                   Step 3: If the row is Empty and the Next Row is Not Empty\n",
    "# *********************************************************************************************\n",
    "        \n",
    "        new_dict = {\"Station_Nmbr\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1], \n",
    "                    \"File_Name\":statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \".txt\", \n",
    "                    \"df_Name\": statn_table_df_splt_StatnNmbr[\"numbers\"][count_1] + \"_df\",\n",
    "                    \"Data\": \"\", \n",
    "                    \"Avg_Streamflow\": \"\",\n",
    "                    \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "        statn_lst.append(dict(new_dict))\n",
    "\n",
    "        cnty_lst.append(dict({cnty_nm: statn_lst}))\n",
    "# *********************************************************************************************\n",
    "    \n",
    "    \n",
    "# *********************************************************************************************\n",
    "#                               Step 4: Add 1 to the Count\n",
    "# *********************************************************************************************    \n",
    "    count_1 = count_1 + 1\n",
    "# *********************************************************************************************\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Teton County, Wyoming': [{'Station_Nmbr': '13010065', 'File_Name': '13010065.txt', 'df_Name': '13010065_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13011000', 'File_Name': '13011000.txt', 'df_Name': '13011000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13011500', 'File_Name': '13011500.txt', 'df_Name': '13011500_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13011900', 'File_Name': '13011900.txt', 'df_Name': '13011900_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13013650', 'File_Name': '13013650.txt', 'df_Name': '13013650_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13015000', 'File_Name': '13015000.txt', 'df_Name': '13015000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13018750', 'File_Name': '13018750.txt', 'df_Name': '13018750_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}]}\n",
      "********************************************************************\n",
      "[{'Station_Nmbr': '13010065', 'File_Name': '13010065.txt', 'df_Name': '13010065_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13011000', 'File_Name': '13011000.txt', 'df_Name': '13011000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13011500', 'File_Name': '13011500.txt', 'df_Name': '13011500_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13011900', 'File_Name': '13011900.txt', 'df_Name': '13011900_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13013650', 'File_Name': '13013650.txt', 'df_Name': '13013650_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13015000', 'File_Name': '13015000.txt', 'df_Name': '13015000_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}, {'Station_Nmbr': '13018750', 'File_Name': '13018750.txt', 'df_Name': '13018750_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}]\n",
      "********************************************************************\n",
      "{'Station_Nmbr': '13010065', 'File_Name': '13010065.txt', 'df_Name': '13010065_df', 'Data': '', 'Avg_Streamflow': '', 'Prcnt_Below_Avg': ''}\n",
      "********************************************************************\n",
      "13010065\n"
     ]
    }
   ],
   "source": [
    "# statn_lst\n",
    "# cnty_lst = {cnty_nm: statn_lst}\n",
    "# cnty_lst[0][0].append(input_fle_dict)\n",
    "# cnty_lst[0][1].append(\"test\")\n",
    "# print(cnty_lst)\n",
    "# print(new_dict)\n",
    "# print(statn_lst)\n",
    "print(cnty_lst[50])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[50][\"Teton County, Wyoming\"])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[50][\"Teton County, Wyoming\"][0])\n",
    "print(\"********************************************************************\")\n",
    "print(cnty_lst[50][\"Teton County, Wyoming\"][0][\"Station_Nmbr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def find(name, path):\n",
    "for root, dirs, files in os.walk(input_fle_path):\n",
    "    if \"13073000.txt\" in files:\n",
    "        print (os.path.join(root, \"13073000.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(\"13073000.txt\", input_fle_path):\n",
    "    result = []\n",
    "    for root, dirs, files in os.walk(input_fle_path):\n",
    "        if name in files:\n",
    "            result.append(os.path.join(root, name))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to Ignore Hidden Files\n",
    "#     - https://stackoverflow.com/questions/15235823/how-to-ignore-hidden-files-in-python-functions\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# # Create a List of the Files in the Directory\n",
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "# # *********************************************************************************************\n",
    "\n",
    "# Create a List to Store/Save the Streamflow Data, Data will be Saved as a List of Dictionaries\n",
    "statn_data_lst_of_dicts = []\n",
    "input_fle_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# # *********************************************************************************************\n",
    "# Put the Station in a list by County Name\n",
    "# First Find the station in the county  \n",
    "\n",
    "if statn_table_df_splt_StatnNmbr[\"text\"][1] == \"\":\n",
    "    print(\"No County\")\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "\n",
    "for input_fle_nm in os.listdir(input_fle_path):\n",
    "# Skip the Hidden Files in the Directory\n",
    "    if not input_fle_nm.startswith('.') and os.path.isfile(os.path.join(input_fle_path, input_fle_nm)):\n",
    "# # *********************************************************************************************\n",
    "# #         Append to the File Names to the Directory\n",
    "#         input_fle_dict[\"Station_Nmbr\"].append(input_fle_nm[:-4])\n",
    "#         input_fle_dict[\"File_Name\"].append(input_fle_nm)\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "#         input_fle_dict[\"df_Name\"].append(\"_\" + input_fle_nm[:-4] + \"_df\")\n",
    "# #         print(input_fle_nm)\n",
    "# # *********************************************************************************************\n",
    "\n",
    "\n",
    "        input_fle_dict = {\"Station_Nmbr\": input_fle_nm[:-4], \n",
    "                          \"File_Name\": input_fle_nm, \n",
    "                          \"df_Name\": \"_\" + input_fle_nm[:-4] + \"_df\", \n",
    "                          \"Data\": \"\", \n",
    "                          \"Avg_Streamflow\": \"\",\n",
    "                          \"Prcnt_Below_Avg\": \"\"}\n",
    "\n",
    "# Append to the File Names to the Directory\n",
    "    statn_data_lst_of_dicts.append(dict(input_fle_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del statn_data_lst_of_dicts[0]\n",
    "statn_data_lst_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[1]['Station_Nmbr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, station in enumerate(dict_nm[key]):\n",
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "    print(statn_data_lst_of_dicts[i]['File_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst[\"Station_Nmbr\"][0]\n",
    "# input_fle_dict[\"File_Name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in input_fle_dict[\"df_Name\"]:\n",
    "    print(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_nm = input_fle_lst[0]\n",
    "input_fle_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40482738/how-to-name-dataframe-with-variables-in-pandas\n",
    "\n",
    "N = 10 # 5 in sample\n",
    "dfs = {'name' + str(i):df for i in range(1,N)}\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"name2\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # 5 in sample\n",
    "# for input_fle_nm in input_fle_lst:\n",
    "input_fle_nm =\"\"\n",
    "dfs = {input_fle_nm:df for input_fle_nm in input_fle_dict[\"df_Name\"]}\n",
    "# print (input_fle_nm)\n",
    "print (dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts[2]['File_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, a_dict in enumerate(statn_data_lst_of_dicts):\n",
    "# *********************************************************************************************\n",
    "#                                   Step 1 Create Variables\n",
    "# *********************************************************************************************\n",
    "\n",
    "#     Create the File Path for Each Station's .txt File Which Includes Streamflow Data\n",
    "    input_fle_path_fr_lp = input_fle_path + \"/\" + statn_data_lst_of_dicts[i]['File_Name']\n",
    "\n",
    "#     Create the Dataframe to Store the Streamflow Data from the .txt File\n",
    "    df = pd.DataFrame(columns = clmn_nms)\n",
    "#     df_nm = \"_\" + statn_nm + \"_df\"\n",
    "# *********************************************************************************************\n",
    "\n",
    "# *********************************************************************************************\n",
    "#                           Step 2 Create a Dataframe for the Streamflow\n",
    "# *********************************************************************************************\n",
    "# Loop Through the .txt File and Store the Data into a Dataframe\n",
    "    with open(input_fle_path_fr_lp,'r') as fh:\n",
    "        for curline in dropwhile(is_comment, fh):\n",
    "    #         print(f\"Index Number: {count} {curline}\")\n",
    "    #         count = count + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Split a String\n",
    "    #     - https://www.geeksforgeeks.org/python-string-split/\n",
    "    # Pandas Series\n",
    "    #     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "            to_append = curline[:-1].split(\"\\t\")\n",
    "            a_series = pd.Series(to_append, index = clmn_nms)\n",
    "\n",
    "    #             Dataframe\n",
    "    #             Dataframe Name\n",
    "            statn_nm = input_fle_nm[:-4]\n",
    "\n",
    "    #             Append Data to the Dataframe\n",
    "            df= df.append(a_series, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(input_fle_nm)\n",
    "# Delete the first 2 Rows of the Dataframe Because they are not Data\n",
    "    df = df.drop(index = [0, 1])\n",
    "# Reset the Index so that it Starts with 0\n",
    "    df = df.reset_index(drop = True)\n",
    "# Change the Data Types of Each Column\n",
    "    df = df.astype(convert_dict) \n",
    "# Change the Date Column to a datetime Data Type\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    \n",
    "    avg_strmflw = df[\"streamflow_rate\"].mean(axis = 0)\n",
    "    print(f\"Average Streamflow: {avg_strmflw}\")\n",
    "#     print(df[\"streamflow_rate\"])\n",
    "#     print(\"********************************************************************\")\n",
    "    print (df)\n",
    "    \n",
    "    count = 0\n",
    "    print(len(df))\n",
    "    \n",
    "    for i_df in range(len(df)):\n",
    "#         print (df[\"streamflow_rate\"][2])\n",
    "        print (df[\"streamflow_rate\"][i_df])\n",
    "#         print (df_row)\n",
    "        if df[\"streamflow_rate\"][i_df] < avg_strmflw:\n",
    "            count = count + 1\n",
    "            \n",
    "            print (\"True\")\n",
    "        elif df[\"streamflow_rate\"][i_df] > avg_strmflw:\n",
    "            print (\"False\")\n",
    "        print(\"********************************************************************\")\n",
    "\n",
    "    pct_blw_avg = (count / len(df) * 100)\n",
    "    print (pct_blw_avg)\n",
    "# Add a value into an empty dictionay element\n",
    "#     - https://www.pluralsight.com/guides/manipulating-lists-dictionaries-python\n",
    "    statn_data_lst_of_dicts[i].update({\"Data\": df})\n",
    "    statn_data_lst_of_dicts[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "    statn_data_lst_of_dicts[i].update({\"Prcnt_Below_Avg\": pct_blw_avg})\n",
    "#     input_fle_dict[\"Data\"].append(df)\n",
    "\n",
    "    # df_nm = df_nm.drop(index = [0, 1])\n",
    "    # \"_\" + statn_nm + \"_df\" = df\n",
    "    # df_nm\n",
    "    # df\n",
    "    # df.drop(index = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statn_data_lst_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"_\" + input_fle_nm + \"_df\")\n",
    "# test = \"_\" + input_fle_nm\n",
    "# test[:-4]\n",
    "# input_fle_dict[\"df_Name\"]\n",
    "# _13073000_df.head()\n",
    "# _13206000_df.drop(index = [0, 1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict['Station_Nmbr'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Data\"][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "input_fle_path = \"Data/Idaho_Streamflow_Data/\" + input_fle_nm\n",
    "\n",
    "count = 0 \n",
    "\n",
    "with open(input_fle_path,'r') as fh:\n",
    "    for curline in dropwhile(is_comment, fh):\n",
    "        print(f\"Index Number: {count} {curline}\")\n",
    "        count = count + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe for the Data\n",
    "\n",
    "clmn_nms = [\"agency\", \"site_nmbr\", \"date\", \"streamflow_rate\", \"approved/pending\"]\n",
    "\n",
    "_13206000_df = pd.DataFrame(columns = clmn_nms)\n",
    "\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a String\n",
    "#     - https://www.geeksforgeeks.org/python-string-split/\n",
    "# Pandas Series\n",
    "#     - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html\n",
    "\n",
    "print(type(curline))\n",
    "print(curline)\n",
    "print((curline.split(\"\\t\")))\n",
    "print(type(curline.split(\"\\t\")))\n",
    "\n",
    "to_append = curline[:-1].split(\"\\t\")\n",
    "a_series = pd.Series(to_append, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Get the Mean Streamflow Rate for Each Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape a webpage and create a BeautifulSoup object from the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 USGS' Science for a Changing World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict = {\"Station_Nmbr\":[], \"File_Name\": [], \"df_Name\": [], \"Data\": [], \"Avg_Streamflow\": []}\n",
    "\n",
    "input_fle_dict[\"Data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)\n",
    "statn_data_lst_of_dicts[0][\"Data\"][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of a dictionary within a list (I modified this codes since my dictionary isn't in a list)\n",
    "#     - https://stackoverflow.com/questions/4391697/find-the-index-of-a-dict-within-a-list-by-matching-the-dicts-value\n",
    "\n",
    "def find_avg (lst, key, value):\n",
    "    for i, a_dict_2 in enumerate(lst):\n",
    "        print(a_dict_2[key])\n",
    "    #         print(input_fle_dict[\"Station_Nmbr\"])\n",
    "    #         print(\"********************************************************************\")\n",
    "#         if a_dict_2[key] == value:    \n",
    "#         if station == value:\n",
    "#             print(i)\n",
    "    \n",
    "                \n",
    "    \n",
    "#             avg_strmflw_rte = dict_nm[\"Data\"][i][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             dict_nm[\"Avg_Streamflow\"][i].append(avg_strmflw_rte )\n",
    "\n",
    "#             avg_strmflw = lst[i][\"Data\"][\"streamflow_rate\"].mean(axis = 0)\n",
    "#             lst[i].update({\"Avg_Streamflow\": avg_strmflw})\n",
    "        \n",
    "#             return i # avg_strmflw_rte\n",
    "    #             print(\"********************************************************************\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fle_dict[\"Station_Nmbr\"][0].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_avg(statn_data_lst_of_dicts, \"Station_Nmbr\", \"13206000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst = [{'id':'1234','name':'Jason'}, {'id':'2345','name':'Tom'}, {'id':'3456','name':'Art'}]\n",
    "\n",
    "tom_index = next((index for (index, d) in enumerate(lst) if d[\"name\"] == \"Tom\"), None)\n",
    "tom_index\n",
    "\n",
    "# tom_index = next((index for (index, d) in enumerate(input_fle_dict) if d[\"Station_Nmbr\"] == 13075910), None)\n",
    "# print(tom_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types1 = [type(k) for k in input_fle_dict[\"Station_Nmbr\"]]\n",
    "types1\n",
    "# type(13075000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts = [{'id':'1234','name':'Jason'},\n",
    "#          {'id':'2345','name':'Tom'},\n",
    "#          {'id':'3456','name':'Art'}]\n",
    "\n",
    "def find_index(dicts, key, value):\n",
    "    class Null: pass\n",
    "    for i, d in enumerate(dicts):\n",
    "        if d.get(key, Null) == value:\n",
    "            return d\n",
    "    else:\n",
    "        raise ValueError('no dict with the key and value combination found')\n",
    "\n",
    "print (find_index(dicts, 'name', 'Tom'))\n",
    "# 1\n",
    "# find_index(dicts, 'name', 'Ensnare')\n",
    "# ValueError: no dict with the key and value combination found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, key, value):\n",
    "#     i = 0\n",
    "    for i, dic in enumerate(lst):\n",
    "        print(lst)\n",
    "        print(dic)\n",
    "        print(\"********************************************************************\")\n",
    "        if dic[key] == value:\n",
    "            return i\n",
    "            print(\"********************************************************************\")\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find(lst, \"name\", \"Tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "search_key = \"13075000\"\n",
    "\n",
    "temp = list(input_fle_dict.items())  Station_Nmbr\n",
    "res = list(input_fle_dict.keys()).index(search_key) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_fle_nm in input_fle_dict[\"File_Name\"]:\n",
    "    \n",
    "# Using list comprehension + enumerate() \n",
    "# Key index in Dictionary \n",
    "    temp = list(test_dict.items())  \n",
    "    res = [idx for idx, key in enumerate(temp) if key[0] == search_key] \n",
    "    \n",
    "    \n",
    "    input_fle_dict[\"Data\"][0][\"streamflow_rate\"] = input_fle_dict[\"Data\"][0][\"streamflow_rate\"].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Data/Idaho_Streamflow_Data/13206000.txt\", \"r\")\n",
    "lines = file.readlines()[26:]\n",
    "\n",
    "print(type(lines))\n",
    "print(lines)\n",
    "\n",
    "pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a Row from the List\n",
    "#     - https://note.nkmk.me/en/python-list-clear-pop-remove-del/#:~:text=In%20Python%2C%20use%20list%20methods,with%20an%20index%20or%20slice.\n",
    "\n",
    "del lines[0:1]\n",
    "lines\n",
    "# print((lines[1].split(\"\\t\")))\n",
    "test = lines[1][:-1].split(\"\\t\")\n",
    "test\n",
    "\n",
    "a_series = pd.Series(test, index = clmn_nms)\n",
    "_13206000_df = _13206000_df.append(a_series, ignore_index=True)\n",
    "_13206000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the Text File and Convert to a Dataframe\n",
    "data = pd.read_csv('Data/Idaho_Streamflow_Data/13206000.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Empty Rows\n",
    "import numpy as np\n",
    "np.where(pd.isnull(statn_table_df_splt_StatnNmbr_nmbrs_clmn))\n",
    "# statn_table_df_splt_StatnNmbr_nmbrs_clmn.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"] = statn_table_df[\"StationNumber\"].astype(str)\n",
    "print(statn_table.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if \"County\" in statn_table[\"StationNumber\"][0]:\n",
    "        print(\"true\")\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([0, 4], axis = 0)\n",
    "statn_table_df_drp_cnty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the County Names from the Table\n",
    "# test = statn_table.drop([0, 4], axis = 0)\n",
    "# test.head()\n",
    "\n",
    "# Count the number of Rows in the Dataframe\n",
    "count = 0\n",
    "for statn_table_df_row in statn_table_df.index:\n",
    "\n",
    "    if \"County\" in statn_table_df[\"StationNumber\"][statn_table_df_row]:\n",
    "        statn_table_df_drp_cnty = statn_table_df.drop([statn_table_df_row], axis = 0)\n",
    "        count = count + 1\n",
    "\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df_drp_cnty.head(15)\n",
    "# statn_table_df_drp_cnty.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statn_table_df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statn_table_df[\"StationNumber\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "# Select(driver.find_element_by_id('rdb'))\n",
    "\n",
    "tab_sprtd_rado = '//input[@type=\"radio\" and @value=\"rdb\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(tab_sprtd_rado)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify location of chromedriver and store it as a variable\n",
    "chromedriver = !which chromedriver\n",
    "print(type(chromedriver))\n",
    "chromedriver[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Retrieve the data/information on USGS' WaterWatch website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "executable_path = {\"executable_path\": \"chromedriver\"}\n",
    "# OR\n",
    "# executable_path = {\"executable_path\": chromedriver[0]}\n",
    "# I am not sure why the above works and the below statement will not. I think it's b/c chromebriver is a class 'IPython.utils.text.SList'?\n",
    "# executable_path = {\"executable_path\": chromedriver}\n",
    "\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://waterwatch.usgs.gov/index.php?id=wwdrought\"\n",
    "# url = \"https://www.usgs.gov/\"\n",
    "browser.visit(url)\n",
    "window = browser.windows.current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BS(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the html code of the NASA's Mars website\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/19392466/python-beautifulsoup-get-select-value-not-text\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    print(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7867537/how-to-select-a-drop-down-menu-value-with-selenium-using-python\n",
    "\n",
    "select = Select(driver.find_element_by_id('st'))\n",
    "\n",
    "# Select by visible text\n",
    "select.select_by_visible_text('Idaho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in Input Fills\n",
    "#     - https://stackoverflow.com/questions/25537567/how-to-open-website-and-fill-in-input-using-selenium-webdriver\n",
    "# Clear the Input Field\n",
    "#     - http://10minbasics.com/clear-fill-input-field-with-selenium/\n",
    "\n",
    "element = driver.find_element_by_name(\"bdt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-01-01\")\n",
    "\n",
    "element = driver.find_element_by_name(\"edt\")\n",
    "element.clear()\n",
    "element.send_keys(\"1990-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press/Click a Button Without an ID\n",
    "#     - https://stackoverflow.com/questions/8871654/how-to-press-click-the-button-using-selenium-if-the-button-does-not-have-the-id\n",
    "\n",
    "NEXT_BUTTON_XPATH = '//input[@type=\"submit\" and @value=\"GO\"]'\n",
    "\n",
    "button = driver.find_element_by_xpath(NEXT_BUTTON_XPATH)\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "\n",
    "# test = soup.find_all(\"div\", class_= \"ztable\")\n",
    "# test\n",
    "\n",
    "# https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup\n",
    "soup.findAll('table')[0].findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab All Page Source on the Page\n",
    "soup_lxml = BS(driver.page_source, \"lxml\")\n",
    "\n",
    "# Find All the Tables on the Page\n",
    "tables = soup_lxml.find_all(\"table\")\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Tables with Pandas\n",
    "dfs = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the Table\n",
    "print(f\"Number of Tables on the page: {len(dfs)}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Data Types for the Table: {dfs[11].dtypes}\")\n",
    "print(\"*********************************************************************************************************\")\n",
    "print(f\"Number of Rows in the dataframe: {len(dfs[11])}\")\n",
    "dfs[11].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[11][\"USGSstationnumber\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "text = requests.get(\"https://waterwatch.usgs.gov/index.php?id=wwdrought\").text\n",
    "data = json.loads(text)\n",
    "print(data['Scty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in soup.find_all('tr')[2:]:\n",
    "    tds = tr.find_all('td')\n",
    "    print (tds)#\"Nome: %s, Cognome: %s, Email: %s\" % \\\n",
    "#           (tds[0].text, tds[1].text, tds[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 Collect the latest News Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
